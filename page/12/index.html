<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
        
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title> 学海无涯</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/favicon.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      
<link rel="stylesheet" href="/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 
<script>
var _hmt = _hmt || [];
(function() {
	var hm = document.createElement("script");
	hm.src = "https://hm.baidu.com/hm.js?b1b5dee3bb1719c8a439f8070118dc80";
	var s = document.getElementsByTagName("script")[0]; 
	s.parentNode.insertBefore(hm, s);
})();
</script>


      <!-- <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script> -->
      <link href="https://cdn.bootcdn.net/ajax/libs/sweetalert2/11.7.3/sweetalert2.min.css" rel="stylesheet">
      <script src="https://cdn.bootcdn.net/ajax/libs/sweetalert2/11.7.3/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    </head>
  </html>
</html>


<body>
  <div id="app">
    
      <canvas class="fireworks"></canvas>
      <style>
        .fireworks {
          position: fixed;
          left: 0;
          top: 0;
          z-index: 99999;
          pointer-events: none;
        }
      </style>
      
      
    <main class="content on">
      
<section class="cover">
    
      
      <a class="forkMe" href="https://github.com/wsq01/"
        target="_blank"><img width="149" height="149" src="/images/forkme.png"
          class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
    
  <div class="cover-frame">
    <div class="bg-box">
      <img src="/images/cover5.jpg" alt="image frame" />
    </div>
    <div class="cover-inner text-center text-white">
      <h1><a href="/">学海无涯</a></h1>
      <div id="subtitle-box">
        
        <span id="subtitle"></span>
        
      </div>
      <div>
        
      </div>
    </div>
  </div>
  <div class="cover-learn-more">
    <a href="javascript:void(0)" class="anchor"><i class="ri-arrow-down-line"></i></a>
  </div>
</section>



<script src="https://cdn.staticfile.org/typed.js/2.0.12/typed.min.js"></script>


<!-- Subtitle -->

  <script>
    try {
      var typed = new Typed("#subtitle", {
        strings: ['面朝大海，春暖花开', '愿你一生努力，一生被爱', '想要的都拥有，得不到的都释怀'],
        startDelay: 0,
        typeSpeed: 200,
        loop: true,
        backSpeed: 100,
        showCursor: true
      });
    } catch (err) {
      console.log(err)
    }
  </script>
  
<div id="main">
  <section class="outer">
  
  
  

<div class="notice" style="margin-top:50px">
    <i class="ri-heart-fill"></i>
    <div class="notice-content" id="broad"></div>
</div>
<script type="text/javascript">
    fetch('https://v1.hitokoto.cn')
        .then(response => response.json())
        .then(data => {
            document.getElementById("broad").innerHTML = data.hitokoto;
        })
        .catch(console.error)
</script>

<style>
    .notice {
        padding: 20px;
        border: 1px dashed #e6e6e6;
        color: #969696;
        position: relative;
        display: inline-block;
        width: 100%;
        background: #fbfbfb50;
        border-radius: 10px;
    }

    .notice i {
        float: left;
        color: #999;
        font-size: 16px;
        padding-right: 10px;
        vertical-align: middle;
        margin-top: -2px;
    }

    .notice-content {
        display: initial;
        vertical-align: middle;
    }
</style>
  
  <article class="articles">
    
    
    
    
    <article
  id="post-Linux/文本处理"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2022/01/18/Linux/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/"
    >Linux文本处理</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2022/01/18/Linux/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/" class="article-date">
  <time datetime="2022-01-18T08:13:15.000Z" itemprop="datePublished">2022-01-18</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Linux/">Linux</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="cat命令：连接文件并打印输出到标准输出设备"><a href="#cat命令：连接文件并打印输出到标准输出设备" class="headerlink" title="cat命令：连接文件并打印输出到标准输出设备"></a>cat命令：连接文件并打印输出到标准输出设备</h1><p><code>cat</code>命令可以用来显示文本文件的内容，也可以把几个文件内容附加到另一个文件中，即连接合并文件。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># cat [选项] 文件名</span></span><br><span class="line">或者</span><br><span class="line">[root@localhost ~]<span class="comment"># cat 文件1 文件2 &gt; 文件3</span></span><br></pre></td></tr></table></figure>
<p>这两种格式中，前者用于显示文件的内容；而后者用于连接合并文件。</p>
<p><code>cat</code>命令常用选项及含义：</p>
<table>
<thead>
<tr>
<th align="center">选项</th>
<th align="center">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="center">-A</td>
<td align="center">相当于 -vET 选项的整合，用于列出所有隐藏符号；</td>
</tr>
<tr>
<td align="center">-E</td>
<td align="center">列出每行结尾的回车符 $；</td>
</tr>
<tr>
<td align="center">-n</td>
<td align="center">对输出的所有行进行编号；</td>
</tr>
<tr>
<td align="center">-b</td>
<td align="center">同 -n 不同，此选项表示只对非空行进行编号。</td>
</tr>
<tr>
<td align="center">-T</td>
<td align="center">把 Tab 键 ^I 显示出来；</td>
</tr>
<tr>
<td align="center">-V</td>
<td align="center">列出特殊字符；</td>
</tr>
<tr>
<td align="center">-s</td>
<td align="center">当遇到有连续 2 行以上的空白行时，就替换为 1 行的空白行。</td>
</tr>
</tbody></table>
<p>注意，<code>cat</code>命令用于查看文件内容时，不论文件内容有多少，都会一次性显示。如果文件非常大，那么文件开头的内容就看不到了。不过 Linux 可以使用<code>PgUp+</code>上箭头组合键向上翻页，但是这种翻页是有极限的，如果文件足够长，那么还是无法看全文件的内容。因此，<code>cat</code>命令适合查看不太大的文件。</p>
<p>如果使用<code>-A</code>选项，则相当于使用了<code>-vET</code>选项，可以查看文本中的所有隐藏符号，包括回车符（<code>$</code>）、Tab 键（<code>^I</code>）等。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># cat -A anaconda-ks.cfg</span></span><br><span class="line"><span class="comment"># Kickstart file automatically generated by anaconda.$</span></span><br><span class="line">$</span><br><span class="line">$</span><br><span class="line"><span class="comment">#version=DEVEL$</span></span><br><span class="line">install$</span><br><span class="line">cdrom$</span><br><span class="line">…省略部分内容…</span><br></pre></td></tr></table></figure>
<p>将文件<code>file1.txt</code>和<code>file2.txt</code>的内容合并后输出到文件<code>file3.txt</code>中。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost base]<span class="comment"># ls</span></span><br><span class="line">file1.txt    file2.txt</span><br><span class="line">[root@localhost base]<span class="comment"># cat file1.txt</span></span><br><span class="line">http://c.biancheng.net(file1.txt)</span><br><span class="line">[root@localhost base]<span class="comment"># cat file2.txt</span></span><br><span class="line">is great(file2.txt)</span><br><span class="line">[root@localhost base]<span class="comment"># cat file1.txt file2.txt &gt; file3.txt</span></span><br><span class="line">[root@localhost base]<span class="comment"># more file3.txt</span></span><br><span class="line"><span class="comment">#more 命令可查看文件中的内容</span></span><br><span class="line">http://c.biancheng.net(file1.txt)</span><br><span class="line">is great(file2.txt)</span><br><span class="line">[root@localhost base]<span class="comment"># ls</span></span><br><span class="line">file1.txt    file2.txt    file3.txt</span><br></pre></td></tr></table></figure>
<h1 id="more命令：分屏显示文件内容"><a href="#more命令：分屏显示文件内容" class="headerlink" title="more命令：分屏显示文件内容"></a>more命令：分屏显示文件内容</h1><p><code>more</code>命令可以分页显示文本文件的内容，使用者可以逐页阅读文件中内容：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># more [选项] 文件名</span></span><br></pre></td></tr></table></figure>
<p><code>more</code>命令选项及含义：</p>
<table>
<thead>
<tr>
<th align="center">选项</th>
<th align="center">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="center">-f</td>
<td align="center">计算行数时，以实际的行数，而不是自动换行过后的行数。</td>
</tr>
<tr>
<td align="center">-p</td>
<td align="center">不以卷动的方式显示每一页，而是先清除屏幕后再显示内容。</td>
</tr>
<tr>
<td align="center">-c</td>
<td align="center">跟 -p 选项相似，不同的是先显示内容再清除其他旧资料。</td>
</tr>
<tr>
<td align="center">-s</td>
<td align="center">当遇到有连续两行以上的空白行时，就替换为一行的空白行。</td>
</tr>
<tr>
<td align="center">-u</td>
<td align="center">不显示下引号（根据环境变量 TERM 指定的终端而有所不同）。</td>
</tr>
<tr>
<td align="center">+n</td>
<td align="center">从第 n 行开始显示文件内容，n 代表数字。</td>
</tr>
<tr>
<td align="center">-n</td>
<td align="center">一次显示的行数，n 代表数字。</td>
</tr>
</tbody></table>
<p><code>more</code>命令的执行会打开一个交互界面，因此有必要了解一些交互命令，常用的交互命令：</p>
<table>
<thead>
<tr>
<th align="center">交互指令</th>
<th align="center">功能</th>
</tr>
</thead>
<tbody><tr>
<td align="center">h 或 ？</td>
<td align="center">显示 more 命令交互命令帮助。</td>
</tr>
<tr>
<td align="center">q 或 Q</td>
<td align="center">退出 more。</td>
</tr>
<tr>
<td align="center">v</td>
<td align="center">在当前行启动一个编辑器。</td>
</tr>
<tr>
<td align="center">:f</td>
<td align="center">显示当前文件的文件名和行号。</td>
</tr>
<tr>
<td align="center">!&lt;命令&gt; 或 :!&lt;命令&gt;</td>
<td align="center">在子Shell中执行指定命令。</td>
</tr>
<tr>
<td align="center">回车键</td>
<td align="center">向下移动一行。</td>
</tr>
<tr>
<td align="center">空格键</td>
<td align="center">向下移动一页。</td>
</tr>
<tr>
<td align="center">Ctrl+l</td>
<td align="center">刷新屏幕。</td>
</tr>
<tr>
<td align="center">&#x3D;</td>
<td align="center">显示当前行的行号。</td>
</tr>
<tr>
<td align="center">‘</td>
<td align="center">转到上一次搜索开始的地方。</td>
</tr>
<tr>
<td align="center">Ctrf+f</td>
<td align="center">向下滚动一页。</td>
</tr>
<tr>
<td align="center">.</td>
<td align="center">重复上次输入的命令。</td>
</tr>
<tr>
<td align="center">&#x2F;字符串</td>
<td align="center">搜索指定的字符串。</td>
</tr>
<tr>
<td align="center">d</td>
<td align="center">向下移动半页。</td>
</tr>
<tr>
<td align="center">b</td>
<td align="center">向上移动一页。</td>
</tr>
</tbody></table>
<p>用分页的方式显示<code>anaconda-ks.cfg</code>文件的内容。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># more anaconda-ks.cfg</span></span><br><span class="line"><span class="comment"># Kickstart file automatically generated by anaconda.</span></span><br><span class="line"><span class="comment">#version=DEVEL</span></span><br><span class="line">install</span><br><span class="line">cdrom</span><br><span class="line">…省略部分内容…</span><br><span class="line">--More--(69%)</span><br><span class="line"><span class="comment">#在这里执行交互命令即可</span></span><br></pre></td></tr></table></figure>
<p>显示文件<code>anaconda-ks.cfg</code>的内容，每 10 行显示一屏，同时清楚屏幕，使用以下命令：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># more -c -10 anaconda-ks.cfg</span></span><br><span class="line"><span class="comment">#省略输出内容。</span></span><br></pre></td></tr></table></figure>
<h1 id="head命令：显示文件开头的内容"><a href="#head命令：显示文件开头的内容" class="headerlink" title="head命令：显示文件开头的内容"></a>head命令：显示文件开头的内容</h1><p><code>head</code>命令可以显示指定文件前若干行的文件内容。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># head [选项] 文件名</span></span><br></pre></td></tr></table></figure>
<p><code>head</code>命令常用选项及含义：</p>
<table>
<thead>
<tr>
<th align="center">选项</th>
<th align="center">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="center">-n K</td>
<td align="center">这里的 K 表示行数，该选项用来显示文件前 K 行的内容；如果使用 “-K” 作为参数，则表示除了文件最后 K 行外，显示剩余的全部内容。</td>
</tr>
<tr>
<td align="center">-c K</td>
<td align="center">这里的 K 表示字节数，该选项用来显示文件前 K 个字节的内容；如果使用 “-K”，则表示除了文件最后 K 字节的内容，显示剩余全部内容。</td>
</tr>
<tr>
<td align="center">-v</td>
<td align="center">显示文件名；注意，如不设置显示的具体行数，则默认显示 10 行的文本数据。</td>
</tr>
</tbody></table>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># head anaconda-ks.cfg</span></span><br></pre></td></tr></table></figure>
<p><code>head</code>命令默认显示文件的开头 10 行内容。如果想显示指定的行数，则只需使用<code>-n</code>选项即可：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># head -n 20 anaconda-ks.cfg</span></span><br></pre></td></tr></table></figure>
<p>这是显示文件的开头 20 行内容，也可以直接写”-行数”：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># head -20 anaconda-ks.cfg</span></span><br></pre></td></tr></table></figure>
<h1 id="less命令：查看文件内容"><a href="#less命令：查看文件内容" class="headerlink" title="less命令：查看文件内容"></a>less命令：查看文件内容</h1><p><code>less</code>命令的作用和<code>more</code>十分类似，都用来浏览文本文件中的内容，不同之处在于，使用<code>more</code>命令浏览文件内容时，只能不断向后翻看，而使用<code>less</code>命令浏览，既可以向后翻看，也可以向前翻看。</p>
<p>不仅如此，为了方面用户浏览文本内容，<code>less</code>命令还提供了以下几个功能：</p>
<ul>
<li>使用光标键可以在文本文件中前后（左后）滚屏；</li>
<li>用行号或百分比作为书签浏览文件；</li>
<li>提供更加友好的检索、高亮显示等操作；</li>
<li>兼容常用的字处理程序（如 Vim、Emacs）的键盘操作；</li>
<li>阅读到文件结束时，<code>less</code>命令不会退出；</li>
<li>屏幕底部的信息提示更容易控制使用，而且提供了更多的信息。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># less [选项] 文件名</span></span><br></pre></td></tr></table></figure>
<p><code>less</code>命令选项及含义：</p>
<table>
<thead>
<tr>
<th align="center">选项</th>
<th align="center">选项含义</th>
</tr>
</thead>
<tbody><tr>
<td align="center">-N</td>
<td align="center">显示每行的行号。</td>
</tr>
<tr>
<td align="center">-S</td>
<td align="center">行过长时将超出部分舍弃。</td>
</tr>
<tr>
<td align="center">-e</td>
<td align="center">当文件显示结束后，自动离开。</td>
</tr>
<tr>
<td align="center">-g</td>
<td align="center">只标志最后搜索到的关键同。</td>
</tr>
<tr>
<td align="center">-Q</td>
<td align="center">不使用警告音。</td>
</tr>
<tr>
<td align="center">-i</td>
<td align="center">忽略搜索时的大小写。</td>
</tr>
<tr>
<td align="center">-m</td>
<td align="center">显示类似 more 命令的百分比。</td>
</tr>
<tr>
<td align="center">-f</td>
<td align="center">强迫打开特殊文件，比如外围设备代号、目录和二进制文件。</td>
</tr>
<tr>
<td align="center">-s</td>
<td align="center">显示连续空行为一行。</td>
</tr>
<tr>
<td align="center">-b</td>
<td align="center">&lt;缓冲区大小&gt;	设置缓冲区的大小。</td>
</tr>
<tr>
<td align="center">-o</td>
<td align="center">&lt;文件名&gt;	将 less 输出的内容保存到指定文件中。</td>
</tr>
<tr>
<td align="center">-x</td>
<td align="center">&lt;数字&gt;	将【Tab】键显示为规定的数字空格。</td>
</tr>
</tbody></table>
<p>在使用<code>less</code>命令查看文件内容的过程中，和<code>more</code>命令一样，也会进入交互界面，因此需要掌握一些常用的交互指令。</p>
<table>
<thead>
<tr>
<th align="center">交互指令</th>
<th align="center">功能</th>
</tr>
</thead>
<tbody><tr>
<td align="center">&#x2F;字符串</td>
<td align="center">向下搜索“字符串”的功能。</td>
</tr>
<tr>
<td align="center">?字符串</td>
<td align="center">向上搜索“字符串”的功能。</td>
</tr>
<tr>
<td align="center">n</td>
<td align="center">重复*前一个搜索（与 &#x2F; 成 ? 有关）。</td>
</tr>
<tr>
<td align="center">N</td>
<td align="center">反向重复前一个搜索（与 &#x2F; 或 ? 有关）。</td>
</tr>
<tr>
<td align="center">b</td>
<td align="center">向上移动一页。</td>
</tr>
<tr>
<td align="center">d</td>
<td align="center">向下移动半页。</td>
</tr>
<tr>
<td align="center">h 或 H</td>
<td align="center">显示帮助界面。</td>
</tr>
<tr>
<td align="center">q 或 Q</td>
<td align="center">退出 less 命令。</td>
</tr>
<tr>
<td align="center">y</td>
<td align="center">向上移动一行。</td>
</tr>
<tr>
<td align="center">空格键</td>
<td align="center">向下移动一页。</td>
</tr>
<tr>
<td align="center">回车键</td>
<td align="center">向下移动一行。</td>
</tr>
<tr>
<td align="center">【PgDn】键</td>
<td align="center">向下移动一页。</td>
</tr>
<tr>
<td align="center">【PgUp】键</td>
<td align="center">向上移动一页。</td>
</tr>
<tr>
<td align="center">Ctrl+f</td>
<td align="center">向下移动一页。</td>
</tr>
<tr>
<td align="center">Ctrl+b</td>
<td align="center">向上移动一页。</td>
</tr>
<tr>
<td align="center">Ctrl+d</td>
<td align="center">向下移动一页。</td>
</tr>
<tr>
<td align="center">Ctrl+u</td>
<td align="center">向上移动半页。</td>
</tr>
<tr>
<td align="center">j</td>
<td align="center">向下移动一行。</td>
</tr>
<tr>
<td align="center">k</td>
<td align="center">向上移动一行。</td>
</tr>
<tr>
<td align="center">G</td>
<td align="center">移动至最后一行。</td>
</tr>
<tr>
<td align="center">g</td>
<td align="center">移动到第一行。</td>
</tr>
<tr>
<td align="center">ZZ</td>
<td align="center">退出 less 命令。</td>
</tr>
<tr>
<td align="center">v</td>
<td align="center">使用配置的编辑器编辑当前文件。</td>
</tr>
<tr>
<td align="center">[</td>
<td align="center">移动到本文档的上一个节点。</td>
</tr>
<tr>
<td align="center">]</td>
<td align="center">移动到本文档的下一个节点。</td>
</tr>
<tr>
<td align="center">p</td>
<td align="center">移动到同级的上一个节点。</td>
</tr>
<tr>
<td align="center">u</td>
<td align="center">向上移动半页。</td>
</tr>
</tbody></table>
<p>使用<code>less</code>命令查看<code>/boot/grub/grub.cfg</code>文件中的内容。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># less /boot/grub/grub.cfg</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#DO NOT EDIT THIS FILE</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#It is automatically generated by grub-mkconfig using templates from /etc/grub.d and settings from /etc/default/grub</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### BEGIN /etc/grub.d/00_header ###</span></span><br><span class="line"><span class="keyword">if</span> [ -s <span class="variable">$prefix</span>/grubenv ]; <span class="keyword">then</span></span><br><span class="line">  <span class="built_in">set</span> have_grubenv=<span class="literal">true</span></span><br><span class="line">  load_env</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">set</span> default=<span class="string">&quot;0&quot;</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">&quot;$ &#123;prev_saved_entry&#125;&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">  <span class="built_in">set</span> saved_entry=<span class="string">&quot;<span class="variable">$&#123;prev_saved_entry&#125;</span>&quot;</span></span><br><span class="line">  save_env saved_entry</span><br><span class="line">  <span class="built_in">set</span> prev_saved_entry= save_env prev_saved_entry</span><br><span class="line">  <span class="built_in">set</span> boot_once=<span class="literal">true</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> savedefault &#123;</span><br><span class="line">  <span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$&#123;boot_once&#125;</span>&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">:</span><br></pre></td></tr></table></figure>
<p>可以看到，<code>less</code>在屏幕底部显示一个冒号（<code>:</code>），等待用户输入命令，比如说，用户想向下翻一页，可以按空格键；如果想向上翻一页，可以按<code>b</code>键。</p>
<h1 id="tail命令：显示文件结尾的内容"><a href="#tail命令：显示文件结尾的内容" class="headerlink" title="tail命令：显示文件结尾的内容"></a>tail命令：显示文件结尾的内容</h1><p><code>tail</code>命令和<code>head</code>命令正好相反，它用来查看文件末尾的数据：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># tail [选项] 文件名</span></span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="center">选项</th>
<th align="center">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="center">-n K</td>
<td align="center">这里的 K 指的是行数，该选项表示输出最后 K 行，在此基础上，如果使用 -n +K，则表示从文件的第 K 行开始输出。</td>
</tr>
<tr>
<td align="center">-c K</td>
<td align="center">这里的 K 指的是字节数，该选项表示输出文件最后 K 个字节的内容，在此基础上，使用 -c +K 则表示从文件第 K 个字节开始输出。</td>
</tr>
<tr>
<td align="center">-f</td>
<td align="center">输出文件变化后新增加的数据。</td>
</tr>
</tbody></table>
<p>查看<code>/etc/passwd</code>文件最后 3 行的数据内容。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># tail -n 3 /etc/passwd</span></span><br><span class="line">sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin</span><br><span class="line">oprofile:x:16:16:Special user account to be used by OProfile:/var/lib/oprofile:/sbin/nologin</span><br><span class="line">tcpdump:x:72:72::/:/sbin/nologin</span><br></pre></td></tr></table></figure>
<p>除此之外，还可以采用如下这种形式：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># tail -3 /etc/passwd</span></span><br><span class="line">sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin</span><br><span class="line">oprofile:x:16:16:Special user account to be used by OProfile:/var/lib/oprofile:/sbin/nologin</span><br><span class="line">tcpdump:x:72:72::/:/sbin/nologin</span><br></pre></td></tr></table></figure>
<p>可以看到，使用<code>tail -n 3 /etc/passwd</code>命令和<code>tail -3 /etc/passwd</code>的效果是一样的。</p>
<p>查看<code>/etc/passwd</code>文件末尾 100 个字节的数据内容。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># tail -c 100 /etc/passwd</span></span><br><span class="line">cpdump:x:72:72::/:/sbin/nologin</span><br></pre></td></tr></table></figure>
<p>监听文件的新増内容。可以使用<code>-f</code>选项来监听文件的新増内容：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment">#tail -f anaconda-ks.cfg</span></span><br><span class="line">@server-platform</span><br><span class="line">@server-policy</span><br><span class="line">pax</span><br><span class="line">oddjob</span><br><span class="line">sgpio</span><br><span class="line">certmonger</span><br><span class="line">pam_krb5</span><br><span class="line">krb5-workstation</span><br><span class="line">perl-DBD-SQLite</span><br><span class="line">%end</span><br><span class="line"><span class="comment">#光标不会退出文件，而会一直监听在文件的结尾处</span></span><br></pre></td></tr></table></figure>
<p>这条命令会显示文件的最后 10 行内容，而且光标不会退出命令，每隔一秒会检查一下文件是否增加新的内容，如果增加就追加到原来的输出结果后面并显示。</p>
<p>如果想终止输出，按<code>Ctrl+c</code>键中断<code>tail</code>命令即可。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Linux/" rel="tag">Linux</a></li></ul>

    </footer>
  </div>

   
   
  
</article>

    
    <article
  id="post-计算机网络/TCP 重传、滑动窗口、流量控制、拥塞控制"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/"
    >TCP 重传、滑动窗口、流量控制、拥塞控制</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/" class="article-date">
  <time datetime="2022-01-15T03:49:21.000Z" itemprop="datePublished">2022-01-15</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">计算机网络</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="重传机制"><a href="#重传机制" class="headerlink" title="重传机制"></a>重传机制</h1><p>TCP 实现可靠传输的方式之一，是通过序列号与确认应答。</p>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/1.jpg" class="">

<p>但在错综复杂的网络，并不一定能如上图那么顺利能正常的数据传输，万一数据在传输过程中丢失了呢？</p>
<p>所以 TCP 针对数据包丢失的情况，会用重传机制解决。常见的重传机制：</p>
<ul>
<li>超时重传</li>
<li>快速重传</li>
<li>SACK</li>
<li>D-SACK</li>
</ul>
<h2 id="超时重传"><a href="#超时重传" class="headerlink" title="超时重传"></a>超时重传</h2><p>重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 ACK 确认应答报文，就会重发该数据，也就是我们常说的超时重传。</p>
<p>TCP 会在以下两种情况发生超时重传：</p>
<ul>
<li>数据包丢失</li>
<li>确认应答丢失</li>
</ul>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/2.jpg" class="">

<h3 id="超时时间应该设置为多少呢？"><a href="#超时时间应该设置为多少呢？" class="headerlink" title="超时时间应该设置为多少呢？"></a>超时时间应该设置为多少呢？</h3><p>我们先来了解一下什么是 RTT（<code>Round-Trip Time</code>往返时延），从下图我们就可以知道：RTT 就是数据从网络一端传送到另一端所需的时间，也就是包的往返时间。</p>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/3.jpg" class="">

<p>超时重传时间是以 RTO （<code>Retransmission Timeout</code>超时重传时间）表示。</p>
<p>假设在重传的情况下，超时时间 RTO 较长或较短时，会发生什么事情呢？</p>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/4.jpg" class="">

<p>上图中有两种超时时间不同的情况：</p>
<ul>
<li>当超时时间 RTO 较大时，重发就慢，丢了老半天才重发，没有效率，性能差；</li>
<li>当超时时间 RTO 较小时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。</li>
</ul>
<p>精确的测量超时时间 RTO 的值是非常重要的，这可让我们的重传机制更高效。</p>
<p>根据上述的两种情况，我们可以得知，超时重传时间 RTO 的值应该略大于报文往返 RTT 的值。</p>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/5.jpg" class="">

<p>至此，可能大家觉得超时重传时间 RTO 的值计算，也不是很复杂嘛。</p>
<p>好像就是在发送端发包时记下<code>t0</code>，然后接收端再把这个<code>ack</code>回来时再记一个<code>t1</code>，于是<code>RTT = t1 – t0</code>。没那么简单，这只是一个采样，不能代表普遍情况。</p>
<p>实际上报文往返 RTT 的值是经常变化的，因为我们的网络也是时常变化的。也就因为报文往返 RTT 的值是经常波动变化的，所以超时重传时间 RTO 的值应该是一个动态变化的值。</p>
<p>我们来看看 Linux 是如何计算 RTO 的呢？</p>
<p>估计往返时间，通常需要采样以下两个：</p>
<p>需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个平滑 RTT 的值，而且这个值还是要不断变化的，因为网络状况不断地变化。</p>
<p>除了采样 RTT，还要采样 RTT 的波动范围，这样就避免如果 RTT 有一个大的波动的话，很难被发现的情况。</p>
<p>RFC6289 建议使用以下的公式计算 RTO：</p>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/6.jpg" class="">

<p>其中 SRTT 是计算平滑的RTT ，DevRTR 是计算平滑的RTT 与 最新 RTT 的差距。</p>
<p>在 Linux 下，<code>α = 0.125，β = 0.25， μ = 1，∂ = 4</code>。别问怎么来的，问就是大量实验中调出来的。</p>
<p>如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是超时间隔加倍。</p>
<p>也就是每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。</p>
<p>超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？</p>
<p>于是就可以用「快速重传」机制来解决超时重发的时间等待。</p>
<h2 id="快速重传"><a href="#快速重传" class="headerlink" title="快速重传"></a>快速重传</h2><p>TCP 还有另外一种快速重传（<code>Fast Retransmit</code>）机制，它不以时间为驱动，而是以数据驱动重传。</p>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/7.jpg" class="">

<p>在上图，发送方发出了 1，2，3，4，5 份数据：</p>
<ul>
<li>第一份 Seq1 先送到了，于是就 Ack 回 2；</li>
<li>结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2；</li>
<li>后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到；</li>
<li>发送端收到了三个 Ack &#x3D; 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。</li>
<li>最后，收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。</li>
</ul>
<p>所以，快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。</p>
<p>快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是重传的时候，是重传之前的一个，还是重传所有的问题。</p>
<p>比如对于上面的例子，是重传 Seq2 呢？还是重传 Seq2、Seq3、Seq4、Seq5 呢？因为发送端并不清楚这连续的三个 Ack 2 是谁传回来的。</p>
<p>根据 TCP 不同的实现，以上两种情况都是有可能的。可见，这是一把双刃剑。</p>
<p>为了解决不知道该重传哪些 TCP 报文，于是就有 SACK 方法。</p>
<h2 id="SACK-方法"><a href="#SACK-方法" class="headerlink" title="SACK 方法"></a>SACK 方法</h2><p>还有一种实现重传机制的方式叫：SACK（Selective Acknowledgment 选择性确认）。</p>
<p>这种方式需要在 TCP 头部「选项」字段里加一个 SACK 的东西，它可以将缓存的地图发送给发送方，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据。</p>
<p>如下图，发送方收到了三次同样的 ACK 确认报文，于是就会触发快速重发机制，通过 SACK 信息发现只有 200~299 这段数据丢失，则重发时，就只选择了这个 TCP 段进行重复。</p>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/8.jpg" class="">

<p>如果要支持 SACK，必须双方都要支持。在 Linux 下，可以通过<code>net.ipv4.tcp_sack</code>参数打开这个功能（Linux 2.4 后默认打开）。</p>
<h2 id="Duplicate-SACK"><a href="#Duplicate-SACK" class="headerlink" title="Duplicate SACK"></a>Duplicate SACK</h2><p>Duplicate SACK 又称 D-SACK，其主要使用了 SACK 来告诉发送方有哪些数据被重复接收了。</p>
<p>下面举例两个栗子，来说明 D-SACK 的作用。</p>
<p>栗子一号：ACK 丢包</p>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/9.jpg" class="">

<ul>
<li>「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）</li>
<li>于是「接收方」发现数据是重复收到的，于是回了一个<code>SACK = 3000~3500</code>，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个<code>SACK</code>就代表着 D-SACK。</li>
<li>这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。</li>
</ul>
<p>栗子二号：网络延时</p>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/10.jpg" class="">

<ul>
<li>数据包（1000~1499）被网络延迟了，导致发送方没有收到 Ack 1500 的确认报文。</li>
<li>而后面报文到达的三个相同的 ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了接收方；</li>
<li>所以接收方回了一个 SACK&#x3D;1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。</li>
<li>这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。</li>
</ul>
<p>可见，D-SACK 有这么几个好处：</p>
<ul>
<li>可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;</li>
<li>可以知道是不是「发送方」的数据包被网络延迟了;</li>
<li>可以知道网络中是不是把「发送方」的数据包给复制了;</li>
</ul>
<h1 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h1><p>我们都知道 TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了，再发送下一个。</p>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/11.jpg" class="">

<p>所以，这样的传输方式有一个缺点：数据包的往返时间越长，通信的效率就越低。</p>
<p>为解决这个问题，TCP 引入了窗口这个概念。即使在往返时间较长的情况下，它也不会降低网络通信的效率。</p>
<p>那么有了窗口，就可以指定窗口大小，窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值。</p>
<p>窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。</p>
<p>假设窗口大小为 3 个 TCP 段，那么发送方就可以连续发送 3 个 TCP 段，并且中途若有 ACK 丢失，可以通过「下一个确认应答进行确认」。如下图：</p>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/12.jpg" class="">

<p>图中的 ACK 600 确认应答报文丢失，也没关系，因为可以通过下一个确认应答进行确认，只要发送方收到了 ACK 700 确认应答，就意味着 700 之前的所有数据接收方都收到了。这个模式就叫累计确认或者累计应答。</p>
<h3 id="窗口大小由哪一方决定？"><a href="#窗口大小由哪一方决定？" class="headerlink" title="窗口大小由哪一方决定？"></a>窗口大小由哪一方决定？</h3><p>TCP 头里有一个字段叫<code>Window</code>，也就是窗口大小。</p>
<p>这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。</p>
<p>所以，通常窗口的大小是由接收方的窗口大小来决定的。</p>
<p>发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。</p>
<h3 id="发送方的滑动窗口"><a href="#发送方的滑动窗口" class="headerlink" title="发送方的滑动窗口"></a>发送方的滑动窗口</h3><p>我们先来看看发送方的窗口，下图就是发送方缓存的数据，根据处理的情况分成四个部分，其中深蓝色方框是发送窗口，紫色方框是可用窗口：</p>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/13.jpg" class="">

<ul>
<li>#1 是已发送并收到<code>ACK</code>确认的数据：1~31 字节</li>
<li>#2 是已发送但未收到<code>ACK</code>确认的数据：32~45 字节</li>
<li>#3 是未发送但总大小在接收方处理范围内（接收方还有空间）：46~51 字节</li>
<li>#4 是未发送但总大小超过接收方处理范围（接收方没有空间）：52 字节以后</li>
</ul>
<p>在下图，当发送方把数据全部都一下发送出去后，可用窗口的大小就为 0 了，表明可用窗口耗尽，在没收到 ACK 确认之前是无法继续发送数据了。</p>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/14.jpg" class="">

<p>在下图，当收到之前发送的数据<code>32~36</code>字节的<code>ACK</code>确认应答后，如果发送窗口的大小没有变化，则滑动窗口往右边移动 5 个字节，因为有 5 个字节的数据被应答确认，接下来<code>52~56</code>字节又变成了可用窗口，那么后续也就可以发送<code>52~56</code>这 5 个字节的数据了。</p>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/15.jpg" class="">

<h3 id="程序是如何表示发送方的四个部分的呢？"><a href="#程序是如何表示发送方的四个部分的呢？" class="headerlink" title="程序是如何表示发送方的四个部分的呢？"></a>程序是如何表示发送方的四个部分的呢？</h3><p>TCP 滑动窗口方案使用三个指针来跟踪在四个传输类别中的每一个类别中的字节。其中两个指针是绝对指针（指特定的序列号），一个是相对指针（需要做偏移）。</p>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/16.jpg" class="">

<ul>
<li><code>SND.WND</code>：表示发送窗口的大小（大小是由接收方指定的）；</li>
<li><code>SND.UNA</code>：是一个绝对指针，它指向的是已发送但未收到确认的第一个字节的序列号，也就是 #2 的第一个字节。</li>
<li><code>SND.NXT</code>：也是一个绝对指针，它指向未发送但可发送范围的第一个字节的序列号，也就是 #3 的第一个字节。</li>
<li>指向 #4 的第一个字节是个相对指针，它需要<code>SND.UNA</code>指针加上<code>SND.WND</code>大小的偏移量，就可以指向 #4 的第一个字节了。</li>
</ul>
<p>那么可用窗口大小的计算就可以是：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">可用窗口大 = SND.WND -（SND.NXT - SND.UNA）</span><br></pre></td></tr></table></figure>
<h3 id="接收方的滑动窗口"><a href="#接收方的滑动窗口" class="headerlink" title="接收方的滑动窗口"></a>接收方的滑动窗口</h3><p>接下来我们看看接收方的窗口，接收窗口相对简单一些，根据处理的情况划分成三个部分：</p>
<ul>
<li>#1 + #2 是已成功接收并确认的数据（等待应用进程读取）；</li>
<li>#3 是未收到数据但可以接收的数据；</li>
<li>#4 未收到数据并不可以接收的数据；</li>
</ul>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/17.jpg" class="">

<p>其中三个接收部分，使用两个指针进行划分:</p>
<ul>
<li><code>RCV.WND</code>：表示接收窗口的大小，它会通告给发送方。</li>
<li><code>RCV.NXT</code>：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是 #3 的第一个字节。</li>
<li>指向 #4 的第一个字节是个相对指针，它需要<code>RCV.NXT</code>指针加上<code>RCV.WND</code>大小的偏移量，就可以指向 #4 的第一个字节了。</li>
</ul>
<h3 id="接收窗口和发送窗口的大小是相等的吗？"><a href="#接收窗口和发送窗口的大小是相等的吗？" class="headerlink" title="接收窗口和发送窗口的大小是相等的吗？"></a>接收窗口和发送窗口的大小是相等的吗？</h3><p>并不是完全相等，接收窗口的大小是约等于发送窗口的大小的。</p>
<p>因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。</p>
<h1 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h1><p>发送方不能无脑的发数据给接收方，要考虑接收方处理能力。</p>
<p>如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。</p>
<p>为了解决这种现象发生，TCP 提供一种机制可以让发送方根据接收方的实际接收能力控制发送的数据量，这就是所谓的流量控制。</p>
<p>下面举个栗子，为了简单起见，假设以下场景：</p>
<ul>
<li>客户端是接收方，服务端是发送方</li>
<li>假设接收窗口和发送窗口相同，都为 200</li>
<li>假设两个设备在整个传输过程中都保持相同的窗口大小，不受外界影响</li>
</ul>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/18.jpg" class="">

<p>根据上图的流量控制，说明下每个过程：</p>
<ol>
<li>客户端向服务端发送请求数据报文。这里要说明下，本次例子是把服务端作为发送方，所以没有画出服务端的接收窗口。</li>
<li>服务端收到请求报文后，发送确认报文和 80 字节的数据，于是可用窗口 Usable 减少为 120 字节，同时 SND.NXT 指针也向右偏移 80 字节后，指向 321，这意味着下次发送数据的时候，序列号是 321。</li>
<li>客户端收到 80 字节数据后，于是接收窗口往右移动 80 字节，<code>RCV.NXT</code>也就指向 321，这意味着客户端期望的下一个报文的序列号是 321，接着发送确认报文给服务端。</li>
<li>服务端再次发送了 120 字节数据，于是可用窗口耗尽为 0，服务端无法再继续发送数据。</li>
<li>客户端收到 120 字节的数据后，于是接收窗口往右移动 120 字节，RCV.NXT 也就指向 441，接着发送确认报文给服务端。</li>
<li>服务端收到对 80 字节数据的确认报文后，<code>SND.UNA</code>指针往右偏移后指向 321，于是可用窗口 Usable 增大到 80。</li>
<li>服务端收到对 120 字节数据的确认报文后，<code>SND.UNA</code>指针往右偏移后指向 441，于是可用窗口 Usable 增大到 200。</li>
<li>服务端可以继续发送了，于是发送了 160 字节的数据后，<code>SND.NXT</code>指向 601，于是可用窗口 Usable 减少到 40。</li>
<li>客户端收到 160 字节后，接收窗口往右移动了 160 字节，<code>RCV.NXT</code>也就是指向了 601，接着发送确认报文给服务端。</li>
<li>服务端收到对 160 字节数据的确认报文后，发送窗口往右移动了 160 字节，于是 SND.UNA 指针偏移了 160 后指向 601，可用窗口 Usable 也就增大至了 200。</li>
</ol>
<h2 id="操作系统缓冲区与滑动窗口的关系"><a href="#操作系统缓冲区与滑动窗口的关系" class="headerlink" title="操作系统缓冲区与滑动窗口的关系"></a>操作系统缓冲区与滑动窗口的关系</h2><p>前面的流量控制例子，我们假定了发送窗口和接收窗口是不变的，但是实际上，发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区中的，而操作系统的缓冲区，会被操作系统调整。</p>
<p>当应用进程没办法及时读取缓冲区的内容时，也会对我们的缓冲区造成影响。</p>
<h3 id="那操心系统的缓冲区，是如何影响发送窗口和接收窗口的呢？"><a href="#那操心系统的缓冲区，是如何影响发送窗口和接收窗口的呢？" class="headerlink" title="那操心系统的缓冲区，是如何影响发送窗口和接收窗口的呢？"></a>那操心系统的缓冲区，是如何影响发送窗口和接收窗口的呢？</h3><p>我们先来看看第一个例子。</p>
<p>当应用程序没有及时读取缓存时，发送窗口和接收窗口的变化。</p>
<p>考虑以下场景：</p>
<ul>
<li>客户端作为发送方，服务端作为接收方，发送窗口和接收窗口初始大小为 360；</li>
<li>服务端非常的繁忙，当收到客户端的数据时，应用层不能及时读取数据。</li>
</ul>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/19.jpg" class="">

<p>根据上图的流量控制，说明下每个过程：</p>
<ol>
<li>客户端发送 140 字节数据后，可用窗口变为 220 （360 - 140）。</li>
<li>服务端收到 140 字节数据，但是服务端非常繁忙，应用进程只读取了 40 个字节，还有 100 字节占用着缓冲区，于是接收窗口收缩到了 260 （360 - 100），最后发送确认信息时，将窗口大小通告给客户端。</li>
<li>客户端收到确认和窗口通告报文后，发送窗口减少为 260。</li>
<li>客户端发送 180 字节数据，此时可用窗口减少到 80。</li>
<li>服务端收到 180 字节数据，但是应用程序没有读取任何数据，这 180 字节直接就留在了缓冲区，于是接收窗口收缩到了 80 （260 - 180），并在发送确认信息时，通过窗口大小给客户端。</li>
<li>客户端收到确认和窗口通告报文后，发送窗口减少为 80。</li>
<li>客户端发送 80 字节数据后，可用窗口耗尽。</li>
<li>服务端收到 80 字节数据，但是应用程序依然没有读取任何数据，这 80 字节留在了缓冲区，于是接收窗口收缩到了 0，并在发送确认信息时，通过窗口大小给客户端。</li>
<li>客户端收到确认和窗口通告报文后，发送窗口减少为 0。</li>
</ol>
<p>可见最后窗口都收缩为 0 了，也就是发生了窗口关闭。当发送方可用窗口变为 0 时，发送方实际上会定时发送窗口探测报文，以便知道接收方的窗口是否发生了改变，这个内容后面会说，这里先简单提一下。</p>
<p>我们先来看看第二个例子。</p>
<p>当服务端系统资源非常紧张的时候，操心系统可能会直接减少了接收缓冲区大小，这时应用程序又无法及时读取缓存数据，那么这时候就有严重的事情发生了，会出现数据包丢失的现象。</p>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/20.jpg" class="">

<p>说明下每个过程：</p>
<ol>
<li>客户端发送 140 字节的数据，于是可用窗口减少到了 220。</li>
<li>服务端因为现在非常的繁忙，操作系统于是就把接收缓存减少了 120 字节，当收到 140 字节数据后，又因为应用程序没有读取任何数据，所以 140 字节留在了缓冲区中，于是接收窗口大小从 360 收缩成了 100，最后发送确认信息时，通告窗口大小给对方。</li>
<li>此时客户端因为还没有收到服务端的通告窗口报文，所以不知道此时接收窗口收缩成了 100，客户端只会看自己的可用窗口还有 220，所以客户端就发送了 180 字节数据，于是可用窗口减少到 40。</li>
<li>服务端收到了 180 字节数据时，发现数据大小超过了接收窗口的大小，于是就把数据包丢失了。</li>
<li>客户端收到第 2 步时，服务端发送的确认报文和通告窗口报文，尝试减少发送窗口到 100，把窗口的右端向左收缩了 80，此时可用窗口的大小就会出现诡异的负值。</li>
</ol>
<p>所以，如果发生了先减少缓存，再收缩窗口，就会出现丢包的现象。</p>
<p>为了防止这种情况发生，TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况。</p>
<h2 id="窗口关闭"><a href="#窗口关闭" class="headerlink" title="窗口关闭"></a>窗口关闭</h2><p>在前面我们都看到了，TCP 通过让接收方指明希望从发送方接收的数据大小（窗口大小）来进行流量控制。</p>
<p>如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。</p>
<h3 id="窗口关闭潜在的危险"><a href="#窗口关闭潜在的危险" class="headerlink" title="窗口关闭潜在的危险"></a>窗口关闭潜在的危险</h3><p>接收方向发送方通告窗口大小时，是通过 ACK 报文来通告的。</p>
<p>那么，当发生窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非 0 的<code>ACK</code>报文，如果这个通告窗口的 ACK 报文在网络中丢失了，那麻烦就大了。</p>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/21.jpg" class="">

<p>这会导致发送方一直等待接收方的非 0 窗口通知，接收方也一直等待发送方的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象。</p>
<h3 id="TCP-是如何解决窗口关闭时，潜在的死锁现象呢？"><a href="#TCP-是如何解决窗口关闭时，潜在的死锁现象呢？" class="headerlink" title="TCP 是如何解决窗口关闭时，潜在的死锁现象呢？"></a>TCP 是如何解决窗口关闭时，潜在的死锁现象呢？</h3><p>为了解决这个问题，TCP 为每个连接设有一个持续定时器，只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。</p>
<p>如果持续计时器超时，就会发送窗口探测 (<code>Window probe</code>) 报文，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。</p>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/22.jpg" class="">

<ul>
<li>如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器；</li>
<li>如果接收窗口不是 0，那么死锁的局面就可以被打破了。</li>
</ul>
<p>窗口探测的次数一般为 3 次，每次大约 30-60 秒（不同的实现可能会不一样）。如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 RST 报文来中断连接。</p>
<h2 id="糊涂窗口综合症"><a href="#糊涂窗口综合症" class="headerlink" title="糊涂窗口综合症"></a>糊涂窗口综合症</h2><p>如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。</p>
<p>到最后，如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症。</p>
<p>要知道，我们的 TCP + IP 头有 40 个字节，为了传输那几个字节的数据，要达上这么大的开销，这太不经济了。</p>
<p>就好像一个可以承载 50 人的大巴车，每次来了一两个人，就直接发车。除非家里有矿的大巴司机，才敢这样玩，不然迟早破产。要解决这个问题也不难，大巴司机等乘客数量超过了 25 个，才认定可以发车。</p>
<p>现举个糊涂窗口综合症的栗子，考虑以下场景：</p>
<p>接收方的窗口大小是 360 字节，但接收方由于某些原因陷入困境，假设接收方的应用层读取的能力如下：</p>
<ul>
<li>接收方每接收 3 个字节，应用程序就只能从缓冲区中读取 1 个字节的数据；</li>
<li>在下一个发送方的 TCP 段到达之前，应用程序还从缓冲区中读取了 40 个额外的字节；</li>
</ul>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/23.png" class="">

<p>每个过程的窗口大小的变化，在图中都描述的很清楚了，可以发现窗口不断减少了，并且发送的数据都是比较小的了。</p>
<p>所以，糊涂窗口综合症的现象是可以发生在发送方和接收方：</p>
<ul>
<li>接收方可以通告一个小的窗口</li>
<li>而发送方可以发送小数据</li>
</ul>
<p>于是，要解决糊涂窗口综合症，就解决上面两个问题就可以了</p>
<ul>
<li>让接收方不通告小窗口给发送方</li>
<li>让发送方避免发送小数据</li>
</ul>
<h3 id="怎么让接收方不通告小窗口呢？"><a href="#怎么让接收方不通告小窗口呢？" class="headerlink" title="怎么让接收方不通告小窗口呢？"></a>怎么让接收方不通告小窗口呢？</h3><p>接收方通常的策略如下:</p>
<p>当「窗口大小」小于 min( MSS，缓存空间&#x2F;2 ) ，也就是小于 MSS 与 1&#x2F;2 缓存大小中的最小值时，就会向发送方通告窗口为 0，也就阻止了发送方再发数据过来。</p>
<p>等到接收方处理了一些数据后，窗口大小 &gt;&#x3D; MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发送方发送数据过来。</p>
<h3 id="怎么让发送方避免发送小数据呢？"><a href="#怎么让发送方避免发送小数据呢？" class="headerlink" title="怎么让发送方避免发送小数据呢？"></a>怎么让发送方避免发送小数据呢？</h3><p>发送方通常的策略:</p>
<p>使用 Nagle 算法，该算法的思路是延时处理，它满足以下两个条件中的一条才可以发送数据：</p>
<ul>
<li>要等到窗口大小 &gt;&#x3D; MSS 或是 数据大小 &gt;&#x3D; MSS</li>
<li>收到之前发送数据的 ack 回包</li>
</ul>
<p>只要没满足上面条件中的一条，发送方一直在囤积数据，直到满足上面的发送条件。</p>
<p>另外，Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如，telnet 或 ssh 这样的交互性比较强的程序，则需要关闭 Nagle 算法。</p>
<p>可以在 Socket 设置<code>TCP_NODELAY</code>选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应用自己的特点来关闭）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">setsockopt(sock_fd, IPPROTO_TCP, TCP_NODELAY, (char *)&amp;value, sizeof(int));</span><br></pre></td></tr></table></figure>
<h1 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h1><h3 id="为什么要有拥塞控制呀，不是有流量控制了吗？"><a href="#为什么要有拥塞控制呀，不是有流量控制了吗？" class="headerlink" title="为什么要有拥塞控制呀，不是有流量控制了吗？"></a>为什么要有拥塞控制呀，不是有流量控制了吗？</h3><p>前面的流量控制是避免发送方的数据填满接收方的缓存，但是并不知道网络的中发生了什么。</p>
<p>一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。</p>
<p>在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大….</p>
<p>所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。</p>
<p>于是，就有了拥塞控制，控制的目的就是避免「发送方」的数据填满整个网络。</p>
<p>为了在「发送方」调节所要发送数据的量，定义了一个叫做「拥塞窗口」的概念。</p>
<h3 id="什么是拥塞窗口？和发送窗口有什么关系呢？"><a href="#什么是拥塞窗口？和发送窗口有什么关系呢？" class="headerlink" title="什么是拥塞窗口？和发送窗口有什么关系呢？"></a>什么是拥塞窗口？和发送窗口有什么关系呢？</h3><p>拥塞窗口<code>cwnd</code>是发送方维护的一个的状态变量，它会根据网络的拥塞程度动态变化的。</p>
<p>我们在前面提到过发送窗口 swnd 和接收窗口<code>rwnd</code>是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是<code>swnd = min(cwnd, rwnd)</code>，也就是拥塞窗口和接收窗口中的最小值。</p>
<p>拥塞窗口<code>cwnd</code>变化的规则：</p>
<ul>
<li>只要网络中没有出现拥塞，<code>cwnd</code>就会增大；</li>
<li>但网络中出现了拥塞，<code>cwnd</code>就减少；</li>
</ul>
<h3 id="那么怎么知道当前网络是否出现了拥塞呢？"><a href="#那么怎么知道当前网络是否出现了拥塞呢？" class="headerlink" title="那么怎么知道当前网络是否出现了拥塞呢？"></a>那么怎么知道当前网络是否出现了拥塞呢？</h3><p>其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是发生了超时重传，就会认为网络出现了用拥塞。</p>
<h3 id="拥塞控制有哪些控制算法？"><a href="#拥塞控制有哪些控制算法？" class="headerlink" title="拥塞控制有哪些控制算法？"></a>拥塞控制有哪些控制算法？</h3><p>拥塞控制主要是四个算法：</p>
<ul>
<li>慢启动</li>
<li>拥塞避免</li>
<li>拥塞发生</li>
<li>快速恢复</li>
</ul>
<h2 id="慢启动"><a href="#慢启动" class="headerlink" title="慢启动"></a>慢启动</h2><p>TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量，如果一上来就发大量的数据，这不是给网络添堵吗？</p>
<p>慢启动的算法记住一个规则就行：当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。</p>
<p>这里假定拥塞窗口<code>cwnd</code>和发送窗口<code>swnd</code>相等，下面举个栗子：</p>
<ul>
<li>连接建立完成后，一开始初始化<code>cwnd = 1</code>，表示可以传一个 MSS 大小的数据。</li>
<li>当收到一个 ACK 确认应答后，<code>cwnd</code>增加 1，于是一次能够发送 2 个</li>
<li>当收到 2 个的 ACK 确认应答后，<code>cwnd</code>增加 2，于是就可以比之前多发2 个，所以这一次能够发送 4 个</li>
<li>当这 4 个的 ACK 确认到来的时候，每个确认<code>cwnd</code>增加 1， 4 个确认<code>cwnd</code>增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个。</li>
</ul>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/23.jpg" class="">

<p>可以看出慢启动算法，发包的个数是指数性的增长。</p>
<h3 id="那慢启动涨到什么时候是个头呢？"><a href="#那慢启动涨到什么时候是个头呢？" class="headerlink" title="那慢启动涨到什么时候是个头呢？"></a>那慢启动涨到什么时候是个头呢？</h3><p>有一个叫慢启动门限<code>ssthresh （slow start threshold）</code>状态变量。</p>
<ul>
<li>当<code>cwnd &lt; ssthresh</code>时，使用慢启动算法。</li>
<li>当<code>cwnd &gt;= ssthresh</code>时，就会使用「拥塞避免算法」。</li>
</ul>
<h2 id="拥塞避免算法"><a href="#拥塞避免算法" class="headerlink" title="拥塞避免算法"></a>拥塞避免算法</h2><p>前面说道，当拥塞窗口 cwnd 「超过」慢启动门限<code>ssthresh</code>就会进入拥塞避免算法。</p>
<p>一般来说<code>ssthresh</code>的大小是 65535 字节。</p>
<p>那么进入拥塞避免算法后，它的规则是：每当收到一个 ACK 时，cwnd 增加 1&#x2F;cwnd。</p>
<p>接上前面的慢启动的栗子，现假定<code>ssthresh</code>为 8：</p>
<p>当 8 个 ACK 应答确认到来时，每个确认增加 1&#x2F;8，8 个 ACK 确认<code>cwnd</code>一共增加 1，于是这一次能够发送 9 个 MSS 大小的数据，变成了线性增长。</p>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/24.jpg" class="">

<p>所以，我们可以发现，拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。</p>
<p>就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。</p>
<p>当触发了重传机制，也就进入了「拥塞发生算法」。</p>
<h2 id="拥塞发生"><a href="#拥塞发生" class="headerlink" title="拥塞发生"></a>拥塞发生</h2><p>当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：</p>
<ul>
<li>超时重传</li>
<li>快速重传</li>
</ul>
<p>这两种使用的拥塞发送算法是不同的，接下来分别来说说。</p>
<h3 id="发生超时重传的拥塞发生算法"><a href="#发生超时重传的拥塞发生算法" class="headerlink" title="发生超时重传的拥塞发生算法"></a>发生超时重传的拥塞发生算法</h3><p>当发生了「超时重传」，则就会使用拥塞发生算法。</p>
<p>这个时候，<code>ssthresh</code>和<code>cwnd</code>的值会发生变化：</p>
<ul>
<li><code>ssthresh</code>设为 cwnd&#x2F;2，</li>
<li>cwnd 重置为 1</li>
</ul>
<img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/25.jpg" class="">

<p>接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是一旦「超时重传」，马上回到解放前。但是这种方式太激进了，反应也很强烈，会造成网络卡顿。</p>
<p>就好像本来在秋名山高速漂移着，突然来个紧急刹车，轮胎受得了吗。。。</p>
<h3 id="发生快速重传的拥塞发生算法"><a href="#发生快速重传的拥塞发生算法" class="headerlink" title="发生快速重传的拥塞发生算法"></a>发生快速重传的拥塞发生算法</h3><p>还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。</p>
<p>TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则<code>ssthresh</code>和 cwnd 变化如下：</p>
<ul>
<li><code>cwnd = cwnd/2</code>，也就是设置为原来的一半;</li>
<li><code>ssthresh = cwnd</code>;</li>
<li>进入快速恢复算法</li>
</ul>
<h2 id="快速恢复"><a href="#快速恢复" class="headerlink" title="快速恢复"></a>快速恢复</h2><p>快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 RTO 超时那么强烈。</p>
<p>正如前面所说，进入快速恢复之前，<code>cwnd</code>和<code>ssthresh</code>已被更新了：</p>
<ul>
<li><code>cwnd = cwnd/2</code>，也就是设置为原来的一半;</li>
<li><code>ssthresh = cwnd</code>;</li>
</ul>
<p>然后，进入快速恢复算法如下：</p>
<ul>
<li>拥塞窗口<code>cwnd = ssthresh + 3 </code>（ 3 的意思是确认有 3 个数据包被收到了）；</li>
<li>重传丢失的数据包；</li>
<li>如果再收到重复的<code>ACK</code>，那么<code>cwnd</code>增加 1；</li>
<li>如果收到新数据的<code>ACK</code>后，把<code>cwnd</code>设置为第一步中的<code>ssthresh</code>的值，原因是该 ACK 确认了新的数据，说明从<code>duplicated</code>ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；</li>
</ul>


<p>也就是没有像「超时重传」一夜回到解放前，而是还在比较高的值，后续呈线性增长。</p>
<h2 id="拥塞算法示意图"><a href="#拥塞算法示意图" class="headerlink" title="拥塞算法示意图"></a>拥塞算法示意图</h2><img src="/2022/01/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%20%E9%87%8D%E4%BC%A0%E3%80%81%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E3%80%81%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6%E3%80%81%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/27.png" class="">
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" rel="tag">计算机网络</a></li></ul>

    </footer>
  </div>

   
   
  
</article>

    
    <article
  id="post-计算机网络/TCP常见问题"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"
    >TCP常见问题</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/" class="article-date">
  <time datetime="2022-01-12T03:49:21.000Z" itemprop="datePublished">2022-01-12</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">计算机网络</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="在-Linux-系统中查看-TCP-状态"><a href="#在-Linux-系统中查看-TCP-状态" class="headerlink" title="在 Linux 系统中查看 TCP 状态"></a>在 Linux 系统中查看 TCP 状态</h1><p>在 Linux 可以通过<code>netstat -napt</code>命令查看 TCP 的连接状态。</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/9.png" class="">

<h1 id="有⼀个-IP-的服务器监听了⼀个端口，它的-TCP-的最⼤连接数是多少？"><a href="#有⼀个-IP-的服务器监听了⼀个端口，它的-TCP-的最⼤连接数是多少？" class="headerlink" title="有⼀个 IP 的服务器监听了⼀个端口，它的 TCP 的最⼤连接数是多少？"></a>有⼀个 IP 的服务器监听了⼀个端口，它的 TCP 的最⼤连接数是多少？</h1><p>服务器通常固定在某个本地端口上监听，等待客户端的连接请求。因此，客户端 IP 和端口是可变的，其理论值计算公式如下: </p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/2.png" class="">

<p>对 IPv4，客户端的 IP 数最多为 2 的 32 次方，客户端的端口数最多为 2 的 16 次方，也就是服务端单机最⼤ TCP 连接数，约为 2 的 48 次方。</p>
<p>当然，服务端最⼤并发 TCP 连接数远不能达到理论上限。</p>
<ul>
<li>首先主要是⽂件描述符限制，Socket 都是⽂件，所以首先要通过<code>ulimit</code>配置⽂件描述符的数⽬；</li>
<li>另⼀个是内存限制，每个 TCP 连接都要占用⼀定内存，操作系统的内存是有限的。</li>
</ul>
<h1 id="TCP-和-UDP-区别"><a href="#TCP-和-UDP-区别" class="headerlink" title="TCP 和 UDP 区别"></a>TCP 和 UDP 区别</h1><table>
<thead>
<tr>
<th></th>
<th>UDP</th>
<th>TCP</th>
</tr>
</thead>
<tbody><tr>
<td>是否连接</td>
<td>无连接</td>
<td>面向连接</td>
</tr>
<tr>
<td>是否可靠</td>
<td>不可靠传输，不使用流量控制和拥塞控制</td>
<td>可靠传输，使用流量控制和拥塞控制</td>
</tr>
<tr>
<td>连接对象个数</td>
<td>支持一对一，一对多，多对一和多对多交互通信</td>
<td>只能是一对一通信</td>
</tr>
<tr>
<td>传输方式</td>
<td>面向报文</td>
<td>面向字节流</td>
</tr>
<tr>
<td>首部开销</td>
<td>首部开销小，仅 8 字节</td>
<td>首部最小 20 字节，最大 60 字节</td>
</tr>
<tr>
<td>适用场景</td>
<td>适用于实时应用（IP 电话、视频会议、直播等）</td>
<td>适用于要求可靠传输的应用，例如文件传输</td>
</tr>
</tbody></table>
<h1 id="为什么-UDP-头部有「包长度」字段，而-TCP-头部则没有「包长度」字段呢？"><a href="#为什么-UDP-头部有「包长度」字段，而-TCP-头部则没有「包长度」字段呢？" class="headerlink" title="为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？"></a>为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？</h1><p>先说说 TCP 是如何计算负载数据长度：</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/4.png" class="">

<p>其中 IP 总长度 和 IP 首部长度，在 IP 首部格式是已知的。TCP 首部长度，则是在 TCP 首部格式已知的，所以就可以求得 TCP 数据的长度。</p>
<p>⼤家这时就奇怪了问：“ UDP 也是基于 IP 层的呀，那 UDP 的数据长度也可以通过这个公式计算呀？ 为何还要有「包长度」呢？”</p>
<p>这么⼀问，确实感觉 UDP 「包长度」是冗余的。</p>
<p>因为为了网络设备硬件设计和处理方便，首部长度需要是 4 字节的整数倍。</p>
<p>如果去掉 UDP 「包长度」字段，那 UDP 首部长度就不是 4 字节的整数倍了，所以这可能是为了补全 UDP 首部长度是 4 字节的整数倍，才补充了「包长度」字段。</p>
<h1 id="为什么客户端和服务端的初始序列号-ISN-是不相同的？"><a href="#为什么客户端和服务端的初始序列号-ISN-是不相同的？" class="headerlink" title="为什么客户端和服务端的初始序列号 ISN 是不相同的？"></a>为什么客户端和服务端的初始序列号 ISN 是不相同的？</h1><p>如果⼀个已经失效的连接被重用了，但是该旧连接的历史报⽂还残留在网络中，如果序列号相同，那么就⽆法分辨出该报⽂是不是历史报⽂，如果历史报⽂被新的连接接收了，则会产生数据错乱。</p>
<p>所以，每次建立连接前重新初始化⼀个序列号主要是为了通信双方能够根据序号将不属于本连接的报⽂段丢弃。</p>
<p>另⼀方⾯是为了安全性，防止⿊客伪造的相同序列号的 TCP 报⽂被对方接收。</p>
<h1 id="既然-IP-层会分片，为什么-TCP-层还需要-MSS-呢？"><a href="#既然-IP-层会分片，为什么-TCP-层还需要-MSS-呢？" class="headerlink" title="既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？"></a>既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？</h1><img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/14.jpg" class="">

<p>MTU：一个网络包的最大长度，以太网中一般为 1500 字节；</p>
<p>MSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；</p>
<p>如果在 TCP 的整个报文（头部 + 数据）交给 IP 层进行分片，会有什么异常呢？</p>
<p>当 IP 层有一个超过 MTU 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 MTU。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，再交给上一层 TCP 传输层。</p>
<p>这看起来井然有序，但这存在隐患，当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传。</p>
<p>因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。</p>
<p>当接收方发现 TCP 报文（头部 + 数据）的某一片丢失后，则不会响应 ACK 给对方，那么发送方的 TCP 在超时后，就会重发「整个 TCP 报文（头部 + 数据）」。</p>
<p>因此，可以得知由 IP 层进行分片传输，是非常没有效率的。</p>
<p>所以，为了达到最佳的传输效能 TCP 协议在建立连接的时候通常要协商双方的 MSS 值，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/15.jpg" class="">

<p>经过 TCP 层分片后，如果一个 TCP 分片丢失后，进行重发时也是以 MSS 为单位，而不用重传所有的分片，大大增加了重传的效率。</p>
<h1 id="什么是-SYN-攻击？如何避免-SYN-攻击？"><a href="#什么是-SYN-攻击？如何避免-SYN-攻击？" class="headerlink" title="什么是 SYN 攻击？如何避免 SYN 攻击？"></a>什么是 SYN 攻击？如何避免 SYN 攻击？</h1><p>我们都知道 TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 SYN 报文，服务端每接收到一个 SYN 报文，就进入SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，无法得到未知 IP 主机的 ACK 应答，久而久之就会占满服务端的 SYN 接收队列（未连接队列），使得服务器不能为正常用户服务。</p>
<h2 id="避免-SYN-攻击方式一"><a href="#避免-SYN-攻击方式一" class="headerlink" title="避免 SYN 攻击方式一"></a>避免 SYN 攻击方式一</h2><p>其中一种解决方式是通过修改 Linux 内核参数，控制队列大小和当队列满时应做什么处理。</p>
<p>当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。控制该队列的最大值如下参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.core.netdev_max_backlog</span><br></pre></td></tr></table></figure>
<p>SYN_RCVD 状态连接的最大个数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_max_syn_backlog</span><br></pre></td></tr></table></figure>
<p>超出处理能时，对新的 SYN 直接回报 RST，丢弃连接：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_abort_on_overflow</span><br></pre></td></tr></table></figure>
<h2 id="避免-SYN-攻击方式二"><a href="#避免-SYN-攻击方式二" class="headerlink" title="避免 SYN 攻击方式二"></a>避免 SYN 攻击方式二</h2><p>我们先来看下 Linux 内核的 SYN （未完成连接建立）队列与 Accpet （已完成连接建立）队列是如何工作的？</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/16.jpg" class="">

<p>正常流程：</p>
<ul>
<li>当服务端接收到客户端的 SYN 报文时，会将其加入到内核的 SYN 队列；</li>
<li>接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文；</li>
<li>服务端接收到 ACK 报文后，从 SYN 队列移除放入到<code>Accept</code>队列；</li>
<li>应用通过调用<code>accpet()</code> socket 接口，从<code>Accept</code>队列取出连接。</li>
</ul>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/17.jpg" class="">

<p>应用程序过慢：</p>
<ul>
<li>如果应用程序过慢时，就会导致<code>Accept</code>队列被占满。</li>
</ul>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/18.jpg" class="">

<p>受到 SYN 攻击：</p>
<ul>
<li>如果不断受到 SYN 攻击，就会导致 SYN 队列被占满。</li>
</ul>
<p><code>tcp_syncookies</code>的方式可以应对 SYN 攻击的方法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_syncookies = 1</span><br></pre></td></tr></table></figure>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/19.jpg" class="">

<ul>
<li>当 SYN 队列满之后，后续服务器收到<code>SYN</code>包，不进入<code>SYN</code>队列；</li>
<li>计算出一个 cookie 值，再以<code>SYN + ACK</code>中的序列号返回客户端，</li>
<li>服务端接收到客户端的应答报文时，服务器会检查这个<code>ACK</code>包的合法性。如果合法，直接放入到<code>Accept</code>队列。</li>
<li>最后应用通过调用<code>accpet()</code> socket 接口，从<code>Accept</code>队列取出的连接。</li>
</ul>
<h1 id="TIME-WAIT-过多有什么危害？"><a href="#TIME-WAIT-过多有什么危害？" class="headerlink" title="TIME_WAIT 过多有什么危害？"></a>TIME_WAIT 过多有什么危害？</h1><p>如果服务器有处于<code>TIME-WAIT</code>状态的 TCP，则说明是由服务器方主动发起的断开请求。</p>
<p>过多的<code>TIME-WAIT</code>状态主要的危害有两种：</p>
<ul>
<li>第一是内存资源占用；</li>
<li>第二是对端口资源的占用，一个 TCP 连接至少消耗一个本地端口；</li>
</ul>
<p>第二个危害是会造成严重的后果的，要知道，端口资源也是有限的，一般可以开启的端口为 32768～61000，也可以通过如下参数设置指定</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.ip_local_port_range</span><br></pre></td></tr></table></figure>
<p>如果发起连接一方的<code>TIME_WAIT</code>状态过多，占满了所有端口资源，则会导致无法创建新连接。</p>
<p>客户端受端口资源限制：</p>
<p>客户端<code>TIME_WAIT</code>过多，就会导致端口资源被占用，因为端口就65536个，被占满就会导致无法创建新的连接。</p>
<p>服务端受系统资源限制：</p>
<p>由于一个四元组表示 TCP 连接，理论上服务端可以建立很多连接，服务端确实只监听一个端口 但是会把连接扔给处理线程，所以理论上监听的端口可以继续监听。但是线程池处理不了那么多一直不断的连接了。所以当服务端出现大量<code>TIME_WAIT</code>时，系统资源被占满时，会导致处理不过来新的连接。</p>
<h1 id="如何优化-TIME-WAIT？"><a href="#如何优化-TIME-WAIT？" class="headerlink" title="如何优化 TIME_WAIT？"></a>如何优化 TIME_WAIT？</h1><p>这里给出优化<code>TIME-WAIT</code>的几个方式，都是有利有弊：</p>
<ul>
<li>打开<code>net.ipv4.tcptwreuse</code>和<code>net.ipv4.tcp_timestamps</code>选项；</li>
<li><code>net.ipv4.tcpmaxtw_buckets</code></li>
<li>程序中使用<code>SO_LINGER</code>，应用强制使用 RST 关闭。</li>
</ul>
<h2 id="方式一：net-ipv4-tcptwreuse和tcp-timestamps"><a href="#方式一：net-ipv4-tcptwreuse和tcp-timestamps" class="headerlink" title="方式一：net.ipv4.tcptwreuse和tcp_timestamps"></a>方式一：<code>net.ipv4.tcptwreuse</code>和<code>tcp_timestamps</code></h2><p>如下的 Linux 内核参数开启后，则可以复用处于<code>TIME_WAIT</code>的<code>socket</code>为新的连接所用。</p>
<p>有一点需要注意的是，<code>tcptwreuse</code>功能只能用客户端（连接发起方），因为开启了该功能，在调用<code>connect()</code>函数时，内核会随机找一个<code>time_wait</code>状态超过 1 秒的连接给新的连接复用。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br></pre></td></tr></table></figure>
<p>使用这个选项，还有一个前提，需要打开对 TCP 时间戳的支持，即</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_timestamps=1（默认即为 1）</span><br></pre></td></tr></table></figure>
<p>这个时间戳的字段是在 TCP 头部的「选项」里，用于记录 TCP 发送方的当前时间戳和从对端接收到的最新时间戳。</p>
<p>由于引入了时间戳，我们在前面提到的 2MSL 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃。</p>
<h2 id="方式二：net-ipv4-tcpmaxtw-buckets"><a href="#方式二：net-ipv4-tcpmaxtw-buckets" class="headerlink" title="方式二：net.ipv4.tcpmaxtw_buckets"></a>方式二：net.ipv4.tcpmaxtw_buckets</h2><p>这个值默认为 18000，当系统中处于<code>TIMEWAIT</code>的连接一旦超过这个值时，系统就会将后面的<code>TIMEWAIT</code>连接状态重置。</p>
<p>这个方法过于暴力，而且治标不治本，带来的问题远比解决的问题多，不推荐使用。</p>
<h2 id="方式三：程序中使用-SO-LINGER"><a href="#方式三：程序中使用-SO-LINGER" class="headerlink" title="方式三：程序中使用 SO_LINGER"></a>方式三：程序中使用 SO_LINGER</h2><p>我们可以通过设置<code>socket</code>选项，来设置调用<code>close</code>关闭连接行为。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">struct linger so_linger;</span><br><span class="line">so_linger.l_onoff = 1;</span><br><span class="line">so_linger.l_linger = 0;</span><br><span class="line">setsockopt(s, SOL_SOCKET, SO_LINGER, &amp;so_linger,sizeof(so_linger));</span><br></pre></td></tr></table></figure>
<p>如果<code>l_onoff</code>为非 0，且<code>l_linger</code>值为 0，那么调用<code>close</code>后，会立该发送一个<code>RST</code>标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了<code>TIME_WAIT</code>状态，直接关闭。</p>
<p>但这为跨越<code>TIME_WAIT</code>状态提供了一个可能，不过是一个非常危险的行为，不值得提倡。</p>
<h1 id="如果已经建立了连接，但是客户端突然出现故障了怎么办？"><a href="#如果已经建立了连接，但是客户端突然出现故障了怎么办？" class="headerlink" title="如果已经建立了连接，但是客户端突然出现故障了怎么办？"></a>如果已经建立了连接，但是客户端突然出现故障了怎么办？</h1><p>TCP 有一个机制是保活机制。这个机制的原理是这样的：<br>定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。</p>
<p>在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_keepalive_time=7200</span><br><span class="line">net.ipv4.tcp_keepalive_intvl=75  </span><br><span class="line">net.ipv4.tcp_keepalive_probes=9</span><br></pre></td></tr></table></figure>
<ul>
<li><code>tcpkeepalivetime=7200</code>：表示保活时间是 7200 秒（2小时），也就 2 小时内如果没有任何连接相关的活动，则会启动保活机制</li>
<li><code>tcpkeepaliveintvl=75</code>：表示每次检测间隔 75 秒；</li>
<li><code>tcpkeepaliveprobes=9</code>：表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。</li>
</ul>
<p>也就是说在 Linux 系统中，最少需要经过2小时11分15秒才可以发现一个死亡连接。</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/23.jpg" class="">

<p>这个时间是有点长的，我们也可以根据实际的需求，对以上的保活相关的参数进行设置。</p>
<p>如果开启了 TCP 保活，需要考虑以下几种情况：<br>第一种，对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 TCP 保活时间会被重置，等待下一个 TCP 保活时间的到来。</p>
<p>第二种，对端程序崩溃并重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，会产生一个 RST 报文，这样很快就会发现 TCP 连接已经被重置。</p>
<p>第三种，是对端程序崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡。</p>
<h1 id="Socket-编程"><a href="#Socket-编程" class="headerlink" title="Socket 编程"></a>Socket 编程</h1><p>针对 TCP 应该如何 Socket 编程？</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/24.jpg" class="">

<ul>
<li>服务端和客户端初始化<code>socket</code>，得到文件描述符；</li>
<li>服务端调用<code>bind</code>，将绑定在 IP 地址和端口;</li>
<li>服务端调用<code>listen</code>，进行监听；</li>
<li>服务端调用<code>accept</code>，等待客户端连接；</li>
<li>客户端调用<code>connect</code>，向服务器端的地址和端口发起连接请求；</li>
<li>服务端<code>accept</code>返回用于传输的<code>socket</code>的文件描述符；</li>
<li>客户端调用<code>write</code>写入数据；服务端调用<code>read</code> 读取数据；</li>
<li>客户端断开连接时，会调用<code>close</code>，那么服务端<code>read</code>读取数据的时候，就会读取到了 EOF，待处理完数据后，服务端调用<code>close</code>，表示连接关闭。</li>
</ul>
<p>这里需要注意的是，服务端调用<code>accept</code>时，连接成功了会返回一个已完成连接的<code>socket</code>，后续用来传输数据。</p>
<p>所以，监听的<code>socket</code>和真正用来传送数据的<code>socket</code>，是两个<code>socket</code>，一个叫作监听<code>socket</code>，一个叫作已完成连接<code>socket</code>。</p>
<p>成功连接建立之后，双方开始通过<code>read</code>和<code>write</code>函数来读写数据，就像往一个文件流里面写东西一样。</p>
<h2 id="listen-时候参数-backlog-的意义？"><a href="#listen-时候参数-backlog-的意义？" class="headerlink" title="listen 时候参数 backlog 的意义？"></a>listen 时候参数 backlog 的意义？</h2><p>Linux内核中会维护两个队列：</p>
<ul>
<li>未完成连接队列（SYN 队列）：接收到一个 SYN 建立连接请求，处于 SYN_RCVD 状态；</li>
<li>已完成连接队列（Accpet 队列）：已完成 TCP 三次握手过程，处于 ESTABLISHED 状态；</li>
</ul>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/25.jpg" class="">
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int listen (int socketfd, int backlog)</span><br></pre></td></tr></table></figure>
<ul>
<li>参数一<code>socketfd</code>为<code>socketfd</code>文件描述符</li>
<li>参数二<code>backlog</code>，这参数在历史版本有一定的变化</li>
</ul>
<p>在早期 Linux 内核<code>backlog</code>是 SYN 队列大小，也就是未完成的队列大小。</p>
<p>在 Linux 内核 2.2 之后，<code>backlog</code>变成<code>accept</code>队列，也就是已完成连接建立的队列长度，所以现在通常认为<code>backlog</code>是<code>accept</code>队列。</p>
<p>但是上限值是内核参数<code>somaxconn</code>的大小，也就说<code>accpet</code>队列长度 &#x3D; <code>min(backlog, somaxconn)</code>。</p>
<h2 id="accept-发生在三次握手的哪一步？"><a href="#accept-发生在三次握手的哪一步？" class="headerlink" title="accept 发生在三次握手的哪一步？"></a>accept 发生在三次握手的哪一步？</h2><p>我们先看看客户端连接服务端时，发送了什么？</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/26.jpg" class="">

<ul>
<li>客户端的协议栈向服务器端发送了 SYN 包，并告诉服务器端当前发送序列号<code>client_isn</code>，客户端进入 SYNSENT 状态；</li>
<li>服务器端的协议栈收到这个包之后，和客户端进行 ACK 应答，应答的值为<code>client_isn+1</code>，表示对 SYN 包<code>client_isn</code>的确认，同时服务器也发送一个 SYN 包，告诉客户端当前我的发送序列号为<code>server_isn</code>，服务器端进入 SYNRCVD 状态；<br>客户端协议栈收到 ACK 之后，使得应用程序从<code>connect</code>调用返回，表示客户端到服务器端的单向连接建立成功，客户端的状态为 ESTABLISHED，同时客户端协议栈也会对服务器端的 SYN 包进行应答，应答数据为 <code>server_isn+1</code>；</li>
<li>应答包到达服务器端后，服务器端协议栈使得<code>accept</code>阻塞调用返回，这个时候服务器端到客户端的单向连接也建立成功，服务器端也进入 ESTABLISHED 状态。</li>
</ul>
<p>从上面的描述过程，我们可以得知客户端<code>connect</code>成功返回是在第二次握手，服务端<code>accept</code>成功返回是在三次握手成功之后。</p>
<h2 id="客户端调用-close-了，断开的流程是什么？"><a href="#客户端调用-close-了，断开的流程是什么？" class="headerlink" title="客户端调用 close 了，断开的流程是什么？"></a>客户端调用 close 了，断开的流程是什么？</h2><p>我们看看客户端主动调用了 close，会发生什么？</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/27.jpg" class="">

<ul>
<li>客户端调用<code>close</code>，表明客户端没有数据需要发送了，则此时会向服务端发送<code>FIN</code>报文，进入<code>FINWAIT1</code>状态；</li>
<li>服务端接收到了<code>FIN</code>报文，TCP 协议栈会为<code>FIN</code>包插入一个文件结束符<code>EOF</code>到接收缓冲区中，应用程序可以通过<code>read</code>调用来感知这个<code>FIN</code>包。这个<code>EOF</code>会被放在已排队等候的其他已接收的数据之后，这就意味着服务端需要处理这种异常情况，因为<code>EOF</code>表示在该连接上再无额外数据到达。此时，服务端进入<code>CLOSE_WAIT</code>状态；</li>
<li>接着，当处理完数据后，自然就会读到<code>EOF</code>，于是也调用<code>close</code>关闭它的套接字，这会使得客户端会发出一个<code>FIN</code>包，之后处于<code>LAST_ACK</code>状态；</li>
<li>客户端接收到服务端的<code>FIN</code>包，并发送<code>ACK</code>确认包给服务端，此时客户端将进入<code>TIME_WAIT</code>状态；</li>
<li>服务端收到<code>ACK</code>确认包后，就进入了最后的<code>CLOSE</code>状态；</li>
<li>客户端经过 2MSL 时间之后，也进入<code>CLOSE</code>状态。</li>
</ul>
<h1 id="TCP-四次挥手，可以变成三次吗？"><a href="#TCP-四次挥手，可以变成三次吗？" class="headerlink" title="TCP 四次挥手，可以变成三次吗？"></a>TCP 四次挥手，可以变成三次吗？</h1><p>TCP 四次挥手中，能不能把第二次的 ACK 报文， 放到第三次<code>FIN</code>报文一起发送？</p>
<p>虽然我们在学习 TCP 挥手时，学到的是需要四次来完成 TCP 挥手，但是在一些情况下，TCP 四次挥手是可以变成 TCP 三次挥手的。</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/31.png" class="">

<h2 id="TCP-四次挥手"><a href="#TCP-四次挥手" class="headerlink" title="TCP 四次挥手"></a>TCP 四次挥手</h2><p>TCP 四次挥手的过程如下：</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/32.png" class="">

<p>具体过程：</p>
<ul>
<li>客户端主动调用关闭连接的函数，于是就会发送<code>FIN</code>报文，这个<code>FIN</code>报文代表客户端不会再发送数据了，进入<code>FIN_WAIT_1</code>状态；</li>
<li>服务端收到了<code>FIN</code>报文，然后马上回复一个<code>ACK</code>确认报文，此时服务端进入<code>CLOSE_WAIT</code>状态。在收到<code>FIN</code>报文的时候，TCP 协议栈会为<code>FIN</code>包插入一个文件结束符<code>EOF</code>到接收缓冲区中，服务端应用程序可以通过<code>read</code>调用来感知这个<code>FIN</code>包，这个<code>EOF</code>会被放在已排队等候的其他已接收的数据之后，所以必须要得继续<code>read</code>接收缓冲区已接收的数据；</li>
<li>接着，当服务端在<code>read</code>数据的时候，最后自然就会读到<code>EOF</code>，接着<code>read()</code>就会返回 0，这时服务端应用程序如果有数据要发送的话，就发完数据后才调用关闭连接的函数，如果服务端应用程序没有数据要发送的话，可以直接调用关闭连接的函数，这时服务端就会发一个<code>FIN</code>包，这个<code>FIN</code>报文代表服务端不会再发送数据了，之后处于<code>LAST_ACK</code>状态；</li>
<li>客户端接收到服务端的<code>FIN</code>包，并发送<code>ACK</code>确认包给服务端，此时客户端将进入<code>TIME_WAIT</code>状态；</li>
<li>服务端收到<code>ACK</code>确认包后，就进入了最后的<code>CLOSE</code>状态；</li>
<li>客户端经过<code>2MSL</code>时间之后，也进入<code>CLOSE</code>状态；</li>
</ul>
<p>你可以看到，每个方向都需要一个<code>FIN</code>和一个<code>ACK</code>，因此通常被称为四次挥手。</p>
<h2 id="为什么-TCP-挥手需要四次呢？"><a href="#为什么-TCP-挥手需要四次呢？" class="headerlink" title="为什么 TCP 挥手需要四次呢？"></a>为什么 TCP 挥手需要四次呢？</h2><p>服务器收到客户端的<code>FIN</code>报文时，内核会马上回一个<code>ACK</code>应答报文，但是服务端应用程序可能还有数据要发送，所以并不能马上发送<code>FIN</code>报文，而是将发送<code>FIN</code>报文的控制权交给服务端应用程序：</p>
<ul>
<li>如果服务端应用程序有数据要发送的话，就发完数据后，才调用关闭连接的函数；</li>
<li>如果服务端应用程序没有数据要发送的话，可以直接调用关闭连接的函数，</li>
</ul>
<p>从上面过程可知，是否要发送第三次挥手的控制权不在内核，而是在被动关闭方（服务端）的应用程序，因为应用程序可能还有数据要发送，由应用程序决定什么时候调用关闭连接的函数，当调用了关闭连接的函数，内核就会发送<code>FIN</code>报文了，所以服务端的<code>ACK</code>和<code>FIN</code>一般都会分开发送。</p>
<p><code>FIN</code>报文一定得调用关闭连接的函数，才会发送吗？</p>
<p>不一定。</p>
<p>如果进程退出了，不管是不是正常退出，还是异常退出（如进程崩溃），内核都会发送<code>FIN</code>报文，与对方完成四次挥手。</p>
<h2 id="粗暴关闭-vs-优雅关闭"><a href="#粗暴关闭-vs-优雅关闭" class="headerlink" title="粗暴关闭 vs 优雅关闭"></a>粗暴关闭 vs 优雅关闭</h2><p>其实关闭的连接的函数有两种函数：</p>
<ul>
<li><code>close</code>函数，同时<code>socket</code>关闭发送方向和读取方向，也就是<code>socket</code>不再有发送和接收数据的能力。如果有多进程&#x2F;多线程共享同一个<code>socket</code>，如果有一个进程调用了<code>close</code>关闭只是让<code>socket</code>引用计数 -1，并不会导致<code>socket</code>不可用，同时也不会发出<code>FIN</code>报文，其他进程还是可以正常读写该<code>socket</code>，直到引用计数变为 0，才会发出 FIN 报文。</li>
<li><code>shutdown</code>函数，可以指定<code>socket</code>只关闭发送方向而不关闭读取方向，也就是<code>socket</code>不再有发送数据的能力，但是还是具有接收数据的能力。如果有多进程&#x2F;多线程共享同一个<code>socket</code>，<code>shutdown</code>则不管引用计数，直接使得该<code>socket</code>不可用，然后发出<code>FIN</code>报文，如果有别的进程企图使用该<code>socket</code>，将会受到影响。</li>
</ul>
<p>如果客户端是用<code>close</code>函数来关闭连接，那么在 TCP 四次挥手过程中，如果收到了服务端发送的数据，由于客户端已经不再具有发送和接收数据的能力，所以客户端的内核会回<code>RST</code>报文给服务端，然后内核会释放连接，这时就不会经历完成的 TCP 四次挥手，所以我们常说，调用<code>close</code>是粗暴的关闭。</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/33.png" class="">

<p>当服务端收到 RST 后，内核就会释放连接，当服务端应用程序再次发起读操作或者写操作时，就能感知到连接已经被释放了：</p>
<ul>
<li>如果是读操作，则会返回 RST 的报错，也就是我们常见的<code>Connection reset by peer</code>。</li>
<li>如果是写操作，那么程序会产生<code>SIGPIPE</code>信号，应用层代码可以捕获并处理信号，如果不处理，则默认情况下进程会终止，异常退出。</li>
</ul>
<p>相对的，<code>shutdown</code>函数因为可以指定只关闭发送方向而不关闭读取方向，所以即使在 TCP 四次挥手过程中，如果收到了服务端发送的数据，客户端也是可以正常读取到该数据的，然后就会经历完整的 TCP 四次挥手，所以我们常说，调用<code>shutdown</code>是优雅的关闭。</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/34.png" class="">

<p>但是注意，<code>shutdown</code>函数也可以指定「只关闭读取方向，而不关闭发送方向」，但是这时候内核是不会发送<code>FIN</code>报文的，因为发送<code>FIN</code>报文是意味着我方将不再发送任何数据，而<code>shutdown</code>如果指定「不关闭发送方向」，就意味着<code>socket</code>还有发送数据的能力，所以内核就不会发送<code>FIN</code>。</p>
<h2 id="什么情况会出现三次挥手？"><a href="#什么情况会出现三次挥手？" class="headerlink" title="什么情况会出现三次挥手？"></a>什么情况会出现三次挥手？</h2><p>当被动关闭方（上图的服务端）在 TCP 挥手过程中，「没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/31.png" class="">

<p>然后因为 TCP 延迟确认机制是默认开启的，所以导致我们抓包时，看见三次挥手的次数比四次挥手还多。</p>
<h2 id="TCP-延迟确认机制"><a href="#TCP-延迟确认机制" class="headerlink" title="TCP 延迟确认机制"></a>TCP 延迟确认机制</h2><p>当发送没有携带数据的<code>ACK</code>，它的网络效率也是很低的，因为它也有 40 个字节的 IP 头 和 TCP 头，但却没有携带数据报文。 为了解决<code>ACK</code>传输效率低问题，所以就衍生出了 TCP 延迟确认。 TCP 延迟确认的策略：</p>
<ul>
<li>当有响应数据要发送时，<code>ACK</code>会随着响应数据一起立刻发送给对方</li>
<li>当没有响应数据要发送时，<code>ACK</code>将会延迟一段时间，以等待是否有响应数据可以一起发送</li>
<li>如果在延迟等待发送<code>ACK</code>期间，对方的第二个数据报文又到达了，这时就会立刻发送<code>ACK</code></li>
</ul>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/35.png" class="">

<p>延迟等待的时间是在 Linux 内核中定义的：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#define TCP_DELACK_MAX((unsigned)(HZ/5)) # 最大延迟确认时间</span><br><span class="line">#define TCP_DELACK_MN((unsigned)(HZ/25)) # 最小延迟确认时间</span><br></pre></td></tr></table></figure>
<p>关键就需要 HZ 这个数值大小，HZ 是跟系统的时钟频率有关，每个操作系统都不一样，在我的 Linux 系统中 HZ 大小是 250，如下图：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat /boot/config-5.15.0-69-generic | grep &#x27;^CONFIG_HZ=&#x27;</span><br><span class="line"></span><br><span class="line">CONFIG_HZ=250</span><br></pre></td></tr></table></figure>
<p>知道了 HZ 的大小，那么就可以算出：</p>
<ul>
<li>最大延迟确认时间是 50 ms （250&#x2F;5）</li>
<li>最短延迟确认时间是 10 ms （250&#x2F;25）</li>
</ul>
<p>怎么关闭 TCP 延迟确认机制？</p>
<p>如果要关闭 TCP 延迟确认机制，可以在<code>Socket</code>设置里启用<code>TCP_QUICKACK</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// 1 表示开启 TCP_QUICKACK，即关闭 TCP 延迟确认机制</span><br><span class="line">int value = 1;</span><br><span class="line">setsockopt(socketfd, IPPROTO_TCP, TCP_QUICKACK, (char*)&amp; value, sizeof(int));</span><br></pre></td></tr></table></figure>
<h1 id="拔掉网线后，-原本的-TCP-连接还存在吗？"><a href="#拔掉网线后，-原本的-TCP-连接还存在吗？" class="headerlink" title="拔掉网线后， 原本的 TCP 连接还存在吗？"></a>拔掉网线后， 原本的 TCP 连接还存在吗？</h1><p>TCP 连接在 Linux 内核中是一个名为<code>struct socket</code>的结构体，该结构体的内容包含 TCP 连接的状态等信息。当拔掉网线的时候，操作系统并不会变更该结构体的任何内容，所以 TCP 连接的状态也不会发生改变。</p>
<p>拔掉网线这个动作并不会影响 TCP 连接的状态。</p>
<p>接下来，要看拔掉网线后，双方做了什么动作。</p>
<p>所以， 针对这个问题，要分场景来讨论：</p>
<ul>
<li>拔掉网线后，有数据传输；</li>
<li>拔掉网线后，没有数据传输；</li>
</ul>
<h2 id="拔掉网线后，有数据传输"><a href="#拔掉网线后，有数据传输" class="headerlink" title="拔掉网线后，有数据传输"></a>拔掉网线后，有数据传输</h2><p>在客户端拔掉网线后，服务端向客户端发送的数据报文会得不到任何的响应，在等待一定时长后，服务端就会触发超时重传机制，重传未得到响应的数据报文。</p>
<p>如果在服务端重传报文的过程中，客户端刚好把网线插回去了，由于拔掉网线并不会改变客户端的 TCP 连接状态，并且还是处于<code>ESTABLISHED</code>状态，所以这时客户端是可以正常接收服务端发来的数据报文的，然后客户端就会回 ACK 响应报文。</p>
<p>此时，客户端和服务端的 TCP 连接依然存在的，就感觉什么事情都没有发生。</p>
<p>但是，如果如果在服务端重传报文的过程中，客户端一直没有将网线插回去，服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开。</p>
<p>而等客户端插回网线后，如果客户端向服务端发送了数据，由于服务端已经没有与客户端相同四元祖的 TCP 连接了，因此服务端内核就会回复 RST 报文，客户端收到后就会释放该 TCP 连接。</p>
<p>此时，客户端和服务端的 TCP 连接都已经断开了。</p>
<p>那 TCP 的数据报文具体重传几次呢？</p>
<p>在 Linux 系统中，提供了一个叫<code>tcp_retries2</code>配置项，默认值是 15，如下图：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># cat /proc/sys/net/ipv4/tcp_retries2</span></span><br><span class="line">15</span><br></pre></td></tr></table></figure>
<p>这个内核参数是控制，在 TCP 连接建立的情况下，超时重传的最大次数。</p>
<p>不过 tcp_retries2 设置了 15 次，并不代表 TCP 超时重传了 15 次才会通知应用程序终止该 TCP 连接，内核还会基于「最大超时时间」来判定。</p>
<p>每一轮的超时时间都是倍数增长的，比如第一次触发超时重传是在 2s 后，第二次则是在 4s 后，第三次则是 8s 后，以此类推。</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/40.png" class="">

<p>内核会根据 tcp_retries2 设置的值，计算出一个最大超时时间。</p>
<p>在重传报文且一直没有收到对方响应的情况时，先达到「最大重传次数」或者「最大超时时间」这两个的其中一个条件后，就会停止重传，然后就会断开 TCP 连接。</p>
<h2 id="拔掉网线后，没有数据传输"><a href="#拔掉网线后，没有数据传输" class="headerlink" title="拔掉网线后，没有数据传输"></a>拔掉网线后，没有数据传输</h2><p>针对拔掉网线后，没有数据传输的场景，还得看是否开启了 TCP keepalive 机制 （TCP 保活机制）。</p>
<p>如果没有开启 TCP keepalive 机制，在客户端拔掉网线后，并且双方都没有进行数据传输，那么客户端和服务端的 TCP 连接将会一直保持存在。</p>
<p>而如果开启了 TCP keepalive 机制，在客户端拔掉网线后，即使双方都没有进行数据传输，在持续一段时间后，TCP 就会发送探测报文：</p>
<p>如果对端是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 TCP 保活时间会被重置，等待下一个 TCP 保活时间的到来。<br>如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡。<br>所以，TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活。</p>
<p>TCP keepalive 机制具体是怎么样的？</p>
<p>这个机制的原理是这样的：</p>
<p>定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。</p>
<p>在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_keepalive_time=7200</span><br><span class="line">net.ipv4.tcp_keepalive_intvl=75  </span><br><span class="line">net.ipv4.tcp_keepalive_probes=9</span><br></pre></td></tr></table></figure>
<ul>
<li><code>tcp_keepalive_time=7200</code>：表示保活时间是 7200 秒（2小时），也就 2 小时内如果没有任何连接相关的活动，则会启动保活机制</li>
<li><code>tcp_keepalive_intvl=75</code>：表示每次检测间隔 75 秒；</li>
<li><code>tcp_keepalive_probes=9</code>：表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。</li>
</ul>
<p>也就是说在 Linux 系统中，最少需要经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接。</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/41.png" class="">

<p>注意，应用程序若想使用 TCP 保活机制需要通过 socket 接口设置 SO_KEEPALIVE 选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。</p>
<p>TCP keepalive 机制探测的时间也太长了吧？</p>
<p>对的，是有点长。</p>
<p>TCP keepalive  是 TCP 层（内核态） 实现的，它是给所有基于 TCP 传输协议的程序一个兜底的方案。</p>
<p>实际上，我们应用层可以自己实现一套探测机制，可以在较短的时间内，探测到对方是否存活。</p>
<p>比如，web 服务软件一般都会提供<code>keepalive_timeout</code>参数，用来指定 HTTP 长连接的超时时间。如果设置了 HTTP 长连接的超时时间是 60 秒，web 服务软件就会启动一个定时器，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，就会触发回调函数来释放该连接。</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/42.png" class="">

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>客户端拔掉网线后，并不会直接影响 TCP 连接状态。所以，拔掉网线后，TCP 连接是否还会存在，关键要看拔掉网线之后，有没有进行数据传输。</p>
<p>有数据传输的情况：</p>
<ul>
<li>在客户端拔掉网线后，如果服务端发送了数据报文，那么在服务端重传次数没有达到最大值之前，客户端就插回了网线，那么双方原本的 TCP 连接还是能正常存在，就好像什么事情都没有发生。</li>
<li>在客户端拔掉网线后，如果服务端发送了数据报文，在客户端插回网线之前，服务端重传次数达到了最大值时，服务端就会断开 TCP 连接。等到客户端插回网线后，向服务端发送了数据，因为服务端已经断开了与客户端相同四元组的 TCP 连接，所以就会回 RST 报文，客户端收到后就会断开 TCP 连接。至此， 双方的 TCP 连接都断开了。</li>
</ul>
<p>没有数据传输的情况：</p>
<ul>
<li>如果双方都没有开启 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，那么客户端和服务端的 TCP 连接状态将会一直保持存在。</li>
<li>如果双方都开启了 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，TCP keepalive 机制会探测到对方的 TCP 连接没有存活，于是就会断开 TCP 连接。而如果在 TCP 探测期间，客户端插回了网线，那么双方原本的 TCP 连接还是能正常存在。</li>
</ul>
<p>除了客户端拔掉网线的场景，还有客户端「宕机和杀死进程」的两种场景。</p>
<p>第一个场景，客户端宕机这件事跟拔掉网线是一样无法被服务端的感知的，所以如果在没有数据传输，并且没有开启 TCP keepalive 机制时，，服务端的 TCP 连接将会一直处于<code>ESTABLISHED</code>连接状态，直到服务端重启进程。</p>
<p>所以，我们可以得知一个点。在没有使用 TCP 保活机制，且双方不传输数据的情况下，一方的 TCP 连接处在<code>ESTABLISHED</code>状态时，并不代表另一方的 TCP 连接还一定是正常的。</p>
<p>第二个场景，杀死客户端的进程后，客户端的内核就会向服务端发送<code>FIN</code>报文，与客户端进行四次挥手。</p>
<p>所以，即使没有开启 TCP keepalive，且双方也没有数据交互的情况下，如果其中一方的进程发生了崩溃，这个过程操作系统是可以感知的到的，于是就会发送 FIN 报文给对方，然后与对方进行 TCP 四次挥手。</p>
<h1 id="服务端挂了，客户端的-TCP-连接还在吗？"><a href="#服务端挂了，客户端的-TCP-连接还在吗？" class="headerlink" title="服务端挂了，客户端的 TCP 连接还在吗？"></a>服务端挂了，客户端的 TCP 连接还在吗？</h1><p>如果「服务端挂掉」指的是「服务端进程崩溃」，那么服务端的进程在发生崩溃的时候，内核会发送 FIN 报文，与客户端进行四次挥手。</p>
<p>但是，如果「服务端挂掉」指的是「服务端主机宕机」，那么是不会发生四次挥手的，具体后续会发生什么？还要看客户端会不会发送数据？</p>
<ul>
<li>如果客户端会发送数据，由于服务端已经不存在，客户端的数据报文会超时重传，当重传次数达到一定阈值后，会断开 TCP 连接；</li>
<li>如果客户端一直不会发送数据，再看客户端有没有开启 TCP keepalive 机制？</li>
<li>如果有开启，客户端在一段时间后，检测到服务端的 TCP 连接已经不存在，则会断开自身的 TCP 连接；</li>
<li>如果没有开启，客户端的 TCP 连接会一直存在，并不会断开。</li>
</ul>
<h2 id="服务端进程崩溃，客户端会发生什么？"><a href="#服务端进程崩溃，客户端会发生什么？" class="headerlink" title="服务端进程崩溃，客户端会发生什么？"></a>服务端进程崩溃，客户端会发生什么？</h2><p>TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手<code>FIN</code>报文，后续的挥手过程也都是在内核完成，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程。</p>
<p>使用<code>kill -9</code>命令来模拟进程崩溃的情况，发现在<code>kill</code>掉进程后，服务端会发送<code>FIN</code>报文，与客户端进行四次挥手。</p>
<h2 id="服务端主机宕机后，客户端会发生什么？"><a href="#服务端主机宕机后，客户端会发生什么？" class="headerlink" title="服务端主机宕机后，客户端会发生什么？"></a>服务端主机宕机后，客户端会发生什么？</h2><p>当服务端的主机突然断电了，这种情况就是属于服务端主机宕机了。</p>
<p>当服务端的主机发生了宕机，是没办法和客户端进行四次挥手的，所以在服务端主机发生宕机的那一时刻，客户端是没办法立刻感知到服务端主机宕机了，只能在后续的数据交互中来感知服务端的连接已经不存在了。</p>
<p>因此，我们要分三种情况来讨论：</p>
<ul>
<li>服务端主机宕机后，客户端会发送数据；</li>
<li>服务端主机宕机后，客户端一直不会发送数据；</li>
<li>服务端主机宕机后，然后马上重启了服务端，重启完成后，如果这时客户端发送了数据</li>
</ul>
<h3 id="服务端主机宕机后，如果客户端会发送数据"><a href="#服务端主机宕机后，如果客户端会发送数据" class="headerlink" title="服务端主机宕机后，如果客户端会发送数据"></a>服务端主机宕机后，如果客户端会发送数据</h3><p>在服务端主机宕机后，客户端发送了数据报文，由于得不到响应，在等待一定时长后，客户端就会触发超时重传机制，重传未得到响应的数据报文。</p>
<p>当重传次数达到达到一定阈值后，内核就会判定出该 TCP 连接有问题，然后通过<code>Socket</code>接口告诉应用程序该 TCP 连接出问题了，于是客户端的 TCP 连接就会断开。</p>
<p>那 TCP 的数据报文具体重传几次呢？</p>
<p>在 Linux 系统中，提供了一个叫<code>tcp_retries2</code>配置项，默认值是 15：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># cat /proc/sys/net/ipv4/tcp_retries2</span></span><br><span class="line">15</span><br></pre></td></tr></table></figure>
<p>这个内核参数是控制在 TCP 连接建立的情况下，超时重传的最大次数。</p>
<p>不过<code>tcp_retries2</code>设置了 15 次，并不代表 TCP 超时重传了 15 次才会通知应用程序终止该 TCP 连接，内核会根据<code>tcp_retries2</code>设置的值，计算出一个<code>timeout</code>（如果<code>tcp_retries2=15</code>，那么计算得到的<code>timeout = 924600 ms</code>），如果重传间隔超过这个<code>timeout</code>，则认为超过了阈值，就会停止重传，然后就会断开 TCP 连接。</p>
<p>在发生超时重传的过程中，每一轮的超时时间（RTO）都是倍数增长的，比如如果第一轮 RTO 是 200ms，那么第二轮 RTO 是 400ms，第三轮 RTO 是 800ms，以此类推。</p>
<p>而 RTO 是基于 RTT（一个包的往返时间） 来计算的，如果 RTT 较大，那么计算出来的 RTO 就越大，那么经过几轮重传后，很快就达到了上面的<code>timeout</code>值了。</p>
<p>举个例子，如果<code>tcp_retries2=15</code>，那么计算得到的<code>timeout = 924600 ms</code>，如果重传总间隔时长达到了<code>timeout</code>就会停止重传，然后就会断开 TCP 连接：</p>
<ul>
<li>如果 RTT 比较小，那么 RTO 初始值就约等于下限 200ms，也就是第一轮的超时时间是 200ms，由于<code>timeout</code>总时长是 924600ms，表现出来的现象刚好就是重传了 15 次，超过了<code>timeout</code>值，从而断开 TCP 连接</li>
<li>如果 RTT 比较大，假设 RTO 初始值计算得到的是 1000ms，也就是第一轮的超时时间是 1 秒，那么根本不需要重传 15 次，重传总间隔就会超过 924600ms。</li>
</ul>
<p>最小 RTO 和最大 RTO 是在 Linux 内核中定义好了：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#define TCP_RTO_MAX ((unsigned)(120*HZ))</span><br><span class="line">#define TCP_RTO_MIN ((unsigned)(HZ/5))</span><br></pre></td></tr></table></figure>
<p>Linux 2.6+ 使用 1000 毫秒的 HZ，因此<code>TCP_RTO_MIN</code>约为 200 毫秒，<code>TCP_RTO_MAX</code>约为 120 秒。</p>
<p>如果<code>tcp_retries</code>设置为 15，且 RTT 比较小，那么 RTO 初始值就约等于下限 200ms，这意味着它需要 924.6 秒才能将断开的 TCP 连接通知给上层（即应用程序），每一轮的 RTO 增长关系如下表格：</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/51.png" class="">

<h3 id="服务端主机宕机后，如果客户端一直不发数据"><a href="#服务端主机宕机后，如果客户端一直不发数据" class="headerlink" title="服务端主机宕机后，如果客户端一直不发数据"></a>服务端主机宕机后，如果客户端一直不发数据</h3><p>在服务端主机发送宕机后，如果客户端一直不发送数据，那么还得看是否开启了<code>TCP keepalive</code>机制（TCP 保活机制）。</p>
<p>如果没有开启<code>TCP keepalive</code>机制，在服务端主机发送宕机后，如果客户端一直不发送数据，那么客户端的 TCP 连接将一直保持存在，所以我们可以得知一个点，在没有使用 TCP 保活机制，且双方不传输数据的情况下，一方的 TCP 连接处在<code>ESTABLISHED</code>状态时，并不代表另一方的 TCP 连接还一定是正常的。</p>
<p>而如果开启了<code>TCP keepalive</code>机制，在服务端主机发送宕机后，即使客户端一直不发送数据，在持续一段时间后，TCP 就会发送探测报文，探测服务端是否存活：</p>
<ul>
<li>如果对端是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 TCP 保活时间会被重置，等待下一个 TCP 保活时间的到来。</li>
<li>如果对端主机崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡。</li>
</ul>
<p>所以，<code>TCP keepalive</code>机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活。</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/52.png" class="">

<p><code>TCP keepalive</code>机制机制的原理是这样的：</p>
<p>定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。</p>
<p>在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔，以下都为默认值：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_keepalive_time=7200</span><br><span class="line">net.ipv4.tcp_keepalive_intvl=75  </span><br><span class="line">net.ipv4.tcp_keepalive_probes=9</span><br></pre></td></tr></table></figure>
<p>每个参数的意思，具体如下：<br><code>tcp_keepalive_time=7200</code>：表示保活时间是 7200 秒（2小时），也就 2 小时内如果没有任何连接相关的活动，则会启动保活机制<br><code>tcp_keepalive_intvl=75</code>：表示每次检测间隔 75 秒；<br><code>tcp_keepalive_probes=9</code>：表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。</p>
<p>也就是说在 Linux 系统中，最少需要经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接。</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/53.png" class="">

<p>注意，应用程序如果想使用 TCP 保活机制，需要通过<code>socket</code>接口设置<code>SO_KEEPALIVE</code>选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。</p>
<p><code>TCP keepalive</code>机制探测的时间是有点长。</p>
<p><code>TCP keepalive</code>是 TCP 层（内核态） 实现的，它是给所有基于 TCP 传输协议的程序一个兜底的方案。</p>
<p>实际上，我们应用层可以自己实现一套探测机制，可以在较短的时间内，探测到对方是否存活。</p>
<p>比如，web 服务软件一般都会提供<code>keepalive_timeout</code>参数，用来指定 HTTP 长连接的超时时间。如果设置了 HTTP 长连接的超时时间是 60 秒，web 服务软件就会启动一个定时器，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，就会触发回调函数来释放该连接。</p>
<img src="/2022/01/12/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/54.png" class="">

<h3 id="服务端主机宕机后，然后马上重启了服务端，客户端发送了数据"><a href="#服务端主机宕机后，然后马上重启了服务端，客户端发送了数据" class="headerlink" title="服务端主机宕机后，然后马上重启了服务端，客户端发送了数据"></a>服务端主机宕机后，然后马上重启了服务端，客户端发送了数据</h3><p>如果服务端主机宕机后，然后马上重启了服务端，重启完成后，如果这时客户端发送了数据，由于服务端之前的连接信息已经不存在，所以会回<code>RST</code>报文给客户端，客户端收到<code>RST</code>报文后，就断开连接。</p>
<h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p>如果「服务端挂掉」指的是「服务端进程崩溃」，服务端的进程在发生崩溃的时候，内核会发送<code>FIN</code>报文，与客户端进行四次挥手。</p>
<p>但是，如果「服务端挂掉」指的是「服务端主机宕机」，那么是不会发生四次挥手的，具体后续会发生什么？还要看客户端会不会发送数据？</p>
<ul>
<li>如果客户端会发送数据，由于服务端已经不存在，客户端的数据报文会超时重传，当重传总间隔时长达到一定阈值（内核会根据<code>tcp_retries2</code>设置的值计算出一个阈值）后，会断开 TCP 连接；</li>
<li>如果客户端一直不会发送数据，再看客户端有没有开启<code>TCP keepalive</code>机制？</li>
<li>如果有开启，客户端在一段时间没有进行数据交互时，会触发<code>TCP keepalive</code>机制，探测对方是否存在，如果探测到对方已经消亡，则会断开自身的 TCP 连接；</li>
<li>如果没有开启，客户端的 TCP 连接会一直存在，并且一直保持在<code>ESTABLISHED</code>状态。</li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" rel="tag">计算机网络</a></li></ul>

    </footer>
  </div>

   
   
  
</article>

    
    <article
  id="post-操作系统/进程与线程"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/"
    >进程与线程</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/" class="article-date">
  <time datetime="2022-01-11T08:22:32.000Z" itemprop="datePublished">2022-01-11</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/">计算机组成</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h1><p>我们编写的代码只是⼀个存储在硬盘的静态⽂件，通过编译后就会⽣成⼆进制可执⾏⽂件，当我们运⾏这个可执⾏⽂件后，它会被装载到内存中，接着 CPU 会执⾏程序中的每⼀条指令，那么这个运⾏中的程序，就被称为进程（<code>Process</code>）。</p>
<p>现在我们考虑有⼀个会读取硬盘⽂件数据的程序被执⾏了，那么当运⾏到读取⽂件的指令时，就会去从硬盘读取数据，但是硬盘的读写速度是⾮常慢的，那么在这个时候，如果 CPU 傻傻的等硬盘返回数据的话，那 CPU 的利⽤率是⾮常低的。</p>
<p>所以，当进程要从硬盘读取数据时，CPU 不需要阻塞等待数据的返回，⽽是去执⾏另外的进程。当硬盘数据返回时，CPU 会收到个中断，于是 CPU 再继续运⾏这个进程。</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/1.png" class="">

<p>这种多个程序、交替执⾏的思想，就有 CPU 管理多个进程的初步想法。</p>
<p>对于⼀个⽀持多进程的系统，CPU 会从⼀个进程快速切换⾄另⼀个进程，其间每个进程各运⾏⼏⼗或⼏百个毫秒。</p>
<p>虽然单核的 CPU 在某⼀个瞬间，只能运⾏⼀个进程。但在 1 秒钟期间，它可能会运⾏多个进程，这样就产⽣并⾏的错觉，实际上这是并发。</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/2.png" class="">

<h2 id="进程的状态"><a href="#进程的状态" class="headerlink" title="进程的状态"></a>进程的状态</h2><p>进程有着「运⾏-暂停-运⾏」的活动规律。⼀般说来，⼀个进程并不是⾃始⾄终连续不停地运⾏的，它与并发执⾏中的其他进程的执⾏是相互制约的。</p>
<p>它有时处于运⾏状态，有时⼜由于某种原因⽽暂停运⾏处于等待状态，当使它暂停的原因消失后，它⼜进⼊准备运⾏状态。</p>
<p>所以，在⼀个进程的活动期间⾄少具备三种基本状态，即运⾏状态、就绪状态、阻塞状态。</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/3.png" class="">

<p>上图中各个状态的意义：</p>
<ul>
<li>运⾏状态（<code>Runing</code>）：该时刻进程占⽤ CPU；</li>
<li>就绪状态（<code>Ready</code>）：可运⾏，由于其他进程处于运⾏状态⽽暂时停⽌运⾏；</li>
<li>阻塞状态（<code>Blocked</code>）：该进程正在等待某⼀事件发⽣（如等待输⼊&#x2F;输出操作的完成）⽽暂时停⽌运⾏，这时，即使给它 CPU 控制权，它也⽆法运⾏；</li>
</ul>
<p>当然，进程还有另外两个基本状态：</p>
<ul>
<li>创建状态（<code>new</code>）：进程正在被创建时的状态；</li>
<li>结束状态（<code>Exit</code>）：进程正在从系统中消失时的状态；</li>
</ul>
<p>于是，⼀个完整的进程状态的变迁如下图：</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/4.png" class="">

<p>再来详细说明⼀下进程的状态变迁：</p>
<ul>
<li><code>NULL</code> -&gt; 创建状态：⼀个新进程被创建时的第⼀个状态；</li>
<li>创建状态 -&gt; 就绪状态：当进程被创建完成并初始化后，⼀切就绪准备运⾏时，变为就绪状态，这个过程是很快的；</li>
<li>就绪态 -&gt; 运⾏状态：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运⾏该进程；</li>
<li>运⾏状态 -&gt; 结束状态：当进程已经运⾏完成或出错时，会被操作系统作结束状态处理；</li>
<li>运⾏状态 -&gt; 就绪状态：处于运⾏状态的进程在运⾏过程中，由于分配给它的运⾏时间⽚⽤完，操作系统会把该进程变为就绪态，接着从就绪态选中另外⼀个进程运⾏；</li>
<li>运⾏状态 -&gt; 阻塞状态：当进程请求某个事件且必须等待时，例如请求 I&#x2F;O 事件；</li>
<li>阻塞状态 -&gt; 就绪状态：当进程要等待的事件完成时，它从阻塞状态变到就绪状态；</li>
</ul>
<p>如果有⼤量处于阻塞状态的进程，进程可能会占⽤着物理内存空间，显然不是我们所希望的，毕竟物理内存空间是有限的，被阻塞状态的进程占⽤着物理内存就⼀种浪费物理内存的⾏为。</p>
<p>所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运⾏的时候，再从硬盘换⼊到物理内存。</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/5.jpg" class="">

<p>那么，就需要一个新的状态，来描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。</p>
<p>另外，挂起状态可以分为两种：</p>
<ul>
<li>阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；</li>
<li>就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；</li>
</ul>
<p>这两种挂起状态加上前面的五种状态，就变成了七种状态变迁：</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/6.jpg" class="">

<p>导致进程挂起的原因不只是因为进程所使用的内存空间不在物理内存，还包括如下情况：</p>
<ul>
<li>通过<code>sleep</code>让进程间歇性挂起，其工作原理是设置一个定时器，到期后唤醒进程。</li>
<li>用户希望挂起一个程序的执行，比如在 Linux 中用 Ctrl+Z 挂起进程；</li>
</ul>
<h2 id="进程的控制结构"><a href="#进程的控制结构" class="headerlink" title="进程的控制结构"></a>进程的控制结构</h2><p>在操作系统中，是用进程控制块（<code>process control block</code>，PCB）数据结构来描述进程的。</p>
<p>PCB 是进程存在的唯一标识，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。</p>
<h3 id="PCB-包含的信息"><a href="#PCB-包含的信息" class="headerlink" title="PCB 包含的信息"></a>PCB 包含的信息</h3><p>进程描述信息：</p>
<ul>
<li>进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；</li>
<li>用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；</li>
</ul>
<p>进程控制和管理信息：</p>
<ul>
<li>进程当前状态，如<code>new、ready、running、waiting</code>或<code>blocked</code>等；</li>
<li>进程优先级：进程抢占 CPU 时的优先级；</li>
</ul>
<p>资源分配清单：</p>
<ul>
<li>有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I&#x2F;O 设备信息。</li>
</ul>
<p>CPU 相关信息：</p>
<ul>
<li>CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。</li>
</ul>
<p>可见，PCB 包含信息还是比较多的。</p>
<h3 id="每个-PCB-的组织方式"><a href="#每个-PCB-的组织方式" class="headerlink" title="每个 PCB 的组织方式"></a>每个 PCB 的组织方式</h3><p>通常是通过链表的方式进行组织，把具有相同状态的进程链在一起，组成各种队列。比如：</p>
<ul>
<li>将所有处于就绪状态的进程链在一起，称为就绪队列；</li>
<li>把所有因等待某事件而处于等待状态的进程链在一起就组成各种阻塞队列；</li>
<li>另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。</li>
</ul>
<p>那么，就绪队列和阻塞队列链表的组织形式如下图：</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/7.jpg" class="">

<p>除了链接的组织方式，还有索引方式，它的工作原理：将同一状态的进程组织在一个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。</p>
<p>一般会选择链表，因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除。</p>
<h2 id="进程的控制"><a href="#进程的控制" class="headerlink" title="进程的控制"></a>进程的控制</h2><h3 id="创建进程"><a href="#创建进程" class="headerlink" title="创建进程"></a>创建进程</h3><p>操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源，当子进程被终止时，其在父进程处继承的资源应当还给父进程。同时，终止父进程时同时也会终止其所有的子进程。</p>
<p>注意：Linux 操作系统对于终止有子进程的父进程，会把子进程交给 1 号进程接管。这里所指出的进程终止概念是宏观操作系统的一种观点，最后怎么实现当然是看具体的操作系统。</p>
<p>创建进程的过程如下：</p>
<ul>
<li>为新进程分配一个唯一的进程标识号，并申请一个空白的 PCB，PCB 是有限的，若申请失败则创建失败；</li>
<li>为进程分配资源，此处如果资源不足，进程就会进入等待状态，以等待资源；</li>
<li>初始化 PCB；</li>
<li>如果进程的调度队列能够接纳新进程，那就将进程插入到就绪队列，等待被调度运行；</li>
</ul>
<h3 id="终止进程"><a href="#终止进程" class="headerlink" title="终止进程"></a>终止进程</h3><p>进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号<code>kill</code>掉）。</p>
<p>终止进程的过程如下：</p>
<ul>
<li>查找需要终止的进程的 PCB；</li>
<li>如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；</li>
<li>如果其还有子进程，则应将其所有子进程终止；</li>
<li>将该进程所拥有的全部资源都归还给父进程或操作系统；</li>
<li>将其从 PCB 所在队列中删除；</li>
</ul>
<h3 id="阻塞进程"><a href="#阻塞进程" class="headerlink" title="阻塞进程"></a>阻塞进程</h3><p>当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。</p>
<p>阻塞进程的过程如下：</p>
<ul>
<li>找到将要被阻塞进程标识号对应的 PCB；</li>
<li>如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；</li>
<li>将该 PCB 插入到阻塞队列中去；</li>
</ul>
<h4 id="唤醒进程"><a href="#唤醒进程" class="headerlink" title="唤醒进程"></a>唤醒进程</h4><p>进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。</p>
<p>如果某进程正在等待 I&#x2F;O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。</p>
<p>唤醒进程的过程如下：</p>
<ul>
<li>在该事件的阻塞队列中找到相应进程的 PCB；</li>
<li>将其从阻塞队列中移出，并置其状态为就绪状态；</li>
<li>把该 PCB 插入到就绪队列中，等待调度程序调度；</li>
</ul>
<p>进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句。</p>
<h2 id="进程的上下文切换"><a href="#进程的上下文切换" class="headerlink" title="进程的上下文切换"></a>进程的上下文切换</h2><p>各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个一个进程切换到另一个进程运行，称为进程的上下文切换。</p>
<h3 id="CPU-上下⽂切换"><a href="#CPU-上下⽂切换" class="headerlink" title="CPU 上下⽂切换"></a>CPU 上下⽂切换</h3><p>大多数操作系统都是多任务，通常支持大于 CPU 数量的任务同时运行。实际上，这些任务并不是同时运行的，只是因为系统在很短的时间内，让各个任务分别在 CPU 运行，于是就造成同时运行的错觉。</p>
<p>任务是交给 CPU 运行的，那么在每个任务运行前，CPU 需要知道任务从哪里加载，又从哪里开始运行。</p>
<p>所以，操作系统需要事先帮 CPU 设置好 CPU 寄存器和程序计数器。</p>
<p>CPU 寄存器是 CPU 内部一个容量小，但是速度极快的内存（缓存）。我举个例子，寄存器像是你的口袋，内存像你的书包，硬盘则是你家里的柜子，如果你的东西存放到口袋，那肯定是比你从书包或家里柜子取出来要快的多。</p>
<p>再来，程序计数器则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。</p>
<p>所以说，CPU 寄存器和程序计数是 CPU 在运行任何任务前，所必须依赖的环境，这些环境就叫做 CPU 上下文。</p>
<p>既然知道了什么是 CPU 上下文，那理解 CPU 上下文切换就不难了。</p>
<p>CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。</p>
<p>系统内核会存储保持下来的上下文信息，当此任务再次被分配给 CPU 运行时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。</p>
<p>上面说到所谓的「任务」，主要包含进程、线程和中断。所以，可以根据任务的不同，把 CPU 上下文切换分成：进程上下文切换、线程上下文切换和中断上下文切换。</p>
<h3 id="进程的上下文切换到底是切换什么呢？"><a href="#进程的上下文切换到底是切换什么呢？" class="headerlink" title="进程的上下文切换到底是切换什么呢？"></a>进程的上下文切换到底是切换什么呢？</h3><p>进程是由内核管理和调度的，所以进程的切换只能发生在内核态。</p>
<p>所以，进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。</p>
<p>通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，如下图所示：</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/8.jpg" class="">

<p>大家需要注意，进程的上下文开销是很关键的，我们希望它的开销越小越好，这样可以使得进程可以把更多时间花费在执行程序上，而不是耗费在上下文切换。</p>
<h3 id="发生进程上下文切换有哪些场景？"><a href="#发生进程上下文切换有哪些场景？" class="headerlink" title="发生进程上下文切换有哪些场景？"></a>发生进程上下文切换有哪些场景？</h3><ul>
<li>为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行；</li>
<li>进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行；</li>
<li>当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度；</li>
<li>当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；</li>
<li>发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；</li>
</ul>
<p>以上，就是发生进程上下文切换的常见场景了。</p>
<h1 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h1><p>在早期的操作系统中都是以进程作为独立运行的基本单位，直到后面，计算机科学家们又提出了更小的能独立运行的基本单位，也就是线程。</p>
<h2 id="什么是线程"><a href="#什么是线程" class="headerlink" title="什么是线程"></a>什么是线程</h2><p>线程是进程当中的一条执行流程。</p>
<p>同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/9.jpg" class="">

<h2 id="线程的优缺点"><a href="#线程的优缺点" class="headerlink" title="线程的优缺点"></a>线程的优缺点</h2><p>线程的优点：</p>
<ul>
<li>一个进程中可以同时存在多个线程；</li>
<li>各个线程之间可以并发执行；</li>
<li>各个线程之间可以共享地址空间和文件等资源；</li>
</ul>
<p>线程的缺点：</p>
<ul>
<li>当进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃。</li>
</ul>
<p>举个例子，对于游戏的用户设计，则不应该使用多线程的方式，否则一个用户挂了，会影响其他同个进程的线程。</p>
<h2 id="线程与进程的比较"><a href="#线程与进程的比较" class="headerlink" title="线程与进程的比较"></a>线程与进程的比较</h2><p>线程与进程的比较如下：</p>
<ul>
<li>进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；</li>
<li>进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；</li>
<li>线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；</li>
<li>线程能减少并发执行的时间和空间开销；</li>
</ul>
<p>对于，线程相比进程能减少开销，体现在：</p>
<ul>
<li>线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；</li>
<li>线程的终止时间比进程快，因为线程释放的资源相比进程少很多；</li>
<li>同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；</li>
<li>由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；</li>
</ul>
<p>所以，不管是时间效率，还是空间效率线程比进程都要高。</p>
<h2 id="线程的上下文切换"><a href="#线程的上下文切换" class="headerlink" title="线程的上下文切换"></a>线程的上下文切换</h2><p>线程与进程最大的区别在于：线程是调度的基本单位，而进程则是资源拥有的基本单位。</p>
<p>所以，所谓操作系统的任务调度，实际上的调度对象是线程，而进程只是给线程提供了虚拟内存、全局变量等资源。</p>
<p>对于线程和进程，我们可以这么理解：</p>
<ul>
<li>当进程只有一个线程时，可以认为进程就等于线程；</li>
<li>当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换时是不需要修改的；</li>
</ul>
<p>另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。</p>
<h3 id="线程上下文切换的是什么？"><a href="#线程上下文切换的是什么？" class="headerlink" title="线程上下文切换的是什么？"></a>线程上下文切换的是什么？</h3><p>这还得看线程是不是属于同一个进程：</p>
<ul>
<li>当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；</li>
<li>当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据；</li>
</ul>
<p>所以，线程的上下文切换相比进程，开销要小很多。</p>
<h2 id="线程的实现"><a href="#线程的实现" class="headerlink" title="线程的实现"></a>线程的实现</h2><p>主要有三种线程的实现方式：</p>
<ul>
<li>用户线程（<code>User Thread</code>）：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；</li>
<li>内核线程（<code>Kernel Thread</code>）：在内核中实现的线程，是由内核管理的线程；</li>
<li>轻量级进程（<code>LightWeight Process</code>）：在内核中来支持用户线程；</li>
</ul>
<p>那么，这还需要考虑一个问题，用户线程和内核线程的对应关系。</p>
<p>首先，第一种关系是多对一的关系，也就是多个用户线程对应同一个内核线程：</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/10.jpg" class="">

<p>第二种是一对一的关系，也就是一个用户线程对应一个内核线程：</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/11.jpg" class="">

<p>第三种是多对多的关系，也就是多个用户线程对应到多个内核线程：</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/12.jpg" class="">

<h2 id="用户线程如何理解？存在什么优势和缺陷？"><a href="#用户线程如何理解？存在什么优势和缺陷？" class="headerlink" title="用户线程如何理解？存在什么优势和缺陷？"></a>用户线程如何理解？存在什么优势和缺陷？</h2><p>用户线程是基于用户态的线程管理库来实现的，那么线程控制块（<code>Thread Control Block</code>, TCB） 也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。</p>
<p>所以，用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。</p>
<p>用户级线程的模型，也就类似前面提到的多对一的关系，即多个用户线程对应同一个内核线程，如下图所示：</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/13.png" class="">

<p>用户线程的优点：</p>
<ul>
<li>每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统；</li>
<li>用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快；</li>
</ul>
<p>用户线程的缺点：</p>
<ul>
<li>由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了。</li>
<li>当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。</li>
<li>由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢；</li>
</ul>
<h2 id="那内核线程如何理解？存在什么优势和缺陷？"><a href="#那内核线程如何理解？存在什么优势和缺陷？" class="headerlink" title="那内核线程如何理解？存在什么优势和缺陷？"></a>那内核线程如何理解？存在什么优势和缺陷？</h2><p>内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。</p>
<p>内核线程的模型，也就类似前面提到的一对一的关系，即一个用户线程对应一个内核线程，如下图所示：</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/14.png" class="">

<p>内核线程的优点：</p>
<ul>
<li>在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行；</li>
<li>分配给线程，多线程的进程获得更多的 CPU 运行时间；</li>
</ul>
<p>内核线程的缺点：</p>
<ul>
<li>在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如 PCB 和 TCB；</li>
<li>线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大；</li>
</ul>
<h2 id="最后的轻量级进程如何理解？"><a href="#最后的轻量级进程如何理解？" class="headerlink" title="最后的轻量级进程如何理解？"></a>最后的轻量级进程如何理解？</h2><p>轻量级进程（Light-weight process，LWP）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度。</p>
<p>在大多数系统中，LWP与普通进程的区别也在于它只有一个最小的执行上下文和调度程序所需的统计信息。一般来说，一个进程代表程序的一个实例，而 LWP 代表程序的执行线程，因为一个执行线程不像进程那样需要那么多状态信息，所以 LWP 也不带有这样的信息。</p>
<p>在 LWP 之上也是可以使用用户线程的，那么 LWP 与用户线程的对应关系就有三种：</p>
<ul>
<li>1 : 1，即一个 LWP 对应 一个用户线程；</li>
<li>N : 1，即一个 LWP 对应多个用户线程；</li>
<li>M : N，即多个 LWP 对应多个用户线程；</li>
</ul>
<p>接下来针对上面这三种对应关系说明它们优缺点。先看下图的 LWP 模型：</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/15.png" class="">

<p>1 : 1 模式<br>一个线程对应到一个 LWP 再对应到一个内核线程，如上图的进程 4，属于此模型。</p>
<p>优点：实现并行，当一个 LWP 阻塞，不会影响其他 LWP；<br>缺点：每一个用户线程，就产生一个内核线程，创建线程的开销较大。<br>N : 1 模式<br>多个用户线程对应一个 LWP 再对应一个内核线程，如上图的进程 2，线程管理是在用户空间完成的，此模式中用户的线程对操作系统不可见。</p>
<p>优点：用户线程要开几个都没问题，且上下文切换发生用户空间，切换的效率较高；<br>缺点：一个用户线程如果阻塞了，则整个进程都将会阻塞，另外在多核 CPU 中，是没办法充分利用 CPU 的。</p>
<p>M : N 模式<br>根据前面的两个模型混搭一起，就形成 M:N 模型，该模型提供了两级控制，首先多个用户线程对应到多个 LWP，LWP 再一一对应到内核线程，如上图的进程 3。</p>
<p>优点：综合了前两种优点，大部分的线程上下文发生在用户空间，且多个线程又可以充分利用多核 CPU 的资源。<br>组合模式</p>
<p>如上图的进程 5，此进程结合 1:1 模型和 M:N 模型。开发人员可以针对不同的应用特点调节内核线程的数目来达到物理并行性和逻辑并行性的最佳方案。</p>
<h1 id="调度"><a href="#调度" class="headerlink" title="调度"></a>调度</h1><p>进程都希望自己能够占用 CPU 进行工作，那么这涉及到前面说过的进程上下文切换。</p>
<p>一旦操作系统把进程切换到运行状态，也就意味着该进程占用着 CPU 在执行，但是当操作系统把进程切换到其他状态时，那就不能在 CPU 中执行了，于是操作系统会选择下一个要运行的进程。</p>
<p>选择一个进程运行这一功能是在操作系统中完成的，通常称为调度程序（<code>scheduler</code>）。</p>
<p>那到底什么时候调度进程，或以什么原则来调度进程呢？</p>
<h2 id="调度时机"><a href="#调度时机" class="headerlink" title="调度时机"></a>调度时机</h2><p>在进程的生命周期中，当进程从一个运行状态到另外一状态变化的时候，其实会触发一次调度。</p>
<p>比如，以下状态的变化都会触发操作系统的调度：</p>
<ul>
<li>从就绪态 -&gt; 运行态：当进程被创建时，会进入到就绪队列，操作系统会从就绪队列选择一个进程运行；</li>
<li>从运行态 -&gt; 阻塞态：当进程发生 I&#x2F;O 事件而阻塞时，操作系统必须选择另外一个进程运行；</li>
<li>从运行态 -&gt; 结束态：当进程退出结束后，操作系统得从就绪队列选择另外一个进程运行；</li>
</ul>
<p>因为，这些状态变化的时候，操作系统需要考虑是否要让新的进程给 CPU 运行，或者是否让当前进程从 CPU 上退出来而换另一个进程运行。</p>
<p>另外，如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断，把调度算法分为两类：</p>
<ul>
<li>非抢占式调度算法挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。</li>
<li>抢占式调度算法挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生时钟中断，以便把 CPU 控制返回给调度程序进行调度，也就是常说的时间片机制。</li>
</ul>
<h2 id="调度原则"><a href="#调度原则" class="headerlink" title="调度原则"></a>调度原则</h2><p>原则一：如果运行的程序，发生了 I&#x2F;O 事件的请求，那 CPU 使用率必然会很低，因为此时进程在阻塞等待硬盘的数据返回。这样的过程，势必会造成 CPU 突然的空闲。所以，为了提高 CPU 利用率，在这种发送 I&#x2F;O 事件致使 CPU 空闲的情况下，调度程序需要从就绪队列中选择一个进程来运行。</p>
<p>原则二：有的程序执行某个任务花费的时间会比较长，如果这个程序一直占用着 CPU，会造成系统吞吐量（CPU 在单位时间内完成的进程数量）的降低。所以，要提高系统的吞吐率，调度程序要权衡长任务和短任务进程的运行完成数量。</p>
<p>原则三：从进程开始到结束的过程中，实际上是包含两个时间，分别是进程运行时间和进程等待时间，这两个时间总和就称为周转时间。进程的周转时间越小越好，如果进程的等待时间很长而运行时间很短，那周转时间就很长，这不是我们所期望的，调度程序应该避免这种情况发生。</p>
<p>原则四：处于就绪队列的进程，也不能等太久，当然希望这个等待的时间越短越好，这样可以使得进程更快的在 CPU 中执行。所以，就绪队列中进程的等待时间也是调度程序所需要考虑的原则。</p>
<p>原则五：对于鼠标、键盘这种交互式比较强的应用，我们当然希望它的响应时间越快越好，否则就会影响用户体验了。所以，对于交互式比较强的应用，响应时间也是调度程序需要考虑的原则。</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/16.png" class="">

<p>针对上面的五种调度原则，总结成如下：</p>
<ul>
<li>CPU 利用率：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；</li>
<li>系统吞吐量：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；</li>
<li>周转时间：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；</li>
<li>等待时间：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意；</li>
<li>响应时间：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。</li>
</ul>
<p>说白了，这么多调度原则，目的就是要使得进程要「快」。</p>
<h2 id="调度算法"><a href="#调度算法" class="headerlink" title="调度算法"></a>调度算法</h2><p>不同的调度算法适用的场景也是不同的。</p>
<p>接下来，说说在单核 CPU 系统中常见的调度算法。</p>
<h3 id="先来先服务调度算法"><a href="#先来先服务调度算法" class="headerlink" title="先来先服务调度算法"></a>先来先服务调度算法</h3><p>最简单的一个调度算法，就是非抢占式的先来先服务（<code>First Come First Serve, FCFS</code>）算法了。</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/17.png" class="">

<p>顾名思义，先来后到，每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。</p>
<p>这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。</p>
<p>FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I&#x2F;O 繁忙型作业的系统。</p>
<h3 id="最短作业优先调度算法"><a href="#最短作业优先调度算法" class="headerlink" title="最短作业优先调度算法"></a>最短作业优先调度算法</h3><p>最短作业优先（<code>Shortest Job First, SJF</code>）调度算法同样也是顾名思义，它会优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/18.png" class="">

<p>这显然对长作业不利，很容易造成一种极端现象。</p>
<p>比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。</p>
<h3 id="高响应比优先调度算法"><a href="#高响应比优先调度算法" class="headerlink" title="高响应比优先调度算法"></a>高响应比优先调度算法</h3><p>前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。</p>
<p>那么，高响应比优先（<code>Highest Response Ratio Next, HRRN</code>）调度算法主要是权衡了短作业和长作业。</p>
<p>每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式：</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/19.png" class="">

<p>从上面的公式，可以发现：</p>
<ul>
<li>如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；</li>
<li>如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；</li>
</ul>
<p>高响应比优先调度算法是「理想型」的调度算法，现实中是实现不了的。</p>
<h3 id="时间片轮转调度算法"><a href="#时间片轮转调度算法" class="headerlink" title="时间片轮转调度算法"></a>时间片轮转调度算法</h3><p>最古老、最简单、最公平且使用最广的算法就是时间片轮转（<code>Round Robin, RR</code>）调度算法。</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/20.png" class="">

<p>每个进程被分配一个时间段，称为时间片（<code>Quantum</code>），即允许该进程在该时间段中运行。</p>
<ul>
<li>如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外一个进程；</li>
<li>如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；</li>
</ul>
<p>另外，时间片的长度就是一个很关键的点：</p>
<ul>
<li>如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；</li>
<li>如果设得太长又可能引起对短作业进程的响应时间变长。</li>
</ul>
<p>一般来说，时间片设为 20ms~50ms 通常是一个比较合理的折中值。</p>
<h3 id="最高优先级调度算法"><a href="#最高优先级调度算法" class="headerlink" title="最高优先级调度算法"></a>最高优先级调度算法</h3><p>前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。</p>
<p>但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法。</p>
<p>进程的优先级可以分为，静态优先级和动态优先级：</p>
<ul>
<li>静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；</li>
<li>动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。</li>
</ul>
<p>该算法也有两种处理优先级高的方法，非抢占式和抢占式：</p>
<ul>
<li>非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。</li>
<li>抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。</li>
</ul>
<p>但是依然有缺点，可能会导致低优先级的进程永远不会运行。</p>
<h3 id="多级反馈队列调度算法"><a href="#多级反馈队列调度算法" class="headerlink" title="多级反馈队列调度算法"></a>多级反馈队列调度算法</h3><p>多级反馈队列（<code>Multilevel Feedback Queue</code>）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。</p>
<p>顾名思义：</p>
<ul>
<li>「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。</li>
<li>「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；</li>
</ul>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/21.png" class="">

<p>来看看，它是如何工作的：</p>
<ul>
<li>设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短；</li>
<li>新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；</li>
<li>当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；</li>
<li>可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也变更长了，所以该算法很好的兼顾了长短作业，同时有较好的响应时间。</li>
</ul>
<h2 id="去银行办业务的例子"><a href="#去银行办业务的例子" class="headerlink" title="去银行办业务的例子"></a>去银行办业务的例子</h2><p>办理业务的客户相当于进程，银行窗口工作人员相当于 CPU。</p>
<p>现在，假设这个银行只有一个窗口（单核 CPU），那么工作人员一次只能处理一个业务。</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/22.png" class="">

<p>那么最简单的处理方式，就是先来的先处理，后面来的就乖乖排队，这就是先来先服务（FCFS）调度算法。但是万一先来的这位老哥是来贷款的，这一谈就好几个小时，一直占用着窗口，这样后面的人只能干等，或许后面的人只是想简单的取个钱，几分钟就能搞定，却因为前面老哥办长业务而要等几个小时，你说气不气人？</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/23.png" class="">

<p>有客户抱怨了，那我们就要改进，我们干脆优先给那些几分钟就能搞定的人办理业务，这就是短作业优先（SJF）调度算法。听起来不错，但是依然还是有个极端情况，万一办理短业务的人非常的多，这会导致长业务的人一直得不到服务，万一这个长业务是个大客户，那不就捡了芝麻丢了西瓜。</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/24.png" class="">

<p>那就公平起见，现在窗口工作人员规定，每个人我只处理 10 分钟。如果 10 分钟之内处理完，就马上换下一个人。如果没处理完，依然换下一个人，但是客户自己得记住办理到哪个步骤了。这个也就是时间片轮转（RR）调度算法。但是如果时间片设置过短，那么就会造成大量的上下文切换，增大了系统开销。如果时间片过长，相当于退化成 FCFS 算法了。</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/25.png" class="">

<p>既然公平也可能存在问题，那银行就对客户分等级，分为普通客户、VIP 客户、SVIP 客户。只要高优先级的客户一来，就第一时间处理这个客户，这就是最高优先级（HPF）调度算法。但依然也会有极端的问题，万一当天来的全是高级客户，那普通客户不是没有被服务的机会，不把普通客户当人是吗？那我们把优先级改成动态的，如果客户办理业务时间增加，则降低其优先级，如果客户等待时间增加，则升高其优先级。</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/26.png" class="">

<p>那有没有兼顾到公平和效率的方式呢？这里介绍一种算法，考虑的还算充分的，多级反馈队列（MFQ）调度算法，它是时间片轮转算法和优先级算法的综合和发展。它的工作方式：</p>
<img src="/2022/01/11/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/27.png" class="">

<ul>
<li>银行设置了多个排队（就绪）队列，每个队列都有不同的优先级，各个队列优先级从高到低，同时每个队列执行时间片的长度也不同，优先级越高的时间片越短。</li>
<li>新客户（进程）来了，先进入第一级队列的末尾，按先来先服务原则排队等待被叫号（运行）。如果时间片用完客户的业务还没办理完成，则让客户进入到下一级队列的末尾，以此类推，直至客户业务办理完成。</li>
<li>当第一级队列没人排队时，就会叫号二级队列的客户。如果客户办理业务过程中，有新的客户加入到较高优先级的队列，那么此时办理中的客户需要停止办理，回到原队列的末尾等待再次叫号，因为要把窗口让给刚进入较高优先级队列的客户。</li>
</ul>
<p>可以发现，对于要办理短业务的客户来说，可以很快的轮到并解决。对于要办理长业务的客户，一下子解决不了，就可以放到下一个队列，虽然等待的时间稍微变长了，但是轮到自己的办理时间也变长了，也可以接受，不会造成极端的现象，可以说是综合上面几种算法的优点。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/" rel="tag">计算机组成</a></li></ul>

    </footer>
  </div>

   
   
  
</article>

    
    <article
  id="post-操作系统/为什么0.1+0.2不等于0.3"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/"
    >为什么0.1+0.2不等于0.3</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/" class="article-date">
  <time datetime="2021-12-29T11:13:32.000Z" itemprop="datePublished">2021-12-29</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/">计算机组成</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="为什么负数要用补码表示"><a href="#为什么负数要用补码表示" class="headerlink" title="为什么负数要用补码表示"></a>为什么负数要用补码表示</h1><p>十进制数转二进制采用的是除 2 取余法，比如数字 8 转二进制的过程：</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/30.png" class="">

<p>整数类型的数字在计算机的存储⽅式，就是将十进制的数字转换成二进制即可。</p>
<p>以<code>int</code>类型的数字作为例，<code>int</code>类型是 32 位的，其中最⾼位是作为「符号标志位」，正数的符号位是 0 ，负数的符号位是 1 ，剩余的 31 位则表示二进制数据。</p>
<p>那么，对于<code>int</code>类型的数字 1 的二进制数表示如下：</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/31.png" class="">

<p>而负数就比较特殊了点，负数在计算机中是以补码表示的，所谓的补码就是把正数的二进制全部取反再加 1，比如 -1 的二进制是把数字 1 的二进制取反后再加 1：</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/32.png" class="">

<p>为什么计算机要用补码的⽅式来表示负数？在回答这个问题前，我们假设不用补码的⽅式来表示负数，而只是把最⾼位的符号标志位变为 1 表示负数，如下图过程：</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/33.png" class="">

<p>如果采用这种⽅式来表示负数的二进制的话，试想⼀下<code>-2 + 1</code>的运算过程：</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/34.png" class="">
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/35.png" class="">

<p>按道理，<code>-2 + 1 = -1</code>，但是上⾯的运算过程中得到结果却是 -3，可以发现，这种负数的表示⽅式是不能用常规的加法来计算了，需要特殊处理，要先判断数字是否为负数，如果是负数就要把加法操作变成减法操作才可以得到正确对结果。</p>
<p>到这⾥，我们就可以回答前⾯提到的「负数为什么要用补码⽅式来表示」的问题了。</p>
<p>如果负数不是使用补码的⽅式表示，则在做基本对加减法运算的时候，还需要多⼀步操作来判断是否为负数，如果为负数，还得把加法反转成减法，或者把减法反转成加法，这就⾮常不好了，毕竟加减法运算在计算机⾥是很常使用的，所以为了性能考虑，应该要尽量简化这个运算过程。</p>
<p>而用了补码的表示⽅式，对于负数的加减法操作，实际上是和正数加减法操作⼀样的。你可以看到下图，用补码表示的负数在运算<code>-2+1</code>过程的时候，其结果是正确的：</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/36.png" class="">

<h1 id="十进制小数与二进制的转换"><a href="#十进制小数与二进制的转换" class="headerlink" title="十进制小数与二进制的转换"></a>十进制小数与二进制的转换</h1><p>整数十进制转二进制我们知道了，接下来看看小数是怎么转二进制的，小数部分的转换不同于整数部分，它采用的是乘 2 取整法，将十进制中的小数部分乘以 2 作为二进制的⼀位，然后继续取小数部分乘以 2 作为下⼀位，直到不存在小数为止。</p>
<p>以 8.625 转二进制作为例：</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/38.png" class="">

<p>最后把「整数部分 + 小数部分」结合在⼀起后，其结果就是<code>1000.101</code>。</p>
<p>但是，并不是所有小数都可以用二进制表示，前⾯提到的 0.625 小数是⼀个特例，刚好通过乘 2 取整法的⽅式完整的转换成二进制。</p>
<p>如果我们用相同的⽅式，来把 0.1 转换成二进制，过程如下：</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/39.png" class="">

<p>可以发现， 0.1 的二进制表示是⽆限循环的。</p>
<p>由于计算机的资源是有限的，所以是没办法用二进制精确的表示 0.1，只能用近似值来表示，就是在有限的精度情况下，最⼤化接近 0.1 的二进制数，于是就会造成精度缺失的情况。</p>
<p>对于二进制小数转十进制时，需要注意⼀点，小数点后⾯的指数幂是负数。</p>
<p>比如，二进制<code>0.1</code>转成十进制就是 2<sup>-1</sup>，也就是十进制 0.5 ，二进制 0.01 转成十进制就是2<sup>-2</sup>，也就是十进制 0.25，以此类推。</p>
<p>举个例⼦，二进制<code>1010.101</code>转十进制的过程，如下图：</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/40.png" class="">

<h1 id="计算机是怎么存小数的"><a href="#计算机是怎么存小数的" class="headerlink" title="计算机是怎么存小数的"></a>计算机是怎么存小数的</h1><p><code>1000.101</code>这种二进制小数是「定点数」形式，代表着小数点是定死的，不能移动，如果你移动了它的小数点，这个数就变了，就不再是它原来的值了。</p>
<p>然而，计算机并不是这样存储小数的，计算机存储小数采用的是浮点数，名字⾥的「浮点」表示小数点是可以浮动的。</p>
<p>比如<code>1000.101</code>这个二进制数，可以表示成 1.000101x2<sup>3</sup>，类似于数学上的科学记数法。</p>
<p>科学记数法在小数点左边只有⼀个数字，而且把这种整数部分没有前导 0 的数字称为规格化，比如 1.0x10<sup>-9</sup> 是规格化的科学记数法，而 0.1x10<sup>-9</sup> 和 10.0 x 10<sup>-9</sup> 就不是了。</p>
<p>因此，如果二进制要用到科学记数法，同时要规范化，那么不仅要保证基数为 2，还要保证小数点左侧只有 1 位，而且必须为 1。</p>
<p>所以通常将<code>1000.101</code>这种二进制数，规格化表示成 1.000101x2<sup>3</sup>，其中，最为关键的是<code>000101</code>和 3 这两个东⻄，它就可以包含了这个二进制小数的所有信息：</p>
<ul>
<li><code>000101</code>称为尾数，即小数点后⾯的数字；</li>
<li>3 称为指数，指定了小数点在数据中的位置；</li>
</ul>
<p>现在绝⼤多数计算机使用的浮点数，⼀般采用的是 IEEE 制定的国际标准，这种标准形式如下图：</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/41.png" class="">

<p>这三个重要部分的意义如下：</p>
<ul>
<li>符号位：表示数字是正数还是负数，为 0 表示正数，为 1 表示负数；</li>
<li>指数位：指定了小数点在数据中的位置，指数可以是负数，也可以是正数，指数位的⻓度越⻓则数值的表达范围就越⼤；</li>
<li>尾数位：小数点右侧的数字，也就是小数部分，比如二进制 1.0011x2<sup>-2</sup>，尾数部分就是<code>0011</code>，而且尾数的⻓度决定了这个数的精度，因此如果要表示精度更⾼的小数，则就要提⾼尾数位的⻓度；</li>
</ul>
<p>用 32 位来表示的浮点数，则称为单精度浮点数，也就是<code>float</code>变量，而用 64 位来表示的浮点数，称为双精度浮点数，也就是<code>double</code>变量，它们的结构如下：</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/42.png" class="">

<p>可以看到：</p>
<ul>
<li><code>double</code>的尾数部分是 52 位，<code>float</code>的尾数部分是 23 位，由于同时都带有⼀个固定隐含位，所以<code>double</code>有 53 个二进制有效位，<code>float</code>有 24 个二进制有效位，所以它们的精度在十进制中分别是<code>log10(2^53)</code>约等于 15.95 和<code>log10(2^24)</code>约等于 7.22 位，因此<code>double</code>的有效数字是<code>15~16</code>位，<code>float</code>的有效数字是<code>7~8</code>位，这些是有效位是包含整数部分和小数部分；</li>
<li><code>double</code>的指数部分是 11 位，而<code>float</code>的指数位是 8 位，意味着<code>double</code>相比<code>float</code>能表示更⼤的数值范围；</li>
</ul>
<p>那二进制小数，是如何转换成二进制浮点数的呢？</p>
<p>以 10.625 作为例⼦，看看这个数字在<code>float</code>⾥是如何存储的。</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/43.png" class="">

<p>⾸先，我们计算出 10.625 的二进制小数为<code>1010.101</code>。</p>
<p>然后把小数点，移动到第⼀个有效数字后⾯，即将<code>1010.101</code>右移 3 位成<code>1.010101</code>，右移 3 位就代表 +3，左移 3 位就是 -3。</p>
<p><code>float</code>中的「指数位」就跟这⾥移动的位数有关系，把移动的位数再加上「偏移量」，<code>float</code>的话偏移量是 127，相加后就是指数位的值了，即指数位这 8 位存的是 10000010 （十进制 130），因此你可以认为「指数位」相当于指明了小数点在数据中的位置。</p>
<p><code>1.010101</code>这个数的小数点右侧的数字就是<code>float</code>⾥的「尾数位」，由于尾数位是 23 位，则后⾯要补充 0，所以最终尾数位存储的数字是<code>01010100000000000000000</code>。</p>
<p>在算指数的时候，你可能会有疑问为什么要加上偏移量呢？</p>
<p>指数可能是正数，也可能是负数，即指数是有符号的整数，而有符号整数的计算是比⽆符号整数麻烦的，所以为了减少不必要的麻烦，在实际存储指数的时候，需要把指数转换成⽆符号整数。</p>
<p><code>float</code>的指数部分是 8 位，IEEE 标准规定单精度浮点的指数取值范围是<code>-126~+127</code>，于是为了把指数转换成⽆符号整数，就要加个偏移量，比如<code>float</code>的指数偏移量是 127，这样指数就不会出现负数了。</p>
<p>比如，指数如果是 8，则实际存储的指数是 8 + 127（偏移量）&#x3D; 135，即把 135 转换为二进制之后再存储，而当我们需要计算实际的十进制数的时候，再把指数减去「偏移量」即可。</p>
<p>移动后的小数点左侧的有效位（即 1）消失了，它并没有存储到<code>float</code>⾥。</p>
<p>这是因为 IEEE 标准规定，二进制浮点数的小数点左侧只能有 1 位，并且还只能是 1，既然这⼀位永远都是 1，那就可以不用存起来了。</p>
<p>于是就让 23 位尾数只存储小数部分，然后在计算时会⾃动把这个 1 加上，这样就可以节约 1 位的空间，尾数就能多存⼀位小数，相应的精度就更⾼了⼀点。</p>
<p>那么，对于我们在从<code>float</code>的二进制浮点数转换成十进制时，要考虑到这个隐含的 1，转换公式如下：</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/44.png" class="">

<p>举个例⼦，我们把下图这个<code>float</code>的数据转换成十进制，过程如下：</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/45.png" class="">

<h2 id="0-1-0-2-x3D-x3D-0-3"><a href="#0-1-0-2-x3D-x3D-0-3" class="headerlink" title="0.1 + 0.2 &#x3D;&#x3D; 0.3 ?"></a>0.1 + 0.2 &#x3D;&#x3D; 0.3 ?</h2><p>并不是所有小数都可以用「完整」的二进制来表示的，比如十进制 0.1 在转换成二进制小数的时候，是⼀串⽆限循环的二进制数，计算机是⽆法表达⽆限循环的二进制数的，毕竟计算机的资源有限。</p>
<p>因此，计算机只能用近似值来表示该二进制，那么意味着计算机存放的小数可能不是⼀个真实值。现在基本都是用 IEEE 754 规范的单精度浮点类型或双精度浮点类型来存储小数的，根据精度的不同，近似值也会不同。</p>
<p>那计算机是存储 0.1 是⼀个怎么样的二进制浮点数呢？</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/46.png" class="">

<p>可以看到，8 位指数部分是<code>01111011</code>，23 位的尾数部分是<code>10011001100110011001101</code>，可以看到尾数部分是<code>0011</code>是⼀直循环的，只不过尾数是有⻓度限制的，所以只会显示⼀部分，所以是⼀个近似值，精度十分有限。</p>
<p>接下来，我们看看 0.2 的<code>float</code>浮点数：</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/47.png" class="">

<p>可以看到，8 位指数部分是<code>01111100</code>，稍微和 0.1 的指数不同，23 位的尾数部分是<code>10011001100110011001101</code>和 0.1 的尾数部分是相同的，也是⼀个近似值。</p>
<p>0.1 的二进制浮点数转换成十进制的结果是<code>0.100000001490116119384765625</code>：</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/48.png" class="">

<p>0.2 的二进制浮点数转换成十进制的结果是<code>0.20000000298023223876953125</code>：</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/49.png" class="">

<p>这两个结果相加就是<code>0.300000004470348358154296875</code>：</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/50.png" class="">

<p>所以，你会看到在计算机中<code>0.1+0.2</code>并不等于完整的 0.3。</p>
<p>这主要是因为有的小数⽆法可以用「完整」的二进制来表示，所以计算机⾥只能采用近似数的⽅式来保存，那两个近似数相加，得到的必然也是⼀个近似数。</p>
<p>我们在 JavaScript ⾥执⾏<code>0.1+0.2</code>，你会得到下⾯这个结果：</p>
<img src="/2021/12/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E4%B8%BA%E4%BB%80%E4%B9%880.1+0.2%E4%B8%8D%E7%AD%89%E4%BA%8E0.3/51.png" class="">

<p>结果和我们前⾯推到的类似，因为 JavaScript 对于数字都是使用 IEEE 754 标准下的双精度浮点类型来存储的。</p>
<p>而我们二进制只能精准表达 2 除尽的数字 1&#x2F;2, 1&#x2F;4, 1&#x2F;8，但是对于 0.1(1&#x2F;10) 和 0.2(1&#x2F;5)，在二进制中都⽆法精准表示时，需要根据精度舍⼊。</p>
<p>我们⼈类熟悉的十进制运算系统，可以精准表达 2 和 5 除尽的数字，例如 1&#x2F;2, 1&#x2F;4, 1&#x2F;5(0.2), 1&#x2F;8,1&#x2F;10(0.1)。</p>
<p>当然，十进制也有⽆法除尽的地⽅，例如 1&#x2F;3, 1&#x2F;7，也需要根据精度舍⼊。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>为什么负数要用补码表示？</p>
<p>负数之所以用补码的方式来表示，主要是为了统一和正数的加减法操作一样，毕竟数字的加减法是很常用的一个操作，就不要搞特殊化，尽量以统一的方式来运算。</p>
<p>十进制小数怎么转成二进制？</p>
<p>十进制整数转二进制使用的是「除 2 取余法」，十进制小数使用的是「乘 2 取整法」。</p>
<p>计算机是怎么存小数的？</p>
<p>计算机是以浮点数的形式存储小数的，大多数计算机都是 IEEE 754 标准定义的浮点数格式，包含三个部分：</p>
<ul>
<li>符号位：表示数字是正数还是负数，为 0 表示正数，为 1 表示负数；</li>
<li>指数位：指定了小数点在数据中的位置，指数可以是负数，也可以是正数，指数位的长度越长则数值的表达范围就越大；</li>
<li>尾数位：小数点右侧的数字，也就是小数部分，比如二进制 1.0011 x 2^(-2)，尾数部分就是 0011，而且尾数的长度决定了这个数的精度，因此如果要表示精度更高的小数，则就要提高尾数位的长度；</li>
</ul>
<p>用 32 位来表示的浮点数，则称为单精度浮点数，也就是我们编程语言中的<code>float</code>变量，而用 64 位来表示的浮点数，称为双精度浮点数，也就是<code>double</code>变量。</p>
<p>0.1 + 0.2 &#x3D;&#x3D; 0.3 吗？</p>
<p>不是的，0.1 和 0.2 这两个数字用二进制表达会是一个一直循环的二进制数，比如 0.1 的二进制表示为<code>0.0 0011 0011 0011… </code>（0011 无限循环），对于计算机而言，0.1 无法精确表达，这是浮点数计算造成精度损失的根源。</p>
<p>因此，IEEE 754 标准定义的浮点数只能根据精度舍入，然后用「近似值」来表示该二进制，那么意味着计算机存放的小数可能不是一个真实值。</p>
<p>0.1 + 0.2 并不等于完整的 0.3，这主要是因为这两个小数无法用「完整」的二进制来表示，只能根据精度舍入，所以计算机里只能采用近似数的方式来保存，那两个近似数相加，得到的必然也是一个近似数。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/" rel="tag">计算机组成</a></li></ul>

    </footer>
  </div>

   
   
  
</article>

    
    <article
  id="post-操作系统/认识操作系统"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%A4%E8%AF%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"
    >认识操作系统</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%A4%E8%AF%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" class="article-date">
  <time datetime="2021-12-28T11:13:32.000Z" itemprop="datePublished">2021-12-28</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/">计算机组成</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="硬件结构"><a href="#硬件结构" class="headerlink" title="硬件结构"></a>硬件结构</h1><h2 id="图灵机的⼯作⽅式"><a href="#图灵机的⼯作⽅式" class="headerlink" title="图灵机的⼯作⽅式"></a>图灵机的⼯作⽅式</h2><p>图灵的基本思想是⽤机器来模拟⼈们⽤纸笔进⾏数学运算的过程，⽽且还定义了计算机由哪些部分组成，程序⼜是如何执⾏的。</p>
<img src="/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%A4%E8%AF%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1.png" class="">

<p>图灵机的基本组成如下：</p>
<ul>
<li>有⼀条「纸带」，纸带由⼀个个连续的格⼦组成，每个格⼦可以写⼊字符，纸带就好⽐内存，⽽纸带上的格⼦的字符就好⽐内存中的数据或程序；</li>
<li>有⼀个「读写头」，读写头可以读取纸带上任意格⼦的字符，也可以把字符写⼊到纸带的格⼦；</li>
<li>读写头上有⼀些部件，⽐如存储单元、控制单元以及运算单元：</li>
</ul>
<ol>
<li>存储单元⽤于存放数据；</li>
<li>控制单元⽤于识别字符是数据还是指令，以及控制程序的流程等；</li>
<li>运算单元⽤于执⾏运算指令；</li>
</ol>
<p>知道了图灵机的组成后，我们以简单数学运算的<code>1+2</code>作为例⼦，来看看它是怎么执⾏这⾏代码的。</p>
<p>⾸先，⽤读写头把<code>1、2、+</code>这 3 个字符分别写⼊到纸带上的 3 个格⼦，然后读写头先停在 1 字符对应的格⼦上；</p>
<img src="/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%A4%E8%AF%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.png" class="">

<p>接着，读写头读⼊ 1 到存储设备中，这个存储设备称为图灵机的状态；</p>
<img src="/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%A4%E8%AF%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/3.png" class="">

<p>然后读写头向右移动⼀个格，⽤同样的⽅式把 2 读⼊到图灵机的状态，于是现在图灵机的状态中存储着两个连续的数字，1 和 2；</p>
<img src="/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%A4%E8%AF%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/4.png" class="">

<p>读写头再往右移动⼀个格，就会碰到 + 号，读写头读到 + 号后，将 + 号传输给「控制单元」，控制单元发现是⼀个 + 号⽽不是数字，所以没有存⼊到状态中，因为 + 号是运算符指令，作⽤是加和⽬前的状态，于是通知「运算单元」⼯作。运算单元收到要加和状态中的值的通知后，就会把状态中的 1 和 2 读⼊并计算，再将计算的结果 3 存放到状态中；</p>
<img src="/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%A4%E8%AF%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/5.png" class="">

<p>最后，运算单元将结果返回给控制单元，控制单元将结果传输给读写头，读写头向右移动，把结果 3 写⼊到纸带的格⼦中；</p>
<img src="/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%A4%E8%AF%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/6.png" class="">

<p>通过上⾯的图灵机计算 1+2 的过程，可以发现图灵机主要功能就是读取纸带格⼦中的内容，然后交给控制单元识别字符是数字还是运算符指令，如果是数字则存⼊到图灵机状态中，如果是运算符，则通知运算符单元读取状态中的数值进⾏计算，计算结果最终返回给读写头，读写头把结果写⼊到纸带的格⼦中。</p>
<p>事实上，图灵机这个看起来很简单的⼯作⽅式，和我们今天的计算机是基本⼀样的。接下来，我们⼀同再看看当今计算机的组成以及⼯作⽅式。</p>
<h2 id="冯诺依曼模型"><a href="#冯诺依曼模型" class="headerlink" title="冯诺依曼模型"></a>冯诺依曼模型</h2><p>在 1945 年冯诺依曼和其他计算机科学家们提出了计算机具体实现的报告，其遵循了图灵机的设计，⽽且还提出⽤电⼦元件构造计算机，并约定了⽤⼆进制进⾏计算和存储，还定义计算机基本结构为 5 个部分，分别是中央处理器（CPU）、内存、输⼊设备、输出设备、总线。</p>
<img src="/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%A4%E8%AF%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/7.png" class="">

<p>这 5 个部分也被称为冯诺依曼模型，接下来看看这 5 个部分的具体作⽤。</p>
<h3 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h3><p>我们的程序和数据都是存储在内存，存储的区域是线性的。</p>
<p>数据存储的单位是⼀个⼆进制位（<code>bit</code>），即 0 或 1。最⼩的存储单位是字节（<code>byte</code>），1 字节等于 8 位。内存的地址是从 0 开始编号的，然后⾃增排列，最后⼀个地址为内存总字节数 - 1，这种结构好似我们程序⾥的数组，所以内存读写任何⼀个数据的速度都是⼀样的。</p>
<h3 id="中央处理器"><a href="#中央处理器" class="headerlink" title="中央处理器"></a>中央处理器</h3><p>中央处理器也就是我们常说的 CPU，32 位和 64 位 CPU 最主要区别在于⼀次能计算多少字节数据：</p>
<ul>
<li>32 位 CPU ⼀次可以计算 4 个字节；</li>
<li>64 位 CPU ⼀次可以计算 8 个字节；</li>
</ul>
<p>这⾥的 32 位和 64 位，通常称为 CPU 的位宽。</p>
<p>之所以 CPU 要这样设计，是为了能计算更⼤的数值，如果是 8 位的 CPU，那么⼀次只能计算 1 个字节 0~255 范围内的数值，这样就⽆法⼀次完成计算<code>10000*500</code>，于是为了能⼀次计算⼤数的运算，CPU 需要⽀持多个<code>byte</code>⼀起计算，所以 CPU 位宽越⼤，可以计算的数值就越⼤，⽐如说 32 位 CPU 能计算的最⼤整数是 4294967295 。</p>
<p>CPU 内部还有⼀些组件，常⻅的有寄存器、控制单元和逻辑运算单元等。其中，控制单元负责控制 CPU ⼯作，逻辑运算单元负责计算，⽽寄存器可以分为多种类，每种寄存器的功能⼜不尽相同。</p>
<p>CPU 中的寄存器主要作⽤是存储计算时的数据，为什么有了内存还需要寄存器？原因很简单，因为内存离 CPU 太远了，⽽寄存器就在 CPU ⾥，还紧挨着控制单元和逻辑运算单元，⾃然计算时速度会很快。</p>
<p>常⻅的寄存器种类：</p>
<ul>
<li>通⽤寄存器，⽤来存放需要进⾏运算的数据，⽐如需要进⾏加和运算的两个数据。</li>
<li>程序计数器，⽤来存储 CPU 要执⾏下⼀条指令「所在的内存地址」，注意不是存储了下⼀条要执⾏的指令，此时指令还在内存中，程序计数器只是存储了下⼀条指令的地址。</li>
<li>指令寄存器，⽤来存放程序计数器指向的指令，也就是指令本身，指令被执⾏完成之前，指令都存储在这⾥。</li>
</ul>
<h3 id="总线"><a href="#总线" class="headerlink" title="总线"></a>总线</h3><p>总线是⽤于 CPU 和内存以及其他设备之间的通信，总线可分为 3 种：</p>
<ul>
<li>地址总线，⽤于指定 CPU 将要操作的内存地址；</li>
<li>数据总线，⽤于读写内存的数据；</li>
<li>控制总线，⽤于发送和接收信号，⽐如中断、设备复位等信号，CPU 收到信号后⾃然进⾏响应，这时也需要控制总线；</li>
</ul>
<p>当 CPU 要读写内存数据的时候，⼀般需要通过两个总线：</p>
<ul>
<li>⾸先要通过「地址总线」来指定内存的地址；</li>
<li>再通过「数据总线」来传输数据；</li>
</ul>
<h3 id="输⼊、输出设备"><a href="#输⼊、输出设备" class="headerlink" title="输⼊、输出设备"></a>输⼊、输出设备</h3><p>输⼊设备向计算机输⼊数据，计算机经过计算后，把数据输出给输出设备。期间，如果输⼊设备是键盘，按下按键时是需要和 CPU 进⾏交互的，这时就需要⽤到控制总线了。</p>
<h2 id="线路位宽与-CPU-位宽"><a href="#线路位宽与-CPU-位宽" class="headerlink" title="线路位宽与 CPU 位宽"></a>线路位宽与 CPU 位宽</h2><p>数据是如何通过线路传输的呢？其实是通过操作电压，低电压表示 0，⾼压电压则表示 1。</p>
<p>如果构造了⾼低⾼这样的信号，其实就是 101 ⼆进制数据，⼗进制则表示 5，如果只有⼀条线路，就意味着每次只能传递<code>1 bit</code>的数据，即 0 或 1，那么传输 101 这个数据，就需要 3 次才能传输完成，这样的效率⾮常低。</p>
<p>这样⼀位⼀位传输的⽅式，称为串⾏，下⼀个<code>bit</code>必须等待上⼀个<code>bit</code>传输完成才能进⾏传输。当然，想⼀次多传⼀些数据，增加线路即可，这时数据就可以并⾏传输。</p>
<p>为了避免低效率的串⾏传输的⽅式，线路的位宽最好⼀次就能访问到所有的内存地址。CPU 要想操作的内存地址就需要地址总线，如果地址总线只有 1 条，那每次只能表示 0 或 1 这两种情况，所以 CPU ⼀次只能操作 2 个内存地址，如果想要 CPU 操作 4G 的内存，那么就需要 32 条地址总线，因为 2<sup>32</sup> &#x3D; 4G。</p>
<p>知道了线路位宽的意义后，我们再来看看 CPU 位宽。</p>
<p>CPU 的位宽最好不要⼩于线路位宽，⽐如 32 位 CPU 控制 40 位宽的地址总线和数据总线的话，⼯作起来就会⾮常复杂且麻烦，所以 32 位的 CPU 最好和 32 位宽的线路搭配，因为 32 位 CPU ⼀次最多只能操作 32 位宽的地址总线和数据总线。</p>
<p>如果⽤ 32 位 CPU 去加和两个 64 位⼤⼩的数字，就需要把这 2 个 64 位的数字分成 2 个低位 32 位数字和 2 个⾼位 32 位数字来计算，先加个两个低位的 32 位数字，算出进位，然后加和两个⾼位的 32 位数字，最后再加上进位，就能算出结果了，可以发现 32 位 CPU 并不能⼀次性计算出加和两个 64 位数字的结果。</p>
<p>对于 64 位 CPU 就可以⼀次性算出加和两个 64 位数字的结果，因为 64 位 CPU 可以⼀次读⼊ 64 位的数字，并且 64 位 CPU 内部的逻辑运算单元也⽀持 64 位数字的计算。</p>
<p>但是并不代表 64 位 CPU 性能⽐ 32 位 CPU ⾼很多，很少应⽤需要算超过 32 位的数字，所以如果计算的数额不超过 32 位数字的情况下，32 位和 64 位 CPU 之间没什么区别的，只有当计算超过 32 位数字的情况下，64 位的优势才能体现出来。</p>
<p>另外，32 位 CPU 最⼤只能操作 4GB 内存，就算装了 8GB 内存条也没⽤。⽽ 64 位 CPU 寻址范围则很⼤，理论最⼤的寻址空间为 2<sup>64</sup>。</p>
<h2 id="程序执⾏的基本过程"><a href="#程序执⾏的基本过程" class="headerlink" title="程序执⾏的基本过程"></a>程序执⾏的基本过程</h2><p>在前⾯，我们知道了程序在图灵机的执⾏过程，接下来我们来看看程序在冯诺依曼模型上是怎么执⾏的。</p>
<p>程序实际上是⼀条⼀条指令，所以程序的运⾏过程就是把每⼀条指令⼀步⼀步的执⾏起来，负责执⾏指令的就是 CPU 了。</p>
<img src="/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%A4%E8%AF%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/8.png" class="">

<p>CPU 执⾏程序的过程如下：</p>
<ul>
<li>第⼀步，CPU 读取「程序计数器」的值，这个值是指令的内存地址，然后 CPU 的「控制单元」操作「地址总线」指定需要访问的内存地址，接着通知内存设备准备数据，数据准备好后通过「数据总线」将指令数据传给 CPU，CPU 收到内存传来的数据后，将这个指令数据存⼊到「指令寄存器」。</li>
<li>第⼆步，CPU 分析「指令寄存器」中的指令，确定指令的类型和参数，如果是计算类型的指令，就把指令交给「逻辑运算单元」运算；如果是存储类型的指令，则交由「控制单元」执⾏；</li>
<li>第三步，CPU 执⾏完指令后，「程序计数器」的值⾃增，表示指向下⼀条指令。这个⾃增的⼤⼩，由 CPU 的位宽决定，⽐如 32 位的 CPU，指令是 4 个字节，需要 4 个内存地址存放，因此「程序计数器」的值会⾃增 4；</li>
</ul>
<p>简单总结⼀下就是，⼀个程序执⾏的时候，CPU 会根据程序计数器⾥的内存地址，从内存⾥⾯把需要执⾏的指令读取到指令寄存器⾥⾯执⾏，然后根据指令⻓度⾃增，开始顺序读取下⼀条指令。</p>
<p>CPU 从程序计数器读取指令、到执⾏、再到下⼀条指令，这个过程会不断循环，直到程序执⾏结束，这个不断循环的过程被称为 CPU 的指令周期。</p>
<h2 id="a-x3D-1-2-执⾏具体过程"><a href="#a-x3D-1-2-执⾏具体过程" class="headerlink" title="a&#x3D;1+2 执⾏具体过程"></a>a&#x3D;1+2 执⾏具体过程</h2><p>知道了基本的程序执⾏过程后，接下来⽤<code>a =1+2</code>的作为例⼦，进⼀步分析该程序在冯诺伊曼模型的执⾏过程。</p>
<p>CPU 是不认识<code>a=1+2</code>这个字符串，这些字符串只是⽅便我们程序员认识，要想这段程序能跑起来，还需要把整个程序翻译成汇编语⾔的程序，这个过程称为编译成汇编代码。</p>
<p>针对汇编代码，我们还需要⽤汇编器翻译成机器码，这些机器码由 0 和 1 组成的机器语⾔，这⼀条条机器码，就是⼀条条的计算机指令，这个才是 CPU 能够真正认识的东⻄。</p>
<p>下⾯来看看<code>a=1+2</code>在 32 位 CPU 的执⾏过程。</p>
<p>程序编译过程中，编译器通过分析代码，发现 1 和 2 是数据，于是程序运⾏时，内存会有个专⻔的区域来存放这些数据，这个区域就是「数据段」。如下图，数据 1 和 2 的区域位置：</p>
<ul>
<li>数据 1 被存放到<code>0x104</code>位置；</li>
<li>数据 2 被存放到<code>0x100</code>位置；</li>
</ul>
<p>注意，数据和指令是分开区域存放的，存放指令区域的地⽅称为「正⽂段」。</p>
<img src="/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%A4%E8%AF%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/9.png" class="">

<p>编译器会把<code>a=1+2</code>翻译成 4 条指令，存放到正⽂段中。如图，这 4 条指令被存放到了<code>0x200~0x20c</code>的区域中：</p>
<ul>
<li><code>0x200</code>的内容是<code>load</code>指令将<code>0x100</code>地址中的数据 2 装⼊到寄存器 R0；</li>
<li><code>0x204</code>的内容是<code>load</code>指令将<code>0x104</code>地址中的数据 1 装⼊到寄存器 R1；</li>
<li><code>0x208</code>的内容是<code>add</code>指令将寄存器 R0 和 R1 的数据相加，并把结果存放到寄存器 R2；</li>
<li><code>0x20c</code>的内容是<code>store</code>指令将寄存器 R2 中的数据存回数据段中的<code>0x108</code>地址中，这个地址也就是变量<code>a</code>内存中的地址；</li>
</ul>
<p>编译完成后，具体执⾏程序的时候，程序计数器会被设置为 0x200 地址，然后依次执⾏这 4 条指令。</p>
<p>上⾯的例⼦中，由于是在 32 位 CPU 执⾏的，因此⼀条指令是占 32 位⼤⼩，所以你会发现每条指令间隔 4 个字节。</p>
<p>⽽数据的⼤⼩是根据你在程序中指定的变量类型，⽐如<code>int</code>类型的数据则占 4 个字节，<code>char</code>类型的数据则占 1 个字节。</p>
<h3 id="指令"><a href="#指令" class="headerlink" title="指令"></a>指令</h3><p>上⾯的例⼦中，图中指令的内容是简易的汇编代码，⽬的是为了⽅便理解指令的具体内容，事实上指令的内容是⼀串⼆进制数字的机器码，每条指令都有对应的机器码，CPU 通过解析机器码来知道指令的内容。</p>
<p>不同的 CPU 有不同的指令集，也就是对应着不同的汇编语⾔和不同的机器码，接下来选⽤最简单的 MIPS 指集，来看看机器码是如何⽣成的，这样也能明⽩⼆进制的机器码的具体含义。</p>
<p>MIPS 的指令是⼀个 32 位的整数，⾼ 6 位代表着操作码，表示这条指令是⼀条什么样的指令，剩下的 26 位不同指令类型所表示的内容也就不相同，主要有三种类型R、I 和 J。</p>
<img src="/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%A4%E8%AF%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/10.png" class="">

<p>这三种类型的含义：</p>
<ul>
<li>R 指令，⽤在算术和逻辑操作，⾥⾯由读取和写⼊数据的寄存器地址。如果是逻辑位移操作，后⾯还有位移操作的「位移量」，⽽最后的「功能码」则是再前⾯的操作码不够的时候，扩展操作码来表示对应的具体指令的；</li>
<li>I 指令，⽤在数据传输、条件分⽀等。这个类型的指令，就没有了位移量和操作码，也没有了第三个寄存器，⽽是把这三部分直接合并成了⼀个地址值或⼀个常数；</li>
<li>J 指令，⽤在跳转，⾼ 6 位之外的 26 位都是⼀个跳转后的地址；</li>
</ul>
<p>接下来，我们把前⾯例⼦的这条指令：「<code>add</code>指令将寄存器 R0 和 R1 的数据相加，并把结果放⼊到 R2」，翻译成机器码。</p>
<img src="/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%A4%E8%AF%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/11.png" class="">

<p>加和运算<code>add</code>指令是属于 R 指令类型：</p>
<ul>
<li><code>add</code>对应的 MIPS 指令⾥操作码是<code>000000</code>，以及最末尾的功能码是<code>100000</code>，这些数值都是固定的，查⼀下 MIPS 指令集的⼿册就能知道的；</li>
<li><code>rs</code>代表第⼀个寄存器 R0 的编号，即<code>00000</code>；</li>
<li><code>rt</code>代表第⼆个寄存器 R1 的编号，即<code>00001</code>；</li>
<li><code>rd</code>代表⽬标的临时寄存器 R2 的编号，即 00010；</li>
</ul>
<p>因为不是位移操作，所以位移量是<code>00000</code>把上⾯这些数字拼在⼀起就是⼀条 32 位的 MIPS 加法指令了，那么⽤ 16 进制表示的机器码则是<code>0x00011020</code>。</p>
<p>编译器在编译程序的时候，会构造指令，这个过程叫做指令的编码。CPU 执⾏程序的时候，就会解析指令，这个过程叫作指令的解码。</p>
<p>现代⼤多数 CPU 都使⽤来流⽔线的⽅式来执⾏指令，所谓的流⽔线就是把⼀个任务拆分成多个⼩任务，于是⼀条指令通常分为 4 个阶段，称为 4 级流⽔线，如下图：</p>
<img src="/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%A4%E8%AF%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/12.png" class="">

<p>四个阶段的具体含义：</p>
<ol>
<li>CPU 通过程序计数器读取对应内存地址的指令，这个部分称为<code>Fetch</code>（取得指令）；</li>
<li>CPU 对指令进⾏解码，这个部分称为<code>Decode</code>（指令译码）；</li>
<li>CPU 执⾏指令，这个部分称为<code>Execution</code>（执⾏指令）；</li>
<li>CPU 将计算结果存回寄存器或者将寄存器的值存⼊内存，这个部分称为<code>Store</code>（数据回写）；</li>
</ol>
<p>上⾯这 4 个阶段，我们称为指令周期，CPU 的⼯作就是⼀个周期接着⼀个周期，周⽽复始。</p>
<p>事实上，不同的阶段其实是由计算机中的不同组件完成的：</p>
<ul>
<li>取指令的阶段，我们的指令是存放在存储器⾥的，实际上，通过程序计数器和指令寄存器取出指令的过程，是由控制器操作的；</li>
<li>指令的译码过程，也是由控制器进⾏的；</li>
<li>指令执⾏的过程，⽆论是进⾏算术操作、逻辑操作，还是进⾏数据传输、条件分⽀操作，都是由算术逻辑单元操作的，也就是由运算器处理的。但是如果是⼀个简单的⽆条件地址跳转，则是直接在控制器⾥⾯完成的，不需要⽤到运算器。</li>
</ul>
<img src="/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%A4%E8%AF%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/13.png" class="">

<h3 id="指令的类型"><a href="#指令的类型" class="headerlink" title="指令的类型"></a>指令的类型</h3><p>指令从功能⻆度划分，可以分为 5 ⼤类：</p>
<ul>
<li>数据传输类型的指令，⽐如<code>store/load</code>是寄存器与内存间数据传输的指令，<code>mov</code>是将⼀个内存地址的数据移动到另⼀个内存地址的指令；</li>
<li>运算类型的指令，⽐如加减乘除、位运算、⽐较⼤⼩等等，它们最多只能处理两个寄存器中的数据；</li>
<li>跳转类型的指令，通过修改程序计数器的值来达到跳转执⾏指令的过程，⽐如编程中常⻅的<code>if else、swtich-case</code>、函数调⽤等。</li>
<li>信号类型的指令，⽐如发⽣中断的指令<code>trap</code>；</li>
<li>闲置类型的指令，⽐如指令<code>nop</code>，执⾏后 CPU 会空转⼀个周期；</li>
</ul>
<h3 id="指令的执⾏速度"><a href="#指令的执⾏速度" class="headerlink" title="指令的执⾏速度"></a>指令的执⾏速度</h3><p>CPU 的硬件参数都会有 GHz 这个参数，⽐如⼀个 1 GHz 的 CPU，指的是时钟频率是 1 G，代表着 1 秒会产⽣ 1G 次数的脉冲信号，每⼀次脉冲信号⾼低电平的转换就是⼀个周期，称为时钟周期。</p>
<p>对于 CPU 来说，在⼀个时钟周期内，CPU 仅能完成⼀个最基本的动作，时钟频率越⾼，时钟周期就越短，⼯作速度也就越快。</p>
<p>⼀个时钟周期⼀定能执⾏完⼀条指令吗？答案是不⼀定的，⼤多数指令不能在⼀个时钟周期完成，通常需要若⼲个时钟周期。不同的指令需要的时钟周期是不同的，加法和乘法都对应着⼀条 CPU 指令，但是乘法需要的时钟周期就要⽐加法多。</p>
<p>程序执⾏的时候，耗费的 CPU 时间少就说明程序是快的，对于程序的 CPU 执⾏时间，我们可以拆解成 CPU 时钟周期数（CPU Cycles）和时钟周期时间（Clock Cycle Time）的乘积。</p>
<img src="/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%A4%E8%AF%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/14.png" class="">

<p>时钟周期时间就是我们前⾯提及的 CPU 主频，主频越⾼说明 CPU 的⼯作速度就越快，⽐如电脑的 CPU 是 2.4GHz 四核 Intel Core i5，这⾥的 2.4GHz 就是电脑的主频，时钟周期时间就是 1&#x2F;2.4G。</p>
<p>要想 CPU 跑的更快，⾃然缩短时钟周期时间，也就是提升 CPU 主频，但是今⾮彼⽇，摩尔定律早已失效，当今的 CPU 主频已经很难再做到翻倍的效果了。</p>
<p>另外，换⼀个更好的 CPU，这个也是我们软件⼯程师控制不了的事情，我们应该把⽬光放到另外⼀个乘法因⼦ —— CPU 时钟周期数，如果能减少程序所需的 CPU 时钟周期数量，⼀样也是能提升程序的性能的。</p>
<p>对于 CPU 时钟周期数我们可以进⼀步拆解成：「指令数 x 每条指令的平均时钟周期数（Cycles Per Instruction，简称 CPI ）」，于是程序的 CPU 执⾏时间的公式可变成如下：</p>
<img src="/2021/12/28/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%AE%A4%E8%AF%86%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/15.png" class="">

<p>因此，要想程序跑的更快，优化这三者即可：</p>
<ul>
<li>指令数，表示执⾏程序所需要多少条指令，以及哪些指令。这个层⾯是基本靠编译器来优化，毕竟同样的代码，在不同的编译器，编译出来的计算机指令会有各种不同的表示⽅式。</li>
<li>每条指令的平均时钟周期数 CPI，表示⼀条指令需要多少个时钟周期数，现代⼤多数 CPU 通过流⽔线技术（Pipline），让⼀条指令需要的 CPU 时钟周期数尽可能的少；</li>
<li>时钟周期时间，表示计算机主频，取决于计算机硬件。有的 CPU ⽀持超频技术，打开了超频意味着把 CPU 内部的时钟给调快了，于是 CPU ⼯作速度就变快了，但是也是有代价的，CPU 跑的越快，散热的压⼒就会越⼤，CPU 会很容易奔溃。</li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/" rel="tag">计算机组成</a></li></ul>

    </footer>
  </div>

   
   
  
</article>

    
    <article
  id="post-网络是怎样连接的/网络是怎样连接的6"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/12/22/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%846/"
    >网络是怎样连接的——响应返回浏览器</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/12/22/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%846/" class="article-date">
  <time datetime="2021-12-22T10:47:09.000Z" itemprop="datePublished">2021-12-22</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">计算机网络</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="服务器概览"><a href="#服务器概览" class="headerlink" title="服务器概览"></a>服务器概览</h1><h2 id="客户端与服务器的区别"><a href="#客户端与服务器的区别" class="headerlink" title="客户端与服务器的区别"></a>客户端与服务器的区别</h2><p>当网络包到达 Web 服务器之后，服务器就会接收这个包并进行处理，但服务器的操作并不是一下子从这里开始的。在服务器启动之后，需要进行各种准备工作，才能接受客户端的访问。因此，处理客户端发来的请求之前，必须先完成相应的准备工作。要理解服务器的工作方式，搞清楚包括这些准备工作在内的服务器整体结构是很重要的，下面我们就来从整体上介绍一下服务器。</p>
<p>根据用途，服务器可以分为很多种类，其硬件和操作系统与客户端是有所不同的。但是，网络相关的部分，如网卡、协议栈、Socket 库等功能和客户端却并无二致。无论硬件和 OS 如何变化，TCP 和 IP 的功能都是一样的，或者说这些功能规格都是统一的。</p>
<p>不过，它们的功能相同，不代表用法也相同。在连接过程中，客户端发起连接操作，而服务器则是等待连接操作，因此在 Socket 库的用法上还是有一些区别的，即应用程序调用的 Socket 库的程序组件不同。</p>
<p>此外，服务器的程序可以同时和多台客户端计算机进行通信，这也是一点区别。因此，服务器程序和客户端程序在结构上是不同的。</p>
<h2 id="服务器程序的结构"><a href="#服务器程序的结构" class="headerlink" title="服务器程序的结构"></a>服务器程序的结构</h2><p>服务器需要同时和多个客户端通信，但一个程序来处理多个客户端的请求是很难的，因为服务器必须把握每一个客户端的操作状态。因此一般的做法是，每有一个客户端连接进来，就启动一个新的服务器程序，确保服务器程序和客户端是一对一的状态。</p>
<p>具体来说，服务器程序的结构如图所示。</p>
<img src="/2021/12/22/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%846/1.png" class="">

<p>首先，我们将程序分成两个模块，即等待连接模块（a）和负责与客户端通信的模块（b）。当服务器程序启动并读取配置文件完成初始化操作后，就会运行等待连接模块（a）。这个模块会创建套接字，然后进入等待连接的暂停状态。接下来，当客户端连发起连接时，这个模块会恢复运行并接受连接，然后启动客户端通信模块（b），并移交完成连接的套接字。接下来，客户端通信模块（b）就会使用已连接的套接字与客户端进行通信，通信结束后，这个模块就退出了。</p>
<p>每次有新的客户端发起连接，都会启动一个新的客户端通信模块（b），因此（b）与客户端是一对一的关系。这样，（b）在工作时就不必考虑其他客户端的连接情况，只要关心自己对应的客户端就可以了。通过这样的方式，可以降低程序编写的难度。服务器操作系统具有多任务、多线程功能，可以同时运行多个程序，服务器程序的设计正是利用了这一功能。</p>
<p>当然，这种方法在每次客户端发起连接时都需要启动新的程序，这个过程比较耗时，响应时间也会相应增加。因此，还有一种方法是事先启动几个客户端通信模块，当客户端发起连接时，从空闲的模块中挑选一个出来将套接字移交给它来处理。</p>
<h2 id="服务器端的套接字和端口号"><a href="#服务器端的套接字和端口号" class="headerlink" title="服务器端的套接字和端口号"></a>服务器端的套接字和端口号</h2><p>下面就来看一看服务器程序是如何调用 Socket 库的。</p>
<p>首先，我们再来回忆一下客户端与服务器的区别。从数据收发的角度来看，区分“客户端”和“服务器”这两个固定的角色似乎不是一个好办法。现在大多数应用都是由客户端去访问服务器，但其实应用的形态不止这一种。为了能够支持各种形态的应用，最好是在数据收发层面不需要区分客户端和服务器，而是能够以左右对称的方式自由发送数据。TCP 也正是在这样的背景下设计出来的。</p>
<p>不过，这其中还是存在一个无法做到左右对称的部分，那就是连接操作。连接这个操作是在有一方等待连接的情况下，另一方才能发起连接，如果双方同时发起连接是不行的，因为在对方没有等待连接的状态下，无法单方面进行连接。因此，只有这个部分必须区分发起连接和等待连接这两个不同的角色。从数据收发的角度来看，这就是客户端与服务器的区别，也就是说，发起连接的一方是客户端，等待连接的一方是服务器。</p>
<p>这个区别体现在如何调用 Socket 库上。首先，客户端的数据收发需要经过下面 4 个阶段。<br>（1）创建套接字（创建套接字阶段）<br>（2）用管道连接服务器端的套接字（连接阶段）<br>（3）收发数据（收发阶段）<br>（4）断开管道并删除套接字（断开阶段）</p>
<p>相对地，服务器是将阶段（2）改成了等待连接，具体如下。<br>（1）创建套接字（创建套接字阶段）<br>（2-1）将套接字设置为等待连接状态（等待连接阶段）<br>（2-2）接受连接（接受连接阶段）<br>（3）收发数据（收发阶段）<br>（4）断开管道并删除套接字（断开阶段）</p>
<p>用伪代码来表示这个过程，如图所示。</p>
<img src="/2021/12/22/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%846/2.png" class="">

<p>首先，协议栈调用<code>socket</code>创建套接字（（1）），这一步和客户端是相同的。</p>
<p>接下来调用<code>bind</code>将端口号写入套接字中（（2-1））。在客户端发起连接的操作中，需要指定服务器端的端口号，这个端口号也就是在这一步设置的。具体的编号是根据服务器程序的种类，按照规则来确定的，例如 Web 服务器使用 80 号端口。</p>
<p>设置好端口号之后，协议栈会调用<code>listen</code>向套接字写入等待连接状态这一控制信息（（2-1））。这样一来，套接字就会开始等待来自客户端的连接网络包。</p>
<p>然后，协议栈会调用<code>accept</code>来接受连接（（2-2））。由于等待连接的模块在服务器程序启动时就已经在运行了，所以在刚启动时，应该还没有客户端的连接包到达。可是，包都没来就调用<code>accept</code>接受连接，可能大家会感到有点奇怪，不过没关系，因为如果包没有到达，就会转为等待包到达的状态，并在包到达的时候继续执行接受连接操作。因此，在执行<code>accept</code>的时候，一般来说服务器端都是处于等待包到达的状态，这时应用程序会暂停运行。在这个状态下，一旦客户端的包到达，就会返回响应包并开始接受连接操作。接下来，协议栈会给等待连接的套接字复制一个副本，然后将连接对象等控制信息写入新的套接字中。刚才我们介绍了调用<code>accept</code>时的工作过程，到这里，我们就创建了一个新的套接字，并和客户端套接字连接在一起了。</p>
<img src="/2021/12/22/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%846/3.png" class="">

<p>当<code>accept</code>结束之后，等待连接的过程也就结束了，这时等待连接模块会启动客户端通信模块，然后将连接好的新套接字转交给客户端通信模块，由这个模块来负责执行与客户端之间的通信操作。之后的数据收发操作和刚才说的一样，与客户端的工作过程是相同的。</p>
<p>其实在这一系列操作中，还有一部分没有讲到，那就是在复制出一个新的套接字之后，原来那个处于等待连接状态的套接字会怎么样呢？其实它还会以等待连接的状态继续存在，当再次调用<code>accept</code>，客户端连接包到达时，它又可以再次执行接受连接操作。接受新的连接之后，和刚才一样，协议栈会为这个等待连接的套接字复制一个新的副本，然后让客户端连接到这个新的副本套接字上。像这样每次为新的连接创建新的套接字就是这一步操作的一个关键点。如果不创建新副本，而是直接让客户端连接到等待连接的套接字上，那么就没有套接字在等待连接了，这时如果有其他客户端发起连接就会遇到问题。为了避免出现这样的情况，协议栈采用了这种创建套接字的新副本，并让客户端连接到这个新副本上的方法。</p>
<p>此外，创建新套接字时端口号也是一个关键点。端口号是用来识别套接字的，因此我们以前说不同的套接字应该对应不同的端口号，但如果这样做，这里就会出现问题。因为在接受连接的时候，新创建的套接字副本就必须和原来的等待连接的套接字具有不同的端口号才行。这样一来，比如客户端本来想要连接 80 端口上的套接字，结果从另一个端口号返回了包，这样一来客户端就无法判断这个包到底是要连接的那个对象返回的，还是其他程序返回的。因此，新创建的套接字副本必须和原来的等待连接的套接字具有相同的端口号。</p>
<p>但是这样一来又会引发另一个问题。端口号是用来识别套接字的，如果一个端口号对应多个套接字，就无法通过端口号来定位到某一个套接字了。当客户端的包到达时，如果协议栈只看 TCP 头部中的接收方端口号，是无法判断这个包到底应该交给哪个套接字的。</p>
<p>这个问题可以用下面的方法来解决，即要确定某个套接字时，不仅使用服务器端套接字对应的端口号，还同时使用客户端的端口号再加上 IP 地址，总共使用下面 4 种信息来进行判断。</p>
<ul>
<li>客户端 IP 地址</li>
<li>客户端端口号</li>
<li>服务器 IP 地址</li>
<li>服务器端口号</li>
</ul>
<p>服务器上可能存在多个端口号相同的套接字，但客户端的套接字都是对应不同端口号的，因此我们可以通过客户端的端口号来确定服务器上的某个套接字。不过，使用不同端口号的规则仅限一台客户端的内部，当有多个客户端进行连接时，它们之间的端口号是可以重复的。因此，我们还必须加上客户端的 IP 地址才能进行判断。例如，IP 地址为 198.18.203.154的客户端的 1025 端口，就和 IP 地址为 198.18.142.86 的客户端的 1025 端口对应不同的套接字。如果能够理解上面这些内容，那么关于套接字和端口号的知识就已经掌握得差不多了。</p>
<p>说句题外话，既然通过客户端 IP 地址、客户端端口号、服务器 IP 地 址、服务器端口号这 4 种信息可以确定某个套接字，那么要指代某个套接字时用这 4 种信息就好了，为什么还要使用描述符呢？这个问题很好，不过我们无法用上面 4 种信息来代替描述符。原因是，在套接字刚刚创建好，还没有建立连接的状态下，这 4 种信息是不全的。此外，为了指代一个套接字，使用一种信息（描述符）比使用 4 种信息要简单。出于上面两个原因，应用程序和协议栈之间是使用描述符来指代套接字的。</p>
<p>使用描述符来指代套接字的原因如下。<br>（1）等待连接的套接字中没有客户端 IP 地址和端口号<br>（2）使用描述符这一种信息比较简单</p>
<img src="/2021/12/22/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%846/4.png" class="">

<h1 id="服务器的接收操作"><a href="#服务器的接收操作" class="headerlink" title="服务器的接收操作"></a>服务器的接收操作</h1><h2 id="网卡将接收到的信号转换成数字信息"><a href="#网卡将接收到的信号转换成数字信息" class="headerlink" title="网卡将接收到的信号转换成数字信息"></a>网卡将接收到的信号转换成数字信息</h2><p>现在，客户端发送的网络包已经到达了服务器。</p>
<p>到达服务器的网络包其本质是电信号或者光信号，接收信号的过程和客户端是一样的。</p>
<p>接收操作的第一步是网卡接收到信号，然后将其还原成数字信息。局域网中传输的网络包信号是由 1 和 0 组成的数字信息与用来同步的时钟信号叠加而成的，因此只要从中分离出时钟信号，然后根据时钟信号进行同步，就可以读取并还原出 1 和 0 的数字信息了。</p>
<p>信号的格式随传输速率的不同而不同，因此某些操作过程可能存在细微差异，例如 10BASE-T 的工作方式如图所示。</p>
<img src="/2021/12/22/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%846/5.png" class="">

<p>首先从报头部分提取出时钟信号（①），报头的信号是按一定频率变化的，只要测定这个变化的频率就可以和时钟信号同步了。接下来，按照相同的周期延长时钟信号（②），并在每个时钟周期位置检测信号的变化方向（③）。图中用向上和向下的箭头表示变化方向，实际的信号则是正或负的电压，这里需要检测电压是从正变为负，还是从负变为正，这两种变化方向分别对应 0 和 1 （④）。在图中，向上的箭头为 1，向下的箭头为 0，实际上是从负到正变化为 1，从正到负变化为 0。这样，信号就被还原成数字信息了。</p>
<img src="/2021/12/22/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%846/6.png" class="">

<p>接下来需要根据包末尾的帧校验序列（FCS）来校验错误，即根据校验公式计算刚刚接收到的数字信息，然后与包末尾的 FCS 值进行比较。FCS 值是在发送时根据转换成电信号之前的数字信息进行计算得到的，因此如果根据信号还原出的数字信息与发送前的信息一致，则计算出的 FCS 也应该与包末尾的 FCS 一致。如果两者不一致，则可能是因为噪声等影响导致信号失真，数据产生了错误，这时接收的包是无效的，因此需要丢弃。</p>
<p>当 FCS 一致，即确认数据没有错误时，接下来需要检查 MAC 头部中的接收方 MAC 地址，看看这个包是不是发给自己的。以太网的基本工作方式是将数据广播到整个网络上，只有指定的接收者才接收数据，因此网络中还有很多发给其他设备的数据在传输，如果包的接收者不是自己，那么就需要丢弃这个包。</p>
<p>到这里，接收信号并还原成数字信息的操作就完成了，还原后的数字信息被保存在网卡内部的缓冲区中。上面这些操作都是由网卡的 MAC 模块来完成的。</p>
<p>网卡的 MAC 模块将网络包从信号还原为数字信息，校验 FCS 并存入缓冲区。</p>
<p>在这个过程中，服务器的 CPU 并不是一直在监控网络包的到达，而是在执行其他的任务，因此 CPU 并不知道此时网络包已经到达了。但接下来的接收操作需要 CPU 来参与，因此网卡需要通过中断将网络包到达的事件通知给 CPU。</p>
<p>接下来，CPU 就会暂停当前的工作，并切换到网卡的任务。然后，网卡驱动会开始运行，从网卡缓冲区中将接收到的包读取出来，根据 MAC 头部的以太类型字段判断协议的种类，并调用负责处理该协议的软件。这里，以太类型的值应该是表示 IP 协议，因此会调用 TCP&#x2F;IP 协议栈，并将包转交给它。</p>
<p>网卡驱动会根据 MAC 头部判断协议类型，并将包交给相应的协议栈。</p>
<h2 id="IP-模块的接收操作"><a href="#IP-模块的接收操作" class="headerlink" title="IP 模块的接收操作"></a>IP 模块的接收操作</h2><p>当网络包转交到协议栈时，IP 模块会首先开始工作，检查 IP 头部。IP 模块首先会检查 IP 头部的格式是否符合规范，然后检查接收方 IP 地址，看包是不是发给自己的。当服务器启用类似路由器的包转发功能时，对于不是发给自己的包，会像路由器一样根据路由表对包进行转发。</p>
<p>确认包是发给自己的之后，接下来需要检查包有没有被分片。检查 IP 头部的内容就可以知道是否分片，如果是分片的包，则将包暂时存放在内存中，等所有分片全部到达之后将分片组装起来还原成原始包；如果没有分片，则直接保留接收时的样子，不需要进行重组。到这里，我们就完成了包的接收。</p>
<p>接下来需要检查 IP 头部的协议号字段，并将包转交给相应的模块。例如，如果协议号为 06（十六进制），则将包转交给 TCP 模块；如果是 11（十六进制），则转交给 UDP 模块。这里我们假设这个包被交给 TCP 模块处理，然后继续往下看。</p>
<p>协议栈的 IP 模块会检查 IP 头部，（1）判断是不是发给自己的；（2）判断网络包是否经过分片；（3）将包转交给 TCP 模块或 UDP模块。</p>
<h2 id="TCP-模块如何处理连接包"><a href="#TCP-模块如何处理连接包" class="headerlink" title="TCP 模块如何处理连接包"></a>TCP 模块如何处理连接包</h2><p>前面的步骤对于任何包都是一样的，但后面的 TCP 模块的操作则根据包的内容有所区别。首先，我们来看一下发起连接的包是如何处理的。</p>
<img src="/2021/12/22/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%846/7.png" class="">

<p>当 TCP 头部中的控制位 SYN 为 1 时，表示这是一个发起连接的包（①）。这时，TCP 模块会执行接受连接的操作，不过在此之前，需要先检查包的接收方端口号，并确认在该端口上有没有与接收方端口号相同且正在处于等待连接状态的套接字。如果指定端口号没有等待连接的套接字，则向客户端返回错误通知的包。</p>
<p>如果存在等待连接的套接字，则为这个套接字复制一个新的副本，并将发送方 IP 地址、端口号、序号初始值、窗口大小等必要的参数写入这个套接字中，同时分配用于发送缓冲区和接收缓冲区的内存空间。然后生成代表接收确认的 ACK 号，用于从服务器向客户端发送数据的序号初始值，表示接收缓冲区剩余容量的窗口大小，并用这些信息生成 TCP 头部，委托 IP 模块发送给客户端。</p>
<p>这个包到达客户端之后，客户端会返回表示接收确认的 ACK 号，当这个 ACK 号返回服务器后，连接操作就完成了。</p>
<p>这时，服务器端的程序应该进入调用<code>accept</code>的暂停状态，当将新套接字的描述符转交给服务器程序之后，服务器程序就会恢复运行。</p>
<p>如果收到的是发起连接的包，则 TCP 模块会：</p>
<ul>
<li>确认 TCP 头部的控制位 SYN；</li>
<li>检查接收方端口号；</li>
<li>为相应的等待连接套接字复制一个新的副本；</li>
<li>记录发送方 IP 地址和端口号等信息。</li>
</ul>
<h2 id="TCP-模块如何处理数据包"><a href="#TCP-模块如何处理数据包" class="headerlink" title="TCP 模块如何处理数据包"></a>TCP 模块如何处理数据包</h2><p>接下来我们来看看进入数据收发阶段之后，当数据包到达时 TCP 模块是如何处理的（②）。</p>
<p>首先，TCP 模块会检查收到的包对应哪一个套接字。在服务器端，可能有多个已连接的套接字对应同一个端口号，因此仅根据接收方端口号无法找到特定的套接字。这时我们需要根据 IP 头部中的发送方 IP 地址和接收方 IP 地址，以及 TCP 头部中的接收方端口号和发送方端口号共 4 种信息，找到上述 4 种信息全部匹配的套接字。</p>
<p>找到 4 种信息全部匹配的套接字之后，TCP 模块会对比该套接字中保存的数据收发状态和收到的包的 TCP 头部中的信息是否匹配，以确定数据收发操作是否正常。具体来说，就是根据套接字中保存的上一个序号和数据长度计算下一个序号，并检查与收到的包的 TCP 头部中的序号是否一致。如果两者一致，就说明包正常到达了服务器，没有丢失。这时，TCP 模块会从包中提出数据，并存放到接收缓冲区中，与上次收到的数据块连接起来。这样一来，数据就被还原成分包之前的状态了。</p>
<p>当收到的数据进入接收缓冲区后，TCP 模块就会生成确认应答的 TCP头部，并根据接收包的序号和数据长度计算出 ACK 号，然后委托 IP 模块发送给客户端。</p>
<p>收到的数据块进入接收缓冲区，意味着数据包接收的操作告一段落了。接下来，应用程序会调用 Socket 库的<code>read</code>（③）来获取收到的数据，这时数据会被转交给应用程序。如果应用程序不来获取数据，则数据会被一直保存在缓冲区中，但一般来说，应用程序会在数据到达之前调用<code>read</code>等待数据到达，在这种情况下，TCP 模块在完成接收操作的同时，就会执行将数据转交给应用程序的操作。</p>
<p>然后，控制流程会转移到服务器程序，对收到的数据进行处理，也就是检查 HTTP 请求消息的内容，并根据请求的内容向浏览器返回相应的数据。</p>
<p>收到数据包时，TCP 模块会</p>
<ul>
<li>根据收到的包的发送方 IP 地址、发送方端口号、接收方 IP 地址、接收方端口号找到相对应的套接字；</li>
<li>将数据块拼合起来并保存在接收缓冲区中；</li>
<li>向客户端返回 ACK。</li>
</ul>
<h2 id="TCP-模块的断开操作"><a href="#TCP-模块的断开操作" class="headerlink" title="TCP 模块的断开操作"></a>TCP 模块的断开操作</h2><p>当数据收发完成后，便开始执行断开操作。这个过程和客户端是一样的。在 TCP 协议的规则中，断开操作可以由客户端或服务器任何一方发起，具体的顺序是由应用层协议决定的。Web 中，这一顺序随 HTTP 协议版本不同而不同，在 HTTP1.0 中，是服务器先发起断开操作。</p>
<p>这时，服务器程序会调用 Socket 库的<code>close</code>，TCP 模块会生成一个控制位 FIN 为 1 的 TCP 头部，并委托 IP 模块发送给客户端。当客户端收到这个包之后，会返回一个 ACK 号。接下来客户端调用<code>close</code>，生成一个 FIN 为 1 的 TCP 头部发给服务器，服务器再返回 ACK 号，这时断开操作就完成了。HTTP1.1 中，是客户端先发起断开操作，这种情况下只要将客户端和服务器的操作颠倒一下就可以了。</p>
<p>无论哪种情况，当断开操作完成后，套接字会在经过一段时间后被删除。</p>
<h1 id="Web-服务器程序解释请求消息并作出响应"><a href="#Web-服务器程序解释请求消息并作出响应" class="headerlink" title="Web 服务器程序解释请求消息并作出响应"></a>Web 服务器程序解释请求消息并作出响应</h1><h2 id="将请求的-URI-转换为实际的文件名"><a href="#将请求的-URI-转换为实际的文件名" class="headerlink" title="将请求的 URI 转换为实际的文件名"></a>将请求的 URI 转换为实际的文件名</h2><p>上图展示了服务器程序的工作过程，这个过程不仅限于 Web 服务器，对于各种服务器程序都是共通的，收发数据的过程也是大同小异的。各种服务器程序的不同点在于图中（b）客户端通信部分的第一行调用<code>read</code>后面的如下部分。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[ 处理请求消息内容 ];</span><br></pre></td></tr></table></figure>
<p>上图中只写了一行，但实际上这里应该是一组处理各种工作的程序，或者说这里才是服务器程序的核心部分。</p>
<p>Web 服务器中，上图的<code>read</code>获取的数据内容就是 HTTP 请求消息。服务器程序会根据收到的请求消息中的内容进行相应的处理，并生成响应消息，再通过<code>write</code>返回给客户端。请求消息包括一个称为“方法”的命令，以及表示数据源的 URI（文件路径名），服务器程序会根据这些内容向客户端返回数据，但对于不同的方法和 URI，服务器内部的工作过程会有所不同。</p>
<p>最简单的一种情况如图中的例子所示。</p>
<img src="/2021/12/22/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%846/8.png" class="">

<p>请求方法为 GET，URI 为一个 HTML 文件名。这种情况只要从文件中读出 HTML 文档，然后将其作为响应消息返回就可以了。不过，按照 URI 从磁盘上读取文件并没有这么简单。如果完全按照 URI 中的路径和文件名读取，那就意味着磁盘上所有的文件都可以访问，Web 服务器的磁盘内容就全部暴露了，这很危险。因此，这里需要一些特殊的机制。</p>
<p>Web 服务器公开的目录其实并不是磁盘上的实际目录，而是虚拟目录，而 URI 中写的就是在这个虚拟目录结构下的路径名。因此，当读取文件时，需要先查询虚拟目录与实际目录的对应关系，并将 URI 转换成实际的文件名后，才能读取文件并返回数据。举个例子，假设我们的虚拟目录结构如图所示。</p>
<img src="/2021/12/22/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%846/9.png" class="">

<p>如果请求消息中的 URI 如下页（1）所示，那么因为<code>/~user2/…</code>对应的实际目录为<code>/home/user2/…</code>，所以将 URI 转换成实际文件名后应该是如下页（2）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/~user2/sub-user2/sample.html (1)</span><br><span class="line">/home/user2/sub-user2/sample.html (2)</span><br></pre></td></tr></table></figure>
<p>于是，服务器就会根据上述路径从磁盘中读取相应的文件，然后将数据返回给客户端。</p>
<p>文件名转换是有特例的，比如 URI 中的路径省略了文件名的情况，这时服务器会读取事先设置好的默认文件名。例如在浏览器中输入如下网址。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://www.glasscom.com/tone/</span><br></pre></td></tr></table></figure>
<p>上面这个网址省略了文件名，服务器会在末尾添加默认文件名。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://www.glasscom.com/tone/index.html</span><br></pre></td></tr></table></figure>
<p>在这个例子中，<code>index.html</code>这个文件名是在服务器中设置好的，服务器会将它添加在目录名的后面。</p>
<p>有些 Web 服务器程序还具有文件名改写功能，只要设置好改写的规则，当 URI 中的路径符合改写规则时，就可以将 URI 中的文件名改写成其他的文件名进行访问。当出于某些原因 Web 服务器的目录和文件名发生变化，但又希望用户通过原来的网址进行访问的时候，这个功能非常有用。</p>
<h2 id="运行-CGI-程序"><a href="#运行-CGI-程序" class="headerlink" title="运行 CGI 程序"></a>运行 CGI 程序</h2><p>如果 URI 指定的文件内容为 HTML 文档或图片，那么只要直接将文件内容作为响应消息返回客户端就可以了。但 URI 指定的文件内容不仅限于 HTML 文档，也有可能是一个程序。在这个情况下，服务器不会直接返回文件内容，而是会运行这个程序，然后将程序输出的数据返回给客户端。Web 服务器可以启动的程序有几种类型，每种类型的具体工作方式有所区别，下面我们来看看 CGI 程序是如何工作的。</p>
<p>当需要 Web 服务器运行程序时，浏览器发送的 HTTP 请求消息内容会和访问 HTML 文档时不太一样。Web 服务器运行程序时，一般来说浏览器会将需要程序处理的数据放在 HTTP 请求消息中发送给服务器。这些数据有很多种类，例如购物网站订单表中的品名、数量、发货地址等，搜索引擎中输入的关键字也是一个常见的例子。</p>
<p>总之，浏览器需要在发送给 Web 服务器的请求消息中加入一些数据。</p>
<p>有两种加入数据的方法。一种是在 HTML 文档的表单中加上<code>method=&quot;GET&quot;</code>，通过 HTTP 的 GET 方法，将输入的数据作为参数添加在 URI 后面发送给服务器。另一种方法是在 HTML 文档的表单中加上<code>method=&quot;POST&quot;</code>，将数据放在 HTTP 请求消息的消息体中发送给服务器。</p>
<img src="/2021/12/22/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%846/10.png" class="">

<p>收到请求消息之后，Web 服务器会进行下面的工作。首先，Web 服务器会检查 URI 指定的文件名，看一看这个文件是不是一个程序。这里的判断方法是在 Web 服务器中事先设置好的，一般是通过文件的扩展名来进行判断，例如将<code>.cgi、.php</code>等扩展名的文件设置为程序，当遇到这些文件时，Web 服务器就会将它们作为程序来对待。也可以设置一个存放程序的目录，将这个目录下的所有文件都作为程序来对待。此外，还可以根据文件的属性来进行判断。</p>
<p>如果判断要访问的文件为程序文件，Web 服务器会委托操作系统运行这个程序，然后从请求消息中取出数据并交给运行的程序。如果方法为 GET，则将 URI 后面的参数传递给程序；如果方法为 POST，则将消息体中的数据传递给程序。</p>
<img src="/2021/12/22/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%846/11.png" class="">

<p>接下来，运行的程序收到数据后会进行一系列处理，并将输出的数据返回给 Web 服务器。程序可以返回各种内容，如表示订单已接受的说明，或者按照关键字从数据库中搜索出的结果等。无论如何，为了将数据处理的结果返回给客户端，首先需要将它返回给 Web 服务器。这些输出的数据一般来说会嵌入到 HTML 文档中，因此 Web 服务器可以直接将其作为响应消息返回给客户端。输出数据的内容是由运行的程序生成的，Web 服务器并不过问，也不会去改变程序输出的内容。</p>
<h2 id="Web-服务器的访问控制"><a href="#Web-服务器的访问控制" class="headerlink" title="Web 服务器的访问控制"></a>Web 服务器的访问控制</h2><p>Web 服务器的基本工作方式就是根据请求消息的内容判断数据源，并从中获取数据返回给客户端，不过在执行这些操作之前，Web 服务器还可以检查事先设置的一些规则，并根据规则允许或禁止访问。这种根据规则判断是否允许访问的功能称为访问控制，一些会员制的信息服务需要限制用户权限的时候会使用这一功能，公司里也可以利用访问控制只允许某些特定部门访问。</p>
<p>Web 服务器的访问控制规则主要有以下 3 种。</p>
<ol>
<li>客户端 IP 地址</li>
<li>客户端域名</li>
<li>用户名和密码</li>
</ol>
<p>以上规则可针对作为数据源的文件和目录进行设置，当收到客户端的请求消息时，服务器会根据 URI 判断数据源，并检查数据源对应的访问控制规则，只有允许访问时才读取文件或运行程序。下面我们来看一下设定访问控制规则时，服务器是如何工作的。</p>
<p>首先是根据客户端 IP 地址设置的规则，这个情况很简单，在调用<code>accept</code>接受连接时，就已经知道客户端的 IP 地址了，只要检查其是否允许访问就可以了。</p>
<p>当根据客户端域名设置规则时，需要先根据客户端 IP 地址查询客户端域名，这需要使用 DNS 服务器。一般我们使用 DNS 服务器都是根据域名查询 IP 地址，其实根据 IP 地址反查域名也可以使用 DNS 服务器。具体来说，这个过程是这样的。收到客户端的请求消息后，Web 服务器（①）会委托协议栈告知包的发送方 IP 地址，然后用这个 IP 地址生成查询消息并发送给最近的 DNS 服务器（②）。接下来，DNS 服务器找出负责管辖该 IP 地址的 DNS 服务器，并将查询转发给它（③），查询到相应的域名之后返回结果（④），然后 Web 服务器端的 DNS 服务器再将结果转发给 Web 服务器（⑤）。这样一来，我们就可以根据发送方 IP 地址查询到域名。接下来，为了保险起见，还需要用这个域名查询一下 IP 地址，看看结果与发送方 IP 地址是否一致（⑥）。这是因为有一种在 DNS 服务器上注册假域名的攻击方式，因此我们需要进行双重检查，如果两者一致则检查相应的访问控制规则，判断是否允许访问。从图中可以看出，这种方式需要和 DNS 服务器进行多次查询，整个过程比较耗时，因此 Web 服务器的响应速度也会变慢。</p>
<img src="/2021/12/22/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%846/12.png" class="">

<p>如果用户名和密码已设置好，那么情况如下图。通常的请求消息中不包含用户名和密码，因此无法验证用户名和密码（①）。因此，Web 服务器会向用户发送一条响应消息，告诉用户需要在请求消息中放入用户名和密码（②）。浏览器收到这条响应消息后，会弹出一个输入用户名和密码的窗口，用户输入用户名和密码后（③），浏览器将这些信息放入请求消息中重新发送给服务器（④）。然后，Web 服务器查看接收到的用户名和密码与事先设置好的用户名和密码是否一致，以此判断是否允许访问，如果允许访问，则返回数据（⑤）。</p>
<img src="/2021/12/22/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%846/13.png" class="">
<h2 id="返回响应消息"><a href="#返回响应消息" class="headerlink" title="返回响应消息"></a>返回响应消息</h2><p>当服务器完成对请求消息的各种处理之后，就可以返回响应消息了。这里的工作过程和客户端向服务器发送请求消息时的过程相同。</p>
<p>首先，Web 服务器调用 Socket 库的<code>write</code>，将响应消息交给协议栈。</p>
<p>这时，需要告诉协议栈这个响应消息应该发给谁，但我们并不需要直接告知客户端的 IP 地址等信息，而是只需要给出表示通信使用的套接字的描述符就可以了。套接字中保存了所有的通信状态，其中也包括通信对象的信息，因此只要有描述符就万事大吉了。</p>
<p>接下来，协议栈会将数据拆分成多个网络包，然后加上头部发送出去。这些包中包含接收方客户端的地址，它们将经过交换机和路由器的转发，通过互联网最终到达客户端。</p>
<h1 id="浏览器接收响应消息并显示内容"><a href="#浏览器接收响应消息并显示内容" class="headerlink" title="浏览器接收响应消息并显示内容"></a>浏览器接收响应消息并显示内容</h1><h2 id="通过响应的数据类型判断其中的内容"><a href="#通过响应的数据类型判断其中的内容" class="headerlink" title="通过响应的数据类型判断其中的内容"></a>通过响应的数据类型判断其中的内容</h2><p>Web 服务器发送的响应消息会被分成多个包发送给客户端，然后客户端需要接收数据。首先，网卡将信号还原成数字信息，协议栈将拆分的网络包组装起来并取出响应消息，然后将消息转交给浏览器。这个过程和服务器的接收操作相同。接下来，我们来看一看浏览器是如何显示内容的。</p>
<p>要显示内容，首先需要判断响应消息中的数据属于哪种类型。Web 可以处理的数据包括文字、图像、声音、视频等多种类型，每种数据的显示方法都不同，因此必须先要知道返回了什么类型的数据，否则无法正确显示。</p>
<p>这时，我们需要一些信息才能判断数据类型，原则上可以根据响应消息开头的<code>Content-Type</code>头部字段的值来进行判断。这个值一般是下面这样的字符串。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Content-Type: text/html</span><br></pre></td></tr></table></figure>
<p>其中“&#x2F;”左边的部分称为“主类型”，表示数据的大分类；右边的“子类型”表示具体的数据类型。在上面的例子中，主类型是<code>text</code>，子类型是<code>html</code>。主类型和子类型的含义都是事先确定好的，下表列出了其中主要的一些类型。上面例子中的数据类型表示遵循 HTML 规格的 HTML 文档。</p>
<img src="/2021/12/22/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%846/14.png" class="">

<p>此外，当数据类型为文本时，还需要判断编码方式，这时需要用<code>charset</code>附加表示文本编码方式的信息，内容如下。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Content-Type: text/html; charset=utf-8</span><br></pre></td></tr></table></figure>
<p>这里的<code>utf-8</code>表示编码方式为 Unicode，如果是<code>euc-jp</code>就表示 EUC 编 码，<code>iso-2022-jp</code>表示 JIS 编码，<code>shift_jis</code>表示 JIS 编码。</p>
<p>除了通过<code>Content-Type</code>判断数据类型，还需要检查<code>Content-Encoding</code>头部字段。如果消息中存放的内容是通过压缩或编码技术对原始数据进行转换得到的，那么<code>Content-Encoding</code>的值就表示具体的转换方式，通过这个字段的值，我们可以知道如何将消息中经过转换的数据还原成原始数据。</p>
<p><code>Content-Type</code>字段使用的表示数据类型的方法是在 MIME 规格中定义的，这个规格不仅用于 Web，也是邮件等领域中普遍使用的一种方式。不过这种方式也只不过是一种原则性的规范，要通过<code>Content-Type</code>准确判断数据类型，就需要保证 Web 服务器正确设置<code>Content-Type</code>的值，但现实中并非总是如此。如果 Web 服务器管理员不当心，就可能会因为设置错误导致<code>Content-Type</code>的值不正确。因此，根据原则检查<code>Content-Type</code>并不能确保总是能够准确判断数据类型。</p>
<p>因此，有时候我们需要结合其他一些信息来综合判断数据类型，例如请求文件的扩展名、数据内容的格式等。比如，我们可以检查文件的扩展名，如果为<code>.html</code>或<code>.htm</code>则看作是 HTML 文件，或者也可以检查数据的内容，如果是以<code>&lt;html&gt;</code>开头的则看作是 HTML 文档。不仅是 HTML 这样的文本文件，图片也是一样。图片是经过压缩的二进制数据，但其开头也有表示内容格式的信息，我们可以根据这些信息来判断数据的类型。不过，这部分的逻辑并没有一个统一的规格，因此不同的浏览器以及不同的版本都会有所差异。</p>
<h2 id="浏览器显示网页内容！访问完成！"><a href="#浏览器显示网页内容！访问完成！" class="headerlink" title="浏览器显示网页内容！访问完成！"></a>浏览器显示网页内容！访问完成！</h2><p>判断完数据类型，我们离终点就只有一步之遥了。接下来只要根据数据类型调用用于显示内容的程序，将数据显示出来就可以了。对于 HTML 文档、纯文本、图片这些基本数据类型，浏览器自身具有显示这些内容的功能，因此由浏览器自身负责显示。</p>
<p>不同类型的数据显示操作的过程也不一样，我们以 HTML 文档为例。HTML 文档通过标签表示文档的布局和字体等样式信息，浏览器需要解释这些标签的含义，按照指定的样式显示文档的内容。实际的显示操作是由操作系统来完成的，浏览器负责对操作系统发出指令，例如在屏幕上的什么位置显示什么文字、使用什么样的字体等。</p>
<p>网页中还可以嵌入图片等数据，HTML 文档和图片等数据是分别存在在不同的文件中的，HTML 文档中只有表示图片引用的标签。在读取文档数据时，一旦遇到相应的标签，浏览器就会向服务器请求其中的图片文件。这个请求过程和请求 HTML 文档的过程是一样的，就是在 HTTP 请求消息的 URI 中写上图片文件的文件名即可。将这个请求消息发送给 Web 服务器之后，Web 服务器就会返回图片数据了。接下来，浏览器会将图片嵌入到标签所在的位置。JPEG 和 GIF 格式的图片是经过压缩的，浏览器需要将其解压后委托操作系统进行显示。</p>
<p>像 HTML 文档和图片等浏览器可自行显示的数据，就会按照上述方式委托浏览器在屏幕上显示出来。不过，Web 服务器可能还会返回其他一些类型的数据，如文字处理、幻灯片等应用程序的数据。这些数据无法由浏览器自行显示，这时浏览器会调用相应的程序。这些程序可以是浏览器的插件，也可以是独立的程序，无论如何，不同类型的数据对应不同的程序，这一对应关系是在浏览器中设置好的，只要按照这一对应关系调用相应的程序，并将数据传递给它就可以了。然后，被调用的程序会负责显示相应的内容。</p>
<p>到这里，浏览器的显示操作就完成了，可以等待用户的下一个动作了。当用户点击网页中的链接，或者在网址栏中输入新的网址时，访问 Web 服务器的操作就又开始了。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" rel="tag">计算机网络</a></li></ul>

    </footer>
  </div>

   
   
  
</article>

    
    <article
  id="post-网络是怎样连接的/网络是怎样连接的5"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/"
    >网络是怎样连接的——服务器端的局域网</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/" class="article-date">
  <time datetime="2021-12-14T08:17:56.000Z" itemprop="datePublished">2021-12-14</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">计算机网络</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Web-服务器的部署地点"><a href="#Web-服务器的部署地点" class="headerlink" title="Web 服务器的部署地点"></a>Web 服务器的部署地点</h1><h2 id="在公司里部署-Web-服务器"><a href="#在公司里部署-Web-服务器" class="headerlink" title="在公司里部署 Web 服务器"></a>在公司里部署 Web 服务器</h2><img src="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/1.png" class="">

<p>网络包从互联网到达服务器的过程，根据服务器部署地点的不同而不同。最简单的是图（a）中的这种情况，服务器直接部署在公司网络上，并且可以从互联网直接访问。这种情况下，网络包通过最近的 POP 中的路由器、接入网以及服务器端路由器之后，就直接到达了服务器。</p>
<p>以前这样的服务器部署方式很常见，但现在已经不是主流方式了。这里有几个原因。第一个原因是 IP 地址不足。这样的方式需要为公司网络中的所有设备，包括服务器和客户端计算机，都分配各自的公有地址。然而现在公有地址已经不够用了，因此采用这种方式已经不现实了。</p>
<p>另一个原因是安全问题。这种方式中，从互联网传来的网络包会无节制地进入服务器，这意味着服务器在攻击者看来处于“裸奔”状态。当然，我们可以强化服务器本身的防御来抵挡攻击，这样可以一定程度上降低风险。但是，任何设置失误都会产生安全漏洞，而裸奔状态的服务器，其安全漏洞也都会暴露出来。人工方式总会出错，安全漏洞很难完全消除，因此让服务器裸奔并不是一个稳妥的办法。</p>
<p>因此，现在我们一般采用图（b）中的方式，即部署防火墙。防火墙的作用类似于海关，它只允许发往指定服务器的指定应用程序的网络包通过，从而屏蔽其他不允许通过的包。这样一来，即便应用程序存在安全漏洞，也可以降低相应的风险。因为防火墙屏蔽了不允许从外部访问的应用程序，所以即便这些程序存在安全漏洞，用于攻击的网络包也进不来。当 然，即便如此风险也不会降到零，因为如果允许外部访问的应用程序中有安全漏洞，还是有可能遭到攻击的，但怎么说也远比完全暴露安全漏洞的风险要低得多。这就是防火墙的作用。</p>
<h2 id="将-Web-服务器部署在数据中心"><a href="#将-Web-服务器部署在数据中心" class="headerlink" title="将 Web 服务器部署在数据中心"></a>将 Web 服务器部署在数据中心</h2><p>图（a）和图（b）都是将 Web 服务器部署在公司里，但 Web 服务器不仅可以部署在公司里，也可以像图（c）这样把服务器放在网络运营商等管理的数据中心里，或者直接租用运营商提供的服务器。</p>
<p>数据中心是与运营商核心部分 NOC 直接连接的，或者是与运营商之间的枢纽 IX 直接连接的。换句话说，数据中心通过高速线路直接连接到互联网的核心部分，因此将服务器部署在这里可以获得很高的访问速度，当服务器访问量很大时这是非常有效的。此外，数据中心一般位于具有抗震结构的大楼内，还具有自主发电设备，并实行 24 小时门禁管理，可以说比放在公司里具有更高的安全性。此外，数据中心不但提供安放服务器的场地，还提供各种附加服务，如服务器工作状态监控、防火墙的配置和运营、非法入侵监控等，从这一点来看，其安全性也更高。</p>
<p>如果 Web 服务器部署在数据中心里，那么网络包会从互联网核心部分直接进入数据中心，然后到达服务器。如果数据中心有防火墙，则网络包会先接受防火墙的检查，放行之后再到达服务器。无论如何，网络包通过路由器的层层转发，最终到达服务器的这个过程都是相同的。</p>
<h1 id="防火墙的结构和原理"><a href="#防火墙的结构和原理" class="headerlink" title="防火墙的结构和原理"></a>防火墙的结构和原理</h1><h2 id="主流的包过滤方式"><a href="#主流的包过滤方式" class="headerlink" title="主流的包过滤方式"></a>主流的包过滤方式</h2><p>无论服务器部署在哪里，现在一般都会在前面部署一个防火墙，如果包无法通过防火墙，就无法到达服务器。</p>
<p>防火墙的基本思路，即只允许发往特定服务器中的特定应用程序的包通过，然后屏蔽其他的包。不过，特定服务器上的特定应用程序这个规则看起来不复杂，但网络中流动着很多各种各样的包，如何才能从这些包中分辨出哪些可以通过，哪些不能通过呢？为此，人们设计了多种方式，其中任何一种方式都可以实现防火墙的目的，但出于性能、价格、易用性等因素，现在最为普及的是包过滤方式。</p>
<h2 id="如何设置包过滤的规则"><a href="#如何设置包过滤的规则" class="headerlink" title="如何设置包过滤的规则"></a>如何设置包过滤的规则</h2><p>网络包的头部包含了用于控制通信操作的控制信息，只要检查这些信息，就可以获得很多有用的内容。这些头部信息中，经常用于设置包过滤规则的字段如表所示。</p>
<img src="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/2.png" class="">
<img src="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/3.png" class="">

<p>假设我们的网络如下图所示，将开放给外网的服务器和公司内网分开部署，Web 服务器所在的网络可以从外网直接访问。现在我们希望允许从互联网访问 Web 服务器（①），但禁止 Web 服务器访问互联网（②）。</p>
<p>在设置包过滤规则时，首先要观察包是如何流动的。通过接收方 IP 地址和发送方 IP 地址，我们可以判断出包的起点和终点。在图中 ① 的位置，包从互联网流向 Web 服务器，从互联网发送过来的包其起点是不确定的，但终点是确定的，即 Web 服务器。因此，我们可以按此来设定规则，允许符合规则的包通过。也就是说，允许起点（发送方 IP 地址）为任意，终点（接收方 IP 地址）为 Web 服务器 IP 地址的包通过（图中表的第 1 行）。如果可以确定发送方 IP 地址，也可以将其加入规则，但这个例子中起点是不确定的，因此可以不将发送方 IP 地址设为判断条件。</p>
<img src="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/4.png" class="">

<p>这样一来，从互联网发往 Web 服务器的包就可以通过防火墙了，但光这样还无法完成访问。因为收到包之后，Web 服务器需要通过确认应答机制通知发送方数据已经正常收到，这需要 Web 服务器向互联网发送包。在 Web 服务器发往互联网的包中，我们可以将起点（发送方 IP 地址）为 Web 服务器地址的包设置为允许通过（图中表的第 3 行）。像这样，我们可以先根据接收方和发送方地址判断包的流向，并设置是允许还是阻止。</p>
<h2 id="通过端口号限定应用程序"><a href="#通过端口号限定应用程序" class="headerlink" title="通过端口号限定应用程序"></a>通过端口号限定应用程序</h2><p>不过，按照前面的设置，相当于允许了互联网和 Web 服务器之间所有的包通过，这个状态很危险。假如服务器上还有一个文件服务器程序在工作，那么这些文件就可能会被非法访问从而造成信息泄露。有风险的还不仅是文件服务器，现在每天都会发布若干安全漏洞，可以说随处都隐藏着风险。因此，我们最好是阻止除了必需服务（也就是本例中的 Web 服务）以外的所有应用程序的包。</p>
<p>当我们要限定某个应用程序时，可以在判断条件中加上 TCP 头部或者 UDP 头部中的端口号。Web 服务器的端口号为 80，因此我们在刚才的接收方 IP 地址和发送方 IP 地址的基础上再加上 80 端口作为条件就可以了。</p>
<p>也就是说，当包的接收方 IP 地址为 Web 服务器地址，且接收方端口号为 80 时，允许这些包通过（图中表的第 1 行）；或者当包的发送方 IP 地址为 Web 服务器地址，且发送方端口号为 80 时，允许这些包通过（图中的表的第 3 行）。如果要允许访问除 Web 之外的其他应用程序，则只要将该应用程序的端口号设置到防火墙中并允许通过就可以了。</p>
<h2 id="通过控制位判断连接方向"><a href="#通过控制位判断连接方向" class="headerlink" title="通过控制位判断连接方向"></a>通过控制位判断连接方向</h2><p>现在我们已经可以指定某个具体的应用程序了，但是条件还没达到，因为还没有办法阻止 Web 服务器访问互联网。Web 使用的 TCP 协议是双向收发网络包的，因此如果单纯地阻止从 Web 服务器发往互联网的包，则从互联网访问 Web 服务器的操作也会受到影响而无法进行。光判断包的流向还不够，我们必须要根据访问的方向来进行判断。这里就需要用到 TCP 头部中的控制位。TCP 在执行连接操作时需要收发 3 个包，其中第一个包的 TCP 控制位中 SYN 为 1，而 ACK 为 0。其他的包中这些值都不同，因此只要按照这个规则就能够过滤到 TCP 连接的第一个包。</p>
<p>如果这第一个包是从 Web 服务器发往互联网的，那么我们就阻止它（图表中的第 2 行）。这样设置之后，当然也不会收到对方返回的第二个响应包，TCP 连接操作就失败了。也就是说，只要以 Web 服务器为起点访问互联网，其连接操作必然会失败，这样一来，我们就阻止了 Web 服务器对互联网的访问。</p>
<p>那么，从互联网访问 Web 服务器会不会受影响呢？从互联网访问 Web 服务器时，第一个包是接收方为 Web 服务器，符合图表中的第 1 行，因此允许通过。第二个包的发送方是 Web 服务器，但 TCP 控制位的规则与第二行不匹配，因此符合第三行的规则，允许通过。随后的所有包要么符合第一行，要么符合第三行，因此从互联网访问 Web 服务器的所有包都会被允许通过。</p>
<p>通过接收方 IP 地址、发送方 IP 地址、接收方端口号、发送方端口号、TCP 控制位这些条件，我们可以判断出通信的起点和终点、应用程序种类，以及访问的方向。当然，还有很多其他的字段可以用作判断条件。通过对这些条件进行组合，我们就可以对包进行筛选。</p>
<p>这里也可以添加多个规则，直到能够将允许的访问和不允许的访问完全区分开为止。这样，我们就可以通过设置规则，让允许访问的包通过防火墙，其他的包则不能通过防火墙。</p>
<p>不过，实际上也存在无法将希望允许和阻止的访问完全区分开的情况，其中一个代表性的例子就是对 DNS 服务器的访问。DNS 查询使用的是 UDP 协议，而 UDP 与 TCP 不同，它没有连接操作，因此无法像 TCP 一样根据控制位来判断访问方向。所以，我们无法设置一个规则，只允许公司内部访问互联网上的 DNS 服务器，而阻止从互联网访问公司内部的 DNS 服务器。这一性质不仅适用于 DNS，对于所有使用 UDP 协议的应用程序都是共通的。在这种情况下，只能二者择其一——要么冒一定的风险允许该应用程序的所有包通过，要么牺牲一定的便利性阻止该应用程序的所有包通过。</p>
<h2 id="从公司内网访问公开区域的规则"><a href="#从公司内网访问公开区域的规则" class="headerlink" title="从公司内网访问公开区域的规则"></a>从公司内网访问公开区域的规则</h2><p>上图这样的网络结构中，我们不仅要设置互联网和公开区域之间的包过滤规则，还需要设置公司内网和互联网之间，或者公司内网与公开区域之间的包过滤规则。这时，需要注意的是不要让这些规则互相干扰。例如，为了让公司内网与公开区域之间的网络包自由流动，我们可以将接收方 IP 地址为公开区域的包设置成全部允许通过。但是，如果在这条规则里没有限定发送方 IP 地址，那么连来自互联网的包也都会被无条件允许进入公开区域了，这会导致公开区域中的服务器全部暴露在危险状态中。因此，我们必须谨慎地设置规则，防止出现这样的情况。</p>
<h2 id="从外部无法访问公司内网"><a href="#从外部无法访问公司内网" class="headerlink" title="从外部无法访问公司内网"></a>从外部无法访问公司内网</h2><p>包过滤方式的防火墙不仅可以允许或者阻止网络包的通过，还具备地址转换功能，因此还需要进行相关的设置。也就是说，互联网和公司内网之间的包需要进行地址转换才能传输，因此必须要进行相关的设置。具体来说，就是和包过滤一样，以起点和终点作为条件，根据需要设置是否需要进行地址转换。私有地址和公有地址之间的对应关系，以及端口号的对应关系都是自动管理的，因此只需要设置是否允许地址转换就可以了。</p>
<p>当使用地址转换时，默认状态下是无法从互联网访问公司内网的，因此我们不需要再设置一条包过滤规则来阻止从互联网访问公司内网。</p>
<h2 id="通过防火墙"><a href="#通过防火墙" class="headerlink" title="通过防火墙"></a>通过防火墙</h2><p>像这样，我们可以在防火墙中设置各种规则，当包到达防火墙时，会根据这些规则判断是允许通过还是阻止通过。</p>
<p>如果判断结果为阻止，那么这个包会被丢弃并被记录下来。这是因为这些被丢弃的包中通常含有非法入侵的痕迹，通过分析这些包能够搞清楚入侵者使用的手法，从而帮助我们更好地防范非法入侵。</p>
<p>如果包被判断为允许通过，则该包会被转发出去，这个转发的过程和路由器是相同的。如果我们只关注判断是否允许包通过这一点，可能会觉得防火墙是一种特殊机制，而且市面上销售的防火墙大多是专用的硬件设备或者软件，这也加深了大家的这种印象。</p>
<p>实际上，在防火墙允许包通过之后，就没有什么特别的机制了，因此包过滤并不是防火墙专用的一种特殊机制，而是应该看作在路由器的包转发功能基础上附加的一种功能。只不过当判断规则比较复杂时，通过路由器的命令难以维护这些规则，而且对阻止的包进行记录对于路由器来说负担也比较大，因此才出现了专用的硬件和软件。如果规则不复杂，也不需要记录日志，那么用内置包过滤功能的普通路由器来充当防火墙也是可以的。</p>
<p>包过滤方式的防火墙可根据接收方 IP 地址、发送方 IP 地址、接收方端口号、发送方端口号、控制位等信息来判断是否允许某个包通过。</p>
<h2 id="防火墙无法抵御的攻击"><a href="#防火墙无法抵御的攻击" class="headerlink" title="防火墙无法抵御的攻击"></a>防火墙无法抵御的攻击</h2><p>防火墙可以根据包的起点和终点来判断是否允许其通过，但仅凭起点和终点并不能筛选出所有有风险的包。比如，假设 Web 服务器在收到含有特定数据的包时会引起宕机。但是防火墙只关心包的起点和终点，因此即便包中含有特定数据，防火墙也无法发现，于是包就被放行了。</p>
<p>然后，当包到达 Web 服务器时，就会引发服务器宕机。通过这个例子大家可以看出，只有检查包的内容才能识别这种风险，因此防火墙对这种情况无能为力。</p>
<p>要应对这种情况有两种方法。这个问题的根源在于 Web 服务器程序的Bug，因此修复 Bug 防止宕机就是其中一种方法。这类 Bug 中，危险性较高的会作为安全漏洞公布出来，开发者会很快发布修复了 Bug 的新版本，因此持续关注安全漏洞信息并更新软件的版本是非常重要的。</p>
<p>另一种方法就是在防火墙之外部署用来检查包的内容并阻止有害包的设备或软件。当然，即便是采用这种方法也并不是完美无缺的，因为包的内容是否有风险，是由 Web 服务器有没有 Bug 决定的，因此当服务器程序中有潜在的 Bug 并且尚未被发现时，我们也无法判断包中的风险，也无法阻止这样的包。也就是说，我们无法抵御未知的风险。从这一点来看，这种方法和直接修复 Bug 的方法是基本等效的，但如果服务器数量较多，更新软件版本需要花费一定的时间，或者容易忘记更新软件，这时对包的内容进行检查就会比较有效。</p>
<h1 id="通过将请求平均分配给多台服务器来平衡负载"><a href="#通过将请求平均分配给多台服务器来平衡负载" class="headerlink" title="通过将请求平均分配给多台服务器来平衡负载"></a>通过将请求平均分配给多台服务器来平衡负载</h1><h2 id="性能不足时需要负载均衡"><a href="#性能不足时需要负载均衡" class="headerlink" title="性能不足时需要负载均衡"></a>性能不足时需要负载均衡</h2><p>当服务器的访问量上升时，增加服务器线路的带宽是有效的，但并不是网络变快了就可以解决所有的问题。高速线路会传输大量的网络包，这会导致服务器的性能跟不上。尤其是通过 CGI 等应用程序动态生成数据的情况下，对服务器 CPU 的负担更重，服务器性能的问题也会表现得越明显。</p>
<p>要解决这个问题，大家可能首先想到的是换一台性能更好的服务器，但当很多用户同时访问时，无论服务器的性能再好，仅靠一台服务器还是难以胜任的。在这种情况下，使用多台服务器来分担负载的方法更有效。</p>
<p>这种架构统称为分布式架构，其中对于负载的分担有几种方法，最简单的一种方法就是采用多台 Web 服务器，减少每台服务器的访问量。假设现在我们有 3 台服务器，那么每台服务器的访问量会减少到三分之一，负载也就减轻了。要采用这样的方法，必须有一个机制将客户端发送的请求分配到每台服务器上。具体的做法有很多种，最简单的一种是通过 DNS 服务器来分配。当访问服务器时，客户端需要先向 DNS 服务器查询服务器的 IP 地址，如果在 DNS 服务器中填写多个名称相同的记录，则每次查询时 DNS 服务器都会按顺序返回不同的 IP 地址。例如，对于域名<code>www.lab.glasscom.com</code>，如果我们给它分配如下 3 个 IP 地址。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.0.2.60</span><br><span class="line">192.0.2.70</span><br><span class="line">192.0.2.80</span><br></pre></td></tr></table></figure>
<p>当第 1 次查询这个域名时，服务器会返回如下内容。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">192.0.2.60 192.0.2.70 192.0.2.80</span><br></pre></td></tr></table></figure>
<p>当第 2 次查询时，服务器会返回如下内容。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">192.0.2.70 192.0.2.80 192.0.2.60</span><br></pre></td></tr></table></figure>
<p>当第 3 次查询时，服务器会返回如下内容。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">192.0.2.80 192.0.2.60 192.0.2.70</span><br></pre></td></tr></table></figure>
<p>当第 4 次查询时就又回到第 1 次查询的结果。这种方式称为轮询（<code>round-robin</code>），通过这种方式可以将访问平均分配给所有的服务器。</p>
<img src="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/5.png" class="">

<p>但这种方式是有缺点的。假如多台 Web 服务器中有一台出现了故障，这时我们希望在返回 IP 地址时能够跳过故障的 Web 服务器，然而普通的 DNS 服务器并不能确认 Web 服务器是否正常工作，因此即便 Web 服务器宕机了，它依然可能会返回这台服务器的 IP 地址。</p>
<p>此外，轮询分配还可能会引发一些问题。在通过 CGI 等方式动态生成网页的情况下，有些操作是要跨多个页面的，如果这期间访问的服务器发生了变化，这个操作就可能无法继续。例如在购物网站中，可能会在第一个页面中输入地址和姓名，在第二个页面中输入信用卡号，这就属于刚才说的那种情况。</p>
<h2 id="使用负载均衡器分配访问"><a href="#使用负载均衡器分配访问" class="headerlink" title="使用负载均衡器分配访问"></a>使用负载均衡器分配访问</h2><p>为了避免出现前面的问题，可以使用一种叫作负载均衡器的设备。使用负载均衡器时，首先要用负载均衡器的 IP 地址代替 Web 服务器的实际地址注册到 DNS 服务器上。假设有一个域名<code>www.lab.glasscom.com</code>，我们将这个域名对应的 IP 地址设置为负载均衡器的 IP 地址并注册到 DNS 服务器上。于是，客户端会认为负载均衡器就是一台 Web 服务器，并向其发送请求，然后由负载均衡器来判断将请求转发给哪台 Web 服务器。</p>
<img src="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/6.png" class="">

<p>这里的关键点不言而喻，那就是如何判断将请求转发给哪台 Web 服务器。</p>
<p>判断条件有很多种，根据操作是否跨多个页面，判断条件也会有所不同。如果操作没有跨多个页面，则可以根据 Web 服务器的负载状况来进行判断。负载均衡器可以定期采集 Web 服务器的 CPU、内存使用率，并根据这些数据判断服务器的负载状况，也可以向 Web 服务器发送测试包，根据响应所需的时间来判断负载状况。当然，Web 服务器的负载可能会在短时间内上下波动，因此无法非常准确地把握负载状况，反过来说，如果过于密集地去查询服务器的负载，这个查询操作本身就会增加 Web 服务器的负载。因此也有一种方案是不去查询服务器的负载，而是根据事先设置的服务器性能指数，按比例来分配请求。无论如何，这些方法都能够避免负载集中在某一台服务器上。</p>
<p>当操作跨多个页面时，则不考虑 Web 服务器的负载，而是必须将请求发送到同一台 Web 服务器上。要实现这一点，关键在于我们必须要判断一个操作是否跨了多个页面。HTTP 的基本工作方式是在发送请求消息之前先建立 TCP 连接，当服务器发送响应消息后断开连接，下次访问 Web 服务器的时候，再重新建立 TCP 连接。因此，在 Web 服务器看来，每一次 HTTP 访问都是相互独立的，无法判断是否和之前的请求相关。</p>
<p>之所以会这样，是因为 Web 中使用的 HTTP 协议原本就是这样设计的。如果要判断请求之间的相关性，就必须在 Web 服务器一端保存相应的信息，这会增加服务器的负担。此外，Web 服务器最早并不是用来运行 CGI 程序的，而是主要用来提供静态文件的，而静态文件不需要判断请求之间的相关性，因此最早设计 HTTP 规格的时候，就有意省略了请求之间相关性的判断。</p>
<p>那么在不知道请求之间的相关性时，能不能根据一系列请求的发送方 IP 地址相同这一点来判断呢？也不行。如果使用了代理机制，所有请求的发送方 IP 地址都会变成代理服务器的 IP 地址，无法判断实际发送请求的客户端是哪个。此外，如果使用了地址转换，发送方 IP 地址则会变成地址转换设备的 IP 地址，也无法判断具体是哪个客户端。</p>
<p>于是，人们想出了一些方案来判断请求之间的相关性。例如，可以在发送表单数据时在里面加上用来表示关联的信息，或者是对 HTTP 规格进行扩展，在 HTTP 头部字段中加上用来判断相关性的信息。这样，负载均衡器就可以通过这些信息来作出判断，将一系列相关的请求发送到同一台 Web 服务器，对于不相关的请求则发送到负载较低的服务器了。</p>
<h1 id="使用缓存服务器分担负载"><a href="#使用缓存服务器分担负载" class="headerlink" title="使用缓存服务器分担负载"></a>使用缓存服务器分担负载</h1><h2 id="如何使用缓存服务器"><a href="#如何使用缓存服务器" class="headerlink" title="如何使用缓存服务器"></a>如何使用缓存服务器</h2><p>除了使用多台功能相同的 Web 服务器分担负载之外，还有另外一种方法，就是将整个系统按功能分成不同的服务器，如 Web 服务器、数据库服务器。缓存服务器就是一种按功能来分担负载的方法。</p>
<p>缓存服务器是一台通过代理机制对数据进行缓存的服务器。代理介于 Web 服务器和客户端之间，具有对 Web 服务器访问进行中转的功能。当进行中转时，它可以将 Web 服务器返回的数据保存在磁盘中，并可以代替 Web 服务器将磁盘中的数据返回给客户端。这种保存的数据称为缓存，缓存服务器指的也就是这样的功能。</p>
<p>Web 服务器需要执行检查网址和访问权限，以及在页面上填充数据等内部操作过程，因此将页面数据返回客户端所需的时间较长。相对地，缓存服务器只要将保存在磁盘上的数据读取出来发送给客户端就可以了，因此可以比 Web 服务器更快地返回数据。</p>
<p>不过，如果在缓存了数据之后，Web 服务器更新了数据，那么缓存的数据就不能用了，因此缓存并不是永久可用的。此外，CGI 程序等产生的页面数据每次都不同，这些数据也无法缓存。无论如何，在来自客户端的访问中，总有一部分访问可以无需经过 Web 服务器，而由缓存服务器直接处理。即便只有这一部分操作通过缓存服务器提高了速度，整体性能也可以得到改善。此外，通过让缓存服务器处理一部分请求，也可以减轻 Web 服务器的负担，从而缩短 Web 服务器的处理时间。</p>
<h2 id="缓存服务器通过更新时间管理内容"><a href="#缓存服务器通过更新时间管理内容" class="headerlink" title="缓存服务器通过更新时间管理内容"></a>缓存服务器通过更新时间管理内容</h2><p>下面来看一看缓存服务器的工作过程。</p>
<img src="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/7.png" class="">
<img src="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/8.png" class="">
<img src="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/9.png" class="">

<p>缓存服务器和负载均衡器一样，需要代替 Web 服务器被注册到 DNS 服务器中。然后客户端会向缓存服务器发送 HTTP 请求消息。这时，缓存服务器会接收请求消息，这个接收操作和 Web 服务器相同。Web 服务器的接收操作简单来说就是创建用来等待连接的套接字，当客户端进行连接时执行连接操作，然后接收客户端发送的请求消息。从客户端来看，缓存服务器就相当于 Web 服务器。接下来，缓存服务器会检查请求消息的内容，看看请求的数据是否已经保存在缓存中。根据是否存在缓存数据，后面的操作会有所不同，现在我们假设不存在缓存数据。这时，缓存服务器会在 HTTP 头部字段中添加一个 Via 字段，表示这个消息经过缓存服务器转发，然后将消息转发给 Web 服务器。</p>
<p>在这个过程中，我们需要判断应该将请求消息转发给哪台 Web 服务器。如果只有一台 Web 服务器，那么情况比较简单，只要将 Web 服务器的域名和 IP 地址配置在缓存服务器上，让它无条件转发给这台服务器就可以了。不过，如果一台缓存服务器对应多台 Web 服务器就没那么简单了，需要根据请求消息的内容来判断应该转发给哪台 Web 服务器。要实现这个目的有几种方法，其中比较有代表性的是根据请求消息的 URI中的目录名来进行判断。使用这种方法时，我们首先需要在缓存服务器上进行如下设置。<br>• 当 URI 为<code>/dir1/</code>这个目录时，转发给<code>www1.lab.glasscom.com</code><br>• 当 URI 为<code>/dir2/</code>这个目录时，转发给<code>www2.lab.glasscom.com</code></p>
<p>缓存服务器会根据上述规则来转发请求消息，在这个过程中，缓存服务器会以客户端的身份向目标 Web 服务器发送请求消息。也就是说，它会先创建套接字，然后连接到 Web 服务器的套接字，并发送请求消息。从 Web 服务器来看，缓存服务器就相当于客户端。于是，缓存服务器会收到来自 Web 服务器的响应消息，接收消息的过程也是以客户端的身份来完成的。</p>
<p>接下来，缓存服务器会在响应消息中加上 Via 头部字段，它表示这个消息是经过缓存服务器中转的，然后缓存服务器会以 Web 服务器的身份向客户端发送响应消息。同时，缓存服务器会将响应消息保存到缓存中，并记录保存的时间。</p>
<p>这种在客户端和 Web 服务器之间充当中间人的方式就是代理的基本原理。在中转消息的过程中，缓存服务器还会顺便将页面数据保存下来，随着缓存数据的积累，用户访问的数据命中缓存的几率也会提高。接下来我们来看一看命中缓存的情况。</p>
<p>首先，接收客户端的请求消息并检查缓存的过程和刚才是一样的。然后，如下图（a），缓存服务器会添加一个<code>If-Modified-Since</code>头部字段并将请求转发给 Web 服务器，询问 Web 服务器用户请求的数据是否已经发生变化。</p>
<p>然后，Web 服务器会根据<code>If-Modified-Since</code>的值与服务器上的页面数据的最后更新时间进行比较，如果在指定时间内数据没有变化，就会返回一个像下图（b）一样的表示没有变化的响应消息。这时，Web 服务器只要查询一下数据的最后更新时间就好了，比返回页面数据的负担要小一些。而且返回的响应消息也比较短，能相应地减少负担。接下来，返回消息到达缓存服务器，然后缓存服务器就会知道 Web 服务器上的数据和本地缓存中的数据是一样的，于是就会将缓存的数据返回给客户端。缓存服务器返回的响应消息的内容和没有命中缓存的情况是一样的。</p>
<p>此外，当 Web 服务器上的数据有变化时，后面的过程和没有命中缓存的情况是一样的。Web 服务器会返回最新版本的数据，然后缓存服务器加上<code>Via</code>字段发送给客户端，同时将数据保存在缓存中。</p>
<img src="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/10.png" class="">
<h2 id="最原始的代理——正向代理"><a href="#最原始的代理——正向代理" class="headerlink" title="最原始的代理——正向代理"></a>最原始的代理——正向代理</h2><p>上面的是在 Web 服务器一端部署一个代理，然后利用其缓存功能来改善服务器的性能，还有一种方法是在客户端一侧部署缓存服务器。</p>
<p>实际上，缓存服务器使用的代理机制最早就是放在客户端一侧的，这才是代理的原型，称为正向代理。</p>
<p>正向代理刚刚出现的时候，其目的之一就是缓存，这个目的和服务器端的缓存服务器相同。不过，当时的正向代理还有另外一个目的，那就是用来实现防火墙。</p>
<p>防火墙的目的是防止来自互联网的非法入侵，而要达到这个目的，最可靠的方法就是阻止互联网和公司内网之间的所有包。不过，这样一来，公司员工就无法上外网了，因此还必须想一个办法让必要的包能够通过，这个办法就是利用代理。简单来说，代理的原理如下图所示，它会先接收来自客户端的请求消息，然后再转发到互联网中，这样就可以实现只允许通过必要的网络包了。这时，如果能够利用代理的缓存，那么效果就会更好，因为对于以前访问过的数据，可以直接从位于公司内网的代理服务器获得，这比通过低速线路访问互联网要快很多。</p>
<img src="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/11.png" class="">

<p>此外，由于代理在转发过程中可以查看请求的内容，所以可以根据内容判断是否允许访问。也就是说，通过代理可以禁止员工访问危险的网站，或者是与工作内容无关的网站。包过滤方式的防火墙只能根据 IP 地址和端口号进行判断，因此无法实现这一目的。</p>
<p>在使用正向代理时，一般需要在浏览器的设置窗口中的“代理服务器”一栏中填写正向代理的 IP 地址，浏览器发送请求消息的过程也会发生相应的变化。在没有设置正向代理的情况下，浏览器会根据网址栏中输入的<code>http://...</code>字符串判断 Web 服务器的域名，并向其发送请求消息；当设置了正向代理时，浏览器会忽略网址栏的内容，直接将所有请求发送给正向代理。请求消息的内容也会有一些不同。没有正向代理时，浏览器会从网址中提取出 Web 服务器域名后面的文件名或目录名，然后将其作为请求的 URI 进行发送；而有正向代理时，浏览器会像下图这样，在请求的 URI 字段中填写完整的<code>http://...</code>网址。</p>
<p>正向代理转发消息的过程也和服务器端的缓存服务器有一些不同，不同点在于对转发目标 Web 服务器的判断上。使用正向代理时，URI 部分为<code>http://...</code>这样的完整网址，因此可以根据这个网址来转发，不需要像服务器端的缓存服务器一样实现设置好转发目标 Web 服务器，而且可以发给任意 Web 服务器。而服务器端的缓存服务器只能向事先设置好的目标进行转发，这就是两者不同的地方。</p>
<img src="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/12.png" class="">
<h2 id="正向代理的改良版——反向代理"><a href="#正向代理的改良版——反向代理" class="headerlink" title="正向代理的改良版——反向代理"></a>正向代理的改良版——反向代理</h2><p>使用正向代理需要在浏览器中进行设置，这可以说是识别正向代理的一个特征。但是，设置浏览器非常麻烦，如果设置错误还可能导致浏览器无法正常工作。</p>
<p>需要设置浏览器这一点除了麻烦、容易发生故障之外，还有其他一些限制。如果我们想把代理放在服务器端，那么服务器不知道谁会来访问，也没办法去设置客户端的浏览器，因此无法采用这种方法来实现。</p>
<p>于是，我们可以对这种方法进行改良，使得不需要在浏览器中设置代理也可以使用。也就是说，我们可以通过将请求消息中的 URI 中的目录名与 Web 服务器进行关联，使得代理能够转发一般的不包含完整网址的请求消息。服务器端的缓存服务器采用的正是这种方式，这种方式称为反向代理。</p>
<h2 id="透明代理"><a href="#透明代理" class="headerlink" title="透明代理"></a>透明代理</h2><p>缓存服务器判断转发目标的方法还有一种，那就是查看请求消息的包头部。因为包的 IP 头部中包含接收方 IP 地址，只要知道了这个地址，就知道用户要访问哪台服务器了。这种方法称为透明代理。</p>
<p>这种方法也可以转发一般的请求消息，因此不需要像正向代理一样设置浏览器参数，也不需要在缓存服务器上设置转发目标，可以将请求转发给任意 Web 服务器。</p>
<p>透明代理集合了正向代理和反向代理的优点，是一个非常方便的方式，但也需要注意一点，那就是如何才能让请求消息到达透明代理。由于透明代理不需要设置在浏览器中，那么浏览器还是照常向 Web 服务器发送请求消息。反向代理采用的是通过 DNS 服务器解析引导的方法，但透明代理是不能采用这种方法的，否则透明代理本身就变成了访问目标，也就无法通过接收方 IP 地址判断转发目标了，这就失去了透明代理的意义。总之，正常情况下，请求消息是从浏览器直接发送到 Web 服务器，并不会到达透明代理。</p>
<p>于是，我们必须将透明代理放在请求消息从浏览器传输到 Web 服务器的路径中，当消息经过时进行拦截。可能大家觉得这种方法太粗暴，但只有这样才能让消息到达透明代理，然后再转发给 Web 服务器。如果请求消息有多条路径可以到达 Web 服务器，那么就必须在这些路径上都放置透明代理，因此一般是将网络设计成只有一条路可以走的结构，然后在这一条路径上放置透明代理。连接互联网的接入网就是这样一个关口，因此可以在接入网的入口处放置反向代理。使用透明代理时，用户不会察觉到代理的存在，也不会注意到 HTTP 消息是如何被转发的，因此大家更倾向于将透明代理说成是缓存。</p>
<h1 id="内容分发服务"><a href="#内容分发服务" class="headerlink" title="内容分发服务"></a>内容分发服务</h1><h2 id="利用内容分发服务分担负载"><a href="#利用内容分发服务分担负载" class="headerlink" title="利用内容分发服务分担负载"></a>利用内容分发服务分担负载</h2><img src="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/13.png" class="">

<p>缓存服务器部署在服务器端还是客户端，其效果是有差别的。如上图（a）所示，当缓存服务器放在服务器端时，可以减轻 Web 服务器的负载，但无法减少互联网中的流量。这一点上，将缓存服务器放在客户端更有效（上图（b））。互联网中会存在一些拥塞点，通过这些地方会比较花时间。如果在客户端部署缓存服务器，就可以不受或者少受这些拥塞点的影响，让网络流量更稳定，特别是当访问内容中含有大图片或视频时效果更明显。</p>
<p>不过，客户端的缓存服务器是归客户端网络运营管理者所有的，Web服务器的运营者无法控制它。比如，某网站的运营者觉得最近网站上增加了很多大容量的内容，因此想要增加缓存服务器的容量。如果缓存放在服务器端，那么网站运营者可以自己通过增加磁盘空间等方式来进行扩容，但对于放在客户端的缓存就无能为力了。进一步说，客户端有没有缓存服务器还不一定呢。</p>
<p>因此，这两种部署缓存服务器的方式各有利弊，但也有一种方式能够集合两者的优点。那就是像上图（c）这样，Web 服务器运营者和网络运营商签约，将可以自己控制的缓存服务器放在客户端的运营商处。</p>
<p>这样一来，我们可以把缓存服务器部署在距离用户很近的地方，同时 Web 服务器运营者还可以控制这些服务器，但这种方式也有问题。对于在互联网上公开的服务器来说，任何地方的人都可以来访问它，因此如果真的要实现这个方式，必须在所有的运营商 POP 中都部署缓存服务器才行，这个数量太大了，非常不现实。</p>
<p>要解决这个问题也有一些办法。首先，我们可以筛选出一些主要的运营商，这样可以减少缓存服务器的数量。尽管这样做可能会导致有些用户访问到缓存服务器还是要经过很长的距离，但总比直接访问 Web 服务器的路径要短多了，因此还是可以产生一定的效果。</p>
<p>接下来这个问题更现实，那就是即便减少了数量，作为一个 Web 服务器运营者，如果自己和这些运营商签约并部署缓存服务器，无论是费用还是精力都是吃不消的。为了解决这个问题，一些专门从事相关服务的厂商出现了，他们来部署缓存服务器，并租借给 Web 服务器运营者。这种服务称为内容分发服务。</p>
<p>提供这种服务的厂商称为 CDSP（<code>Content Delivery Service Provider</code>，内容分发服务运营商），他们会与主要的供应商签约，并部署很多台缓存服务器。另一方面，CDSP 会与 Web 服务器运营者签约，使得 CDSP 的缓存服务器配合 Web 服务器工作。具体的方法我们后面会介绍，只要 Web 服务器与缓存服务器建立关联，那么当客户端访问 Web 服务器时，实际上就是在访问 CDSP 的缓存服务器了。</p>
<p>缓存服务器可以缓存多个网站的数据，因此 CDSP 的缓存服务器就可以提供给多个 Web 服务器的运营者共享。这样一来，每个网站运营者的平均成本就降低了，从而减少了网站运营者的负担。而且，和运营商之间的签约工作也由 CDSP 统一负责，网站运营者也节省了精力。</p>
<h2 id="如何找到最近的缓存服务器"><a href="#如何找到最近的缓存服务器" class="headerlink" title="如何找到最近的缓存服务器"></a>如何找到最近的缓存服务器</h2><p>在使用内容分发服务时，互联网中有很多缓存服务器，如何才能从这些服务器中找到离客户端最近的一个，并让客户端去访问那台服务器呢？</p>
<img src="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/14.png" class="">

<p>我们可以像正向代理一样在浏览器中进行设置，但用户那么多，也没办法帮所有人去设置浏览器。因此，我们需要一种机制，即便用户不进行任何设置，也能够将请求消息发送到缓存服务器。</p>
<p>这样的方法有几种。第一个方法是像负载均衡一样用 DNS 服务器来分配访问。也就是说，我们可以在 DNS 服务器返回 Web 服务器 IP 地址时，对返回的内容进行一些加工，使其能够返回距离客户端最近的缓存服务器的 IP 地址。</p>
<p>互联网中有很多台 DNS 服务器，它们通过相互接力来处理 DNS 查询，这个过程从客户端发送查询消息开始，也就是说客户端会用要访问的 Web 服务器域名生成查询消息，并发送给自己局域网中的 DNS 服务器（下图①）。然后，客户端 DNS 服务器会通过域名的层次结构找到负责管理该域名的 DNS 服务器，也就是 Web 服务器端的那个 DNS 服务器，并将查询消息发送给它（下图②）。Web 服务器端的 DNS 服务器收到查询消息后，会查询并返回域名相对应的 IP 地址。在这台 DNS 中，有一张管理员维护的域名和 IP 地址的对应表，只要按照域名查表，就可以找到相应的 IP 地址（下图③）。接下来，响应消息回到客户端的 DNS 服务器，然后再返回给客户端（下图④）</p>
<img src="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/15.png" class="">

<p>上面是 Web 服务器的域名只对应一个 IP 地址的情况，如果一个域名对应多个 IP 地址，则按照前面轮询方式按顺序返回所有的 IP 地址。</p>
<p>如果按照 DNS 服务器的一般工作方式来看，它只能以轮询方式按顺序返回 IP 地址，完全不考虑客户端与缓存服务器的远近，因此可能会返回离客户端较远的缓存服务器 IP 地址。</p>
<p>如果要让用户访问最近的缓存服务器，则不应采用轮询方式，而是应该判断客户端与缓存服务器的距离，并返回距离客户端最近的缓存服务器 IP 地址。这里的关键点不言自明，那就是到底该怎样判断客户端与缓存服务器之间的距离呢？</p>
<p>方法是这样的。首先，作为准备，需要事先从缓存服务器部署地点的路由器收集路由信息。例如，在下图的例子中，一共有 4 台缓存服务器，在这 4 台服务器的部署地点又分别有 4 台路由器，则我们需要分别获取这 4 台路由器的路由表，并将 4 张路由表集中到 DNS 服务器上。</p>
<p>接下来，DNS 服务器根据路由表查询从本机到 DNS 查询消息的发送方，也就是客户端 DNS 服务器的路由信息。例如，根据下图路由器 A 的路由表，可以查出路由器 A 到客户端 DNS 服务器的路由。通过互联网内部的路由表中的路由信息可以知道先通过运营商 X，然后通过运营商 Y，最后到达运营商 Z 这样的信息，通过这样的信息可以大致估算出距离。依次查询所有路由器的路由表之后，我们就可以通过比较找出哪一台路由器距离客户端 DNS 服务器最近。提供路由表的路由器位于缓存服务器的位置，而客户端 DNS 服务器也应该和客户端在同一位置，这样就等于估算出了缓存服务器与客户端之间的距离，从而能够判断出哪台缓存服务器距离客户端最近了。实际上，客户端 DNS 服务器不一定和客户端在同一位置，因此可能无法得出准确的距离，但依然可以达到相当的精度。</p>
<img src="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/16.png" class="">
<img src="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/17.png" class="">
<h2 id="通过重定向服务器分配访问目标"><a href="#通过重定向服务器分配访问目标" class="headerlink" title="通过重定向服务器分配访问目标"></a>通过重定向服务器分配访问目标</h2><p>还有另一个让客户端访问最近的缓存服务器的方法。HTTP 规格中定义了很多头部字段，其中有一个叫作<code>Location</code>的字段。当 Web 服务器数据转移到其他服务器时可以使用这个字段，它的意思是“您要访问的数据在另一台服务器上，请访问那台服务器吧。”这种将客户端访问引导到另一台 Web 服务器的操作称为重定向，通过这种方法也可以将访问目标分配到最近的缓存服务器。</p>
<p>当使用重定向告知客户端最近的缓存服务器时，首先需要将重定向服务器注册到 Web 服务器端的 DNS 服务器上。这样一来，客户端会将 HTTP 请求消息发送到重定向服务器上。重定向服务器和刚才一种方法中的 DNS 服务器一样，收集了来自各个路由器的路由信息，并根据这些信息找到最近的缓存服务器，然后将缓存服务器的地址放到<code>Location</code>字段中返回响应。这样，客户端就会重新去访问指定的缓存服务器了。</p>
<img src="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/18.png" class="">
<img src="/2021/12/14/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%845/19.png" class="">

<p>这种方法的缺点在于增加了 HTTP 消息的交互次数，相应的开销也比较大，但它也有优点。对 DNS 服务器进行扩展的方法是估算客户端 DNS 服务器到缓存服务器之间的距离，因此精度较差；相对而言，重定向的方法是根据客户端发送来的 HTTP 消息的发送方 IP 地址来估算距离的，因此精度较高。</p>
<p>此外，也可以使用除路由信息之外的其他一些信息来估算距离，进一步提高精度。重定向服务器不仅可以返回带有<code>Location</code>字段的 HTTP 消息，也可以返回一个通过网络包往返时间估算到缓存服务器的距离的脚本，通过在客户端运行脚本来找到最优的缓存服务器。这个脚本可以向不同的缓存服务器发送测试包并计算往返时间，然后将请求发送到往返时间最短的一台缓存服务器，这样就可以判断出对于客户端最优的缓存服务器，并让客户端去访问该服务器。</p>
<h2 id="缓存的更新方法会影响性能"><a href="#缓存的更新方法会影响性能" class="headerlink" title="缓存的更新方法会影响性能"></a>缓存的更新方法会影响性能</h2><p>还有一个因素会影响缓存服务器的效率，那就是缓存内容的更新方法。</p>
<p>缓存本来的思路是将曾经访问过的数据保存下来，然后当再次访问时拿出来用，以提高访问操作的效率。不过，这种方法对于第一次访问是无效的，而且后面的每次访问都需要向原始服务器查询数据有没有发生变化，如果遇到网络拥塞，就会使响应时间恶化。</p>
<p>要改善这一点，有一种方法是让 Web 服务器在原始数据发生更新时，立即通知缓存服务器，使得缓存服务器上的数据一直保持最新状态，这样就不需要每次确认原始数据是否有变化了，而且从第一次访问就可以发挥缓存的效果。内容分发服务采用的缓存服务器就具备这样的功能。</p>
<p>此外，除了事先编写好内容的静态页面之外，还有一些在收到请求后由 CGI 程序生成的动态页面，这种动态页面是不能保存在缓存服务器上的。这种情况下，我们可以不保存整个页面，而是将应用程序生成的部分，也就是每次内容都会发生变化的动态部分，与内容不会发生变化的静态部分分开，只将静态部分保存在缓存中。</p>
<p>Web 服务器前面存在着各种各样的服务器，如防火墙、代理服务器、缓存服务器等。请求消息最终会通过这些服务器，到达 Web 服务器。Web 服务器接收请求之后，会查询其中的内容，并根据请求生成并返回响应消息。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" rel="tag">计算机网络</a></li></ul>

    </footer>
  </div>

   
   
  
</article>

    
    <article
  id="post-网络是怎样连接的/网络是怎样连接的4"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/"
    >网络是怎样连接的——接入网和网络运营商</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/" class="article-date">
  <time datetime="2021-12-09T06:33:22.000Z" itemprop="datePublished">2021-12-09</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">计算机网络</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="ADSL-接入网的结构和工作方式"><a href="#ADSL-接入网的结构和工作方式" class="headerlink" title="ADSL 接入网的结构和工作方式"></a>ADSL 接入网的结构和工作方式</h1><h2 id="互联网的基本结构和家庭、公司网络是相同的"><a href="#互联网的基本结构和家庭、公司网络是相同的" class="headerlink" title="互联网的基本结构和家庭、公司网络是相同的"></a>互联网的基本结构和家庭、公司网络是相同的</h2><p>和家庭、公司网络一样，互联网也是通过路由器来转发包的，而且路由器的基本结构和工作方式也并没有什么不同。因此，我们可以将互联网理解为家庭、公司网络的一个放大版。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/1.png" class="">

<p>当然，互联网也有一些和家庭、公司网络不同的地方，其中之一就是与转发设备间的距离。在家庭、公司网络中，与转发设备之间的距离不过几十米到几百米，在这种情况下，只要延长以太网线就可以到达相邻的转发设备了。然而，互联网可不能这么搞，因为你家到最近的电话局至少也有几公里的距离，而从日本连接到美国甚至要跨越太平洋，用以太网线是无法实现这种连接的。</p>
<p>除了距离之外，路由器在如何控制包的转发目标上也不一样。尽管从基本原理来看，互联网也是根据路由表中的记录来判断转发目标的，但路由表记录的维护方式不同。互联网中的路由器上有超过 10 万条路由记录，而且这些记录还在不断变化，当出现线路故障时，或者新的公司加入互联网时，都会引发路由的变化。人工维护这些路由信息是不现实的，必须实现自动化。公司的路由器也有自动维护路由表的机制，但出于各种原因，互联网中采用的机制和公司有所区别。</p>
<p>距离的不同和路由的维护方式，就是互联网与家庭、公司网络之间最主要的两个不同点。</p>
<h2 id="连接用户与互联网的接入网"><a href="#连接用户与互联网的接入网" class="headerlink" title="连接用户与互联网的接入网"></a>连接用户与互联网的接入网</h2><p>网络包通过交换机和路由器的转发一步一步地接近它的目的地，在通过互联网接入路由器之后，就进入了互联网。</p>
<p>路由器的转发操作都是相同的，因此互联网接入路由器的包转发操作和以太网路由器几乎是一样的。简单来说，就是根据包 IP 头部中的接收方 IP 地址在路由表的目标地址中进行匹配，找到相应的路由记录后将包转发到这条路由的目标网关。不过，互联网接入路由器发送网络包的操作和以太网路由器有一点不同，互联网接入路由器是按照接入网规则来发送包的。</p>
<p>所谓接入网，就是指连接互联网与家庭、公司网络的通信线路。一般家用的接入网方式包括 ADSL、FTTH、CATV、电话线、ISDN 等，公司则还可能使用专线。接入网的线路有很多种类，我们无法探索所有这些线路，因此以 ADSL 为例。</p>
<h2 id="ADSL-Modem-将包拆分成信元"><a href="#ADSL-Modem-将包拆分成信元" class="headerlink" title="ADSL Modem 将包拆分成信元"></a>ADSL Modem 将包拆分成信元</h2><p>ADSL 技术使用的接入线路，其内部结构如图。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/2.png" class="">
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/3.png" class="">

<p>在这张图中网络包是从右往左传输的。用户端路由器发出的网络包通过 ADSL Modem 和电话线到达电话局，然后到达 ADSL 的网络运营商（即 ISP，互联网服务提供商）。在网络包从用户传输到运营商的过程中，会变换几种不同的形态，整个过程如图。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/4.png" class="">

<p>首先，客户端生成的网络包（①和②）先经过集线器和交换机到达互联网接入路由器（③），并在此从以太网包中取出 IP 包并判断转发目标（④），和以太网路由器的工作方式是一样的。接下来，包发送的操作也很类似。如果互联网接入路由器和 ADSL Modem 之间是通过以太网连接的，那么就会按照以太网的规则执行包发送的操作，发送信号本身的过程跟之前是一样的，但以太网的头部会有一些差异。这部分的具体情况各运营商会有所不同。这里大家先记住，网络包会加上 MAC 头部、PPPoE 头部、PPP 头部总共 3 种头部（⑤），然后按照以太网规则转换成电信号后被发送出去。</p>
<p>互联网接入路由器会在网络包前面加上 MAC 头部、PPPoE 头部、PPP 头部总共 3 种头部， 然后发送给 ADSL Modem（PPPoE 方式下）。</p>
<p>互联网接入路由器将包发送出去之后，包就到达了 ADSL Modem（⑥），然后，ADSL Modem 会把包拆分成很多小格子（⑦），每一个小格子称为一个信元。信元是一个非常小的数据块，开头是有 5 个字节的头部，后面是 48 个字节的数据，用于一种叫作 ATM 的通信技术。</p>
<p>可以将信元理解为一种更小一号的包，原理上跟 TCP&#x2F;IP 将应用程序的数据拆分成块装进一个个包的过程是一样的。</p>
<p>之所以要将包拆分成信元，原因是这样的。当初开发 ADSL 技术时，通信业比较看好 ATM 技术，各运营商也在 ATM 相关的设备上投入了很多资金。在这样的情况下，如果使用信元来传输数据，就比较容易和其他设备进行整合，可以降低开发投入和设备投入。如果不是出于这样的原因，其实并不需要将包拆分成信元，实际上也有一些 ADSL 运营商使用的 ADSL Modem 是不进行数据拆分的。</p>
<p>ADSL Modem 将包拆分成信元，并转换成电信号发送给分离器。</p>
<h2 id="ADSL-将信元“调制”成信号"><a href="#ADSL-将信元“调制”成信号" class="headerlink" title="ADSL 将信元“调制”成信号"></a>ADSL 将信元“调制”成信号</h2><p>将网络包拆分成信元之后，接下来就要将这些信元转换成信号了（⑧）。以太网采用的是用方波信号表示 0 和 1 的方式，这种方式很简单，但同样是将数字信息转换成模拟信号，ADSL 采用的方法要复杂一些。其中有两个原因，一个原因是方波信号的波形容易失真，随着距离的延长错误率也会提高；另一个原因是方波信号覆盖了从低频到高频的宽广频段，信号频率越高，辐射出来的电磁噪声就越强，因此信号频谱太宽就难以控制噪声。</p>
<p>因此，ADSL Modem 采用了一种用圆滑波形（正弦波）对信号进行合成来表示 0 和 1 的技术，这种技术称为调制。调制有很多方式，ADSL 采用的调制方式是振幅调制（ASK）和相位调制（PSK）相结合的正交振幅调制（QAM）方式。下面先来看一下它的两个组成要素。</p>
<p>振幅调制是用信号的强弱，也就是信号振幅的大小来对应 0 和 1 的方式。如图（b），振幅小的信号为 0，振幅大的信号为 1，这是一种最简单的对应关系。在这个例子中，振幅大小只有两个级别，如果增加振幅变化的级别，就可以对应更多的比特。例如，如果将振幅增加到 4 个级别，则振幅从小到大可分别对应 00、01、10 和 11，这样就可以表示两个比特了。这样做可以将单位时间内传输的数据量加倍，也就能够提高速率。以此类推，如果振幅有 8 个级别，就可以表示 3 个比特，16 个级别就可以表示 4 个比特，速率也就越来越高。不过，信号会在传输过程中发生衰减，也会受到噪声影响而失真，如果振幅级别太多，接收方对信号的识别就容易出错，因此振幅级别也不能太多。</p>
<p>另一个组成要素是相位调制，这是一种根据信号的相位来对应 0 和 1 的方式。Modem 产生的信号是以一定周期振动的波，如图，振动的起始位置不同，波的形状也就不同。如果将波的一个振动周期理解为一个圆，则起始位置就可以用 0 度到 360 度的角度来表示，这个角度就是相位，用角度来对应 0 和 1 的方式就叫作相位调制。例如，从 0 度开始的波为 0，从 180 度开始的波为 1，这是一种最简单的对应关系，如图（c）所示。和振幅调制一样，相位调制也可以通过将角度划分为更细的级别来增加对应的比特数量，从而提高速率。但是，角度太接近的时候也容易产生误判，因此这样提升速率还是有限度的。</p>
<p>ADSL 使用的正交振幅调制就是将前面这两种方式组合起来实现的。 图（d）就是将图（b）和图（c）组合起来的一个例子，大家应该一看就明白了。如果信号的振幅可以表示 1 个比特，相位可以表示 1 个比特，那么加起来就可以表示 2 个比特。因此，将两种方式组合起来，正交振幅调制就可以用一个波表示更多的比特，从而提高传输速率。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/5.png" class="">
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/6.png" class="">

<p>正交振幅调制中，通过增加振幅和相位的级别，就可以增加能表示的比特数。例如，如果振幅和相位各自都有 4 个级别，那么组合起来就有 16 个级别，也就可以表示 4 个比特的值。当然，和单独使用振幅调制或相位调制的情况一样，级别过多就容易发生误判，因此这种方法提升的速率是有限度的。</p>
<h2 id="ADSL-通过使用多个波来提高速率"><a href="#ADSL-通过使用多个波来提高速率" class="headerlink" title="ADSL 通过使用多个波来提高速率"></a>ADSL 通过使用多个波来提高速率</h2><p>实际上信号不一定要限制在一个频率。不同频率的波可以合成，也可以用滤波器从合成的波中分离出某个特定频率的波。因此，我们可以使用多个频率合成的波来传输信号，这样一来，能够表示的比特数就可以成倍提高了。</p>
<p>ADSL 就是利用了这一性质，通过多个波增加能表示的比特数来提高速率的。具体来说，如图，ADSL 使用间隔为 4.3125 kHz 的上百个不同频率的波进行合成，每个波都采用正交振幅调制，而且，根据噪声等条件的不同，每个波表示的比特数是可变的。也就是说，噪声小的频段可以给波分配更多的比特，噪声大的频段则给波分配较少的比特，每个频段表示的比特数加起来，就决定了整体的传输速率。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/7.png" class="">

<p>ADSL 技术中，上行方向（用户到互联网）和下行方向（互联网到用户）的传输速率是不同的，原因也在这里。如果上行使用 26 个频段，下行则可以使用 95 个或者 223 个频段，波的数量不同，导致了上下行速率不同。</p>
<p>当然，下行使用的频段较高，这些信号容易衰减而且更容易受到噪声的影响，因此这些频段可能只能表示较少的比特数，或者干脆无法传输信号。距离越远，频率越高，这种情况也就越显著，因此如果你家距离电话局太远，速率就会下降。</p>
<p>噪声和衰减等影响线路质量的因素在每条线路上都不同，而且会随着时间发生变化。因此，ADSL 会持续检查线路质量，动态判断使用的频段数量，以及每个频段分配到的比特数。具体来说，当 Modem 通电后，会发送测试信号，并根据信号的接收情况判断使用的频段数量和每个频段的比特数，这个过程称为训练（握手），需要几秒到几十秒的时间。</p>
<h2 id="分离器的作用"><a href="#分离器的作用" class="headerlink" title="分离器的作用"></a>分离器的作用</h2><p>ADSL Modem 将信元转换为电信号之后，信号会进入一个叫作分离器的设备，然后 ADSL 信号会和电话的语音信号混合起来一起从电话线传输出去。在信号从用户端发送出去时，电话和 ADSL 信号只是同时流到一条线路上而已，分离器实际上并没有做什么事。</p>
<p>分离器的作用其实在相反的方向，也就是信号从电话线传入的时候。这时，分离器需要负责将电话和 ADSL 的信号进行分离。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/8.png" class="">

<p>电话线传入的信号是电话的语音信号和 ADSL 信号混合在一起的，如果这个混合信号直接进入电话机，ADSL 信号就会变成噪音，导致电话难以听清。为了避免这样的问题，就需要通过分离器将传入的信号分离，以确保 ADSL 信号不会传入电话机。具体来说，分离器的功能是将一定频率以上的信号过滤掉，也就是过滤掉了 ADSL 使用的高频信号，这样一来，只有电话信号才会传入电话机，但对于另一头的 ADSL Modem，则是传输原本的混合信号给它。ADSL Modem 内部已经具备将 ADSL 频率外的信号过滤掉的功能，因此不需要在分离器进行过滤。</p>
<p>大家可能会认为分离器的功能只是过滤掉高频信号，防止 ADSL 对电话产生干扰，而实际上它还可以防止电话对 ADSL 产生干扰。如果没有分离器，拿起电话听筒接通电话的状态，和放下听筒挂断电话的状态下，信号的传输方式是不同的。当放下听筒时，电话机的电路和电话线是断开的，当拿起听筒时电话机就和电话线相连，电话机的信号就会传到电话线上。</p>
<p>这两种状态的差异会导致噪声等线路状态的改变，如果 ADSL 通信过程中拿起话筒导致线路状态改变，就需要重新训练（握手），这就会导致几十秒的通信中断，分离器可以防止发生这样的问题。当然，也有一种技术能够快速重新握手，即便没有分离器也不会影响 ADSL 通信，G.992.2 的 ADSL 规格就包含这种技术，但 ADSL 信号还是会影响电话，因此 G.992.2 的 ADSL 规格中一般还是需要使用分离器。</p>
<h2 id="从用户到电话局"><a href="#从用户到电话局" class="headerlink" title="从用户到电话局"></a>从用户到电话局</h2><p>从分离器出来，就是插电话线的接口，信号从这里出来之后，会通过室内电话线，然后到达大楼的 IDFA 和 MDFB，外面的电话线在这里和大楼内部的室内电话线相连接。如果是独栋住宅，就可以将室外线和室内线直接连起来。通过配线盘之后，信号会到达保安器。保安器是为了防止雷电等情况下电话线中产生过大电流的一种保护装置，内部有保险丝。</p>
<p>接下来，信号会进入电线杆上架设的电话电缆。电话线是一种直径 0.32～0.9 mm 的金属信号线，这些信号线如图所示被捆绑在一起。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/9.png" class="">

<p>电话电缆在用户住宅附近一般是架设在电线杆上，但中途会沿电线杆侧面的金属管进入地下。由于电话线必须进入很多住宅和大楼，所以电话局附近就会集结数量庞大的电缆，这么多电缆要通过电线杆引入电话局是非常不现实的，电话局周围得密密麻麻地立满了电线杆，而且电线杆上架设过多的电缆，还会产生防灾方面的问题。因此，在电话局附近，电话线都是埋在地下的。由于电话局附近的地下电缆很多，集中埋设电缆的地方就形成了一条地道，这部分称为电缆隧道。通过电缆隧道进入电话局后，电缆会逐根连接到电话局的 MDF 上。</p>
<h2 id="噪声的干扰"><a href="#噪声的干扰" class="headerlink" title="噪声的干扰"></a>噪声的干扰</h2><p>电话电缆中的信号也会受到噪声的干扰。虽然电话线和以太网双绞线的结构有所不同，但它们都是用金属信号线传输电信号，本质上是共通的。<br>也就是说，电话线也会受到来自外部的噪声和来自内部的噪声（串扰）的干扰，导致信号失真。此外，电话线原本的设计并没有考虑到传输 ADSL 这样的高频信号，从这个角度上可以说它比以太网双绞线更容易受到噪声的干扰。</p>
<p>不过，电话线受到干扰的方式和双绞线有些不同。双绞线中只有一路方波信号，信号失真后就无法读取还原成数字信号，于是就会产生错误， 但 ADSL 信号受到干扰后并不会立即造成错误。ADSL 信号分布在多个频段上，只有和噪声频率相同的信号会受到影响而无法读取，即可用的信号数量减少，结果导致速率下降。</p>
<p>因此，电话线架设在噪声比较多的地方时，可能就会导致速率下降，比如电车线路旁边。电车的受电弓（pantograph）从架空接触网获取电力时会产生电火花释放噪声，ADSL 会因此受到干扰，导致速率下降。此外，ADSL 还会受到 AM 电台广播的干扰。</p>
<p>电缆内部产生的噪声也会形成干扰。图 4.8 中的四芯线内部，或者相邻子单元的附近如果同时存在 ADSL 和 ISDN 信号线，ISDN 发出的噪声就会干扰 ADSL。ADSL 刚刚开始普及的时候，大家还都比较关注防止 ISDN 干扰的技术，不过现在防止 ISDN 干扰的技术已经形成了，因此在使用 ADSL 时已经基本上没必要在意 ISDN 线路的问题了。</p>
<h2 id="通过-DSLAM-到达-BAS"><a href="#通过-DSLAM-到达-BAS" class="headerlink" title="通过 DSLAM 到达 BAS"></a>通过 DSLAM 到达 BAS</h2><p>信号通过电话线到达电话局之后，会经过配线盘、分离器到达 DSLAMA （图 4.3 ⑨）。在这里，电信号会被还原成数字信息——信元（图 4.3 ⑩）。</p>
<p>DSLAM 通过读取信号波形，根据振幅和相位判断对应的比特值，将信号还原成数字信息，这一过程和用户端的 ADSL Modem 在接收数据时的过程是一样的。因此，如果在电话局里安装一大堆和用户端一样的 ADSL Modem，也可以完成这些工作，只不过安装这么多 Modem 需要占用大量的空间，而且监控起来也非常困难。因此，电话局使用了 DSLAM 设备，它是一种将相当于很多个 ADSL Modem 的功能集中在一个外壳里的设备。<br>不过，DSLAM 和用户端 ADSL Modem 相比还是有一个不同的地方。</p>
<p>用户端 ADSL Modem 具备以太网接口，可以与用户端的路由器和计算机交互，收发以太网包，而 DSLAM 一般不用以太网接口，而是用 ATM 接口，和后方路由器收发数据时使用的是原始网络包拆分后的 ATM 信元形式。</p>
<p>DSLAM 具有 ATM 接口，和后方路由器收发数据时使用的是原始网络包拆分后的 ATM 信元形式。</p>
<p>信元从 DSLAM 出来之后，会到达一个叫作 BAS 的包转发设备（图 4.3 k）。BAS 和 DSLAM 一样，都具有 ATM 接口，可以接收 ATM 信 元，还可以将接收到的 ATM 信元还原成原始的包（图 4.3 l）。到这里，BAS 的接收工作就完成了，接下来，它会将收到的包前面的 MAC 头部和 PPPoE 头部丢弃，取出 PPP 头部以及后面的数据（图 4.3 m）。MAC 头部和 PPPoE 头部的作用是将包送达 BAS 的接口，当接口完成接收工作后，它们就完成了使命，可以被丢弃了。具有以太网接口的路由器在接收到包之后也会丢弃其中的 MAC 头部，道理是一样的。接下来，BAS 会在包的前面加上隧道专用头部，并发送到隧道的出口（图 4.3 n）。<br>然后，网络包会到达隧道出口的隧道专用路由器（图 4.3 o），在这里隧道头部会被去掉，IP 包会被取出（图 4.3 p），并被转发到互联网内部（图 4.3 q）。</p>
<p>BAS 负责将 ATM 信元还原成网络包并转发到互联网内部。</p>
<h1 id="光纤接入网（FTTH）"><a href="#光纤接入网（FTTH）" class="headerlink" title="光纤接入网（FTTH）"></a>光纤接入网（FTTH）</h1><h2 id="光纤的基本知识"><a href="#光纤的基本知识" class="headerlink" title="光纤的基本知识"></a>光纤的基本知识</h2><p>通过 ADSL 接入网和 BAS 之后，网络包就到达了互联网内部，另一种接入网技术叫 FTTH，是一种基于光纤的接入网技术。FTTH 的关键点在于对光纤的使用。</p>
<p>光纤的结构如图所示，它是由一种双层结构的纤维状透明材质（玻璃和塑料）构成的，通过在里面的纤芯中传导光信号来传输数字信息。ADSL 信号是由多个频段的信号组成的，比较复杂，但光信号却非常简单，亮表示 1，暗表示 0。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/10.png" class="">

<p>不过，数字信息并不能一下子变成光信号，而是需要先将数字信息转换成电信号，然后再将电信号转换成光信号。这里的电信号非常简单，1 用高电压表示，0 用低电压表示。将这样的电信号输入 LED、激光二极管等光源后，这些光源就会根据信号电压的变化发光，高电压发光亮，低电压发光暗。这样的光信号在光纤中传导之后，就可以通过光纤到达接收端。接收端有可以感应光线的光敏元件，光敏元件可以根据光的亮度产生不同的电压。当光信号照射到上面时，光亮的时候就产生高电压，光暗的时候就产生低电压，这样就将光信号转换成了电信号。</p>
<p>最后再将电信号转换成数字信息，我们就接收到数据了。这就是光纤的通信原理。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/11.png" class="">
<h2 id="单模与多模"><a href="#单模与多模" class="headerlink" title="单模与多模"></a>单模与多模</h2><p>光纤通信的关键技术就是能够传导光信号的光纤。光在透明材质中传导似乎听起来很简单，但实际上光的传导方式是非常复杂的，不同材质的光纤其透光率和折射率也不同，纤芯的直径等因素也会影响光的传导。其中，纤芯的直径对光的传导影响很大，要理解这一点，我们得先来看看光在光纤中是如何传导的。</p>
<p>首先，我们来看看光源发出的光是如何进入纤芯的。光源在所有方向上都会发光，因此会有各种角度的光线进入纤芯，但入射角度太大的光线会在纤芯和包层（纤芯外沿部分）的边界上折射出去，只有入射角较小的光线会被包层全反射，从而在纤芯中前进。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/12.png" class="">

<p>不过，也不是所有入射角小的光线都会在纤芯中传导。光也是一种波，因此光也有相位，当光线在纤芯和包层的边界上反射时，会由于反射角产生相位变化。当朝反射面前进的光线和被反射回来的光线交会时，如果两条光线的相位不一致，就会彼此发生干涉抵消，只有那些相位一致的光线才会继续在光纤中传导。</p>
<p>这个现象和往水面上投一颗石子产生的波纹是一样的。水波也有相位，在石子进入水面的瞬间，波纹中心会产生各种相位的波。不过，相位不同的波会相互干涉。相位不同的波在干涉后会变弱、消失，最后就只剩下相位相同的波向周围扩散开来。石子投入水面后扩散出来的波纹会形成同心圆状，一般大家对这样的现象已经习以为常，实际上只有相位相同的波才会扩散出来被我们看到。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/13.png" class="">

<p>如果周围没有障碍物，水面上的波纹会一直呈同心圆状扩散出去，但如果遇到两侧的墙壁，波纹就会被反射回来。这时，向墙壁前进的波和从墙壁反射回来的波就会相互叠加，其中相位相同的波相互加强，相位不同的波相互抵消。</p>
<p>光纤中的情况也是一样的，只不过和水波不同的是，光在被纤芯和包层的边界反射时，相位会发生变化。这个变化的量随光在反射面的反射角度不同而不同，大多数角度下，都会因为相位不同而被干涉抵消。不过，有几个特定的角度下，向反射面前进的光和反射回来的光的相位是一致的，只有以这些角度反射的光才能继续向前传导。进入光纤的光线有各种角度，但其中，只有少数按照特定角度入射以保持相位一致的光线才会继续传导。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/14.png" class="">

<p>这个角度非常关键，纤芯的直径也是根据这个角度来确定的，而且纤芯的直径大小会极大地改变光纤的性质。根据纤芯直径，光纤可以划分成几种类型，大体上包括较细的单模光纤（8～10 μm）和较粗的多模光纤（50 μm 或 62.5 μm）。单模光纤的纤芯很细，只有入射角很小的光线才能进入，因此在能够保持相位一致的角度中，只有角度最小的光线能进入光纤。</p>
<p>反过来可以说，单模光纤的纤芯直径就是按照只允许相位一致的最小角度的光进入而设计的。多模光纤的纤芯比较粗，入射角比较大的光也可以进入，这样一来，在相位一致的角度中，不仅角度最小的可以在光纤中传导，其他角度更大一些的也可以，也就是说，可以有多条光线在纤芯中同时传导。换句话说，单模和多模实际上表示相位一致的角度有一个还是多个。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/15.png" class="">

<p>单模光纤和多模光纤在光的传导方式上有所不同，这决定了它们的特性也有所不同。多模光纤中可以传导多条光线，这意味着能通过的光线较多，对光源和光敏元件的性能要求也就较低，从而可以降低光源和光敏元件的价格。相对地，单模光纤的纤芯中只能传导一条光线，能通过的光线较少，相应地对于光源和光敏元件的性能要求就较高，但信号的失真会比较小。</p>
<p>信号失真与光在纤芯传导时反射的次数相关。多模光纤中，多条反射角不同的光线同时传导，其中反射角越大的光线反射次数越多，走过的距离也就越长；相对地，反射角越小的光线走过的距离越短。光通过的距离会影响其到达接收端的时间，也就是说，通过的距离越长，到达接收端的时间越长。结果，多条光线到达的时间不同，信号的宽度就会被拉伸，这就造成了失真。因此，光纤越长，失真越大，当超过允许范围时，通信就会出错。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/16.png" class="">

<p>相对地，单模光纤则不会出现这样的问题。因为在纤芯传导的光线只有一条，不会因为行进距离的差异产生时间差，所以即便光纤很长，也不会产生严重的失真。</p>
<p>光纤的最大长度也是由上述性质决定的。单模光纤的失真小，可以比多模光纤更长，因此多模光纤主要用于一座建筑物里面的连接，单模光纤则用于距离较远的建筑物之间的连接。FTTH 属于后者，因此主要使用单模光纤。</p>
<h2 id="通过光纤分路来降低成本"><a href="#通过光纤分路来降低成本" class="headerlink" title="通过光纤分路来降低成本"></a>通过光纤分路来降低成本</h2><p>用光纤来代替 ADSL 将用户端接入路由器和运营商的 BAS 连接起来的接入方式就是 FTTH，从形态上可大致分为两种。</p>
<p>一种是用一根光纤直接从用户端连接到最近的电话局（图（a））。</p>
<p>这种类型的 FTTH 中，用户和电话局之间通过光纤直接连接，网络包的传输方式如下。首先，用户端的光纤收发器将以太网的电信号转换成光信号。这一步只进行电信号到光信号的转换，而不会像 ADSL 一样还需要将包拆分成信元，大家可以认为是将以太网包原原本本地转换成了光信号。</p>
<p>接下来，光信号通过连接到光纤收发器的光纤直接到达 BAS 前面的多路光纤收发器。FTTH 一般使用单模光纤，因此其纤芯中只有特定角度的光信号能够反射并前进。然后，多路光纤收发器将光信号转换成电信号，BAS 的端口接收之后，将包转发到互联网内部。</p>
<p>把网络包发送到互联网之后，服务器会收到响应，响应包的光信号也是沿着同一条光纤传输到用户端的。这里，前往互联网的上行光信号和前往用户的下行光信号在光纤中混合在一起，信号会变得无法识别，因此我们需要对它们进行区分，办法是上行和下行信号采用不同波长的光。波长不同的光混合后可通过棱镜原理进行分离，因此光纤中的上行和下行信号即便混合起来也可以识别。像这样在一条光纤中使用不同的波长传输多个光信号的方式叫作波分复用。</p>
<p>另一种光纤的接入方式是在用户附近的电线杆上安装一个名为分光器的设备，通过这个设备让光纤分路，同时连接多个用户（图（b））。在这种方式下，用户端不使用光纤收发器，而是使用一个叫作 ONU 的设备，它将以太网的电信号转换成光信号之后，会到达 BAS 前面的一个叫作 OLT 的设备。光信号的传导方式和直连方式是一样的，但有一点不同，因为多个用户同时收发网络包时信号会在分光器产生碰撞。因此，OLT 和 ONU 中具备通过调整信号收发时机来避免碰撞的功能。具体来说，OLT 会调整信号发送时机并向 ONU 下发指令，ONU 则根据 OLT 的指令来发送数据。反过来，当 BAS 端向用户发送数据时，分光器只需要将信号发给所有用户就可以了，这里并不会发生碰撞，但这样做会导致一个用户收到其他所有用户的信号，造成信息泄露的问题，因此需要在每个包前面加上用于识别 ONU 的信息，当 ONU 收到信号后，会接收发给自己的信号并将其转换成以太网信号。</p>
<p>像这样，FTTH 可以分为直连和分路两种方式，这两种方式只是光信号的传输方式有一些区别，实际传输的网络包是相同的。当使用 PPPoE 来传输包时，其工作过程和刚才讲过的 ADSL 类似。具体来说，就是像图4.3 中的⑤一样，由互联网接入路由器在 IP 头部前面加上 MAC 头部、PPPoE 头部和 PPP 头部，然后由光纤收发器或者 ONU 转换成光信号，并通过光纤到达 BAS 前面的多路光纤收发器和 OLT，最后被还原成电信号并到达 BAS。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/17.png" class="">
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/18.png" class="">
<h1 id="接入网中使用的-PPP-和隧道"><a href="#接入网中使用的-PPP-和隧道" class="headerlink" title="接入网中使用的 PPP 和隧道"></a>接入网中使用的 PPP 和隧道</h1><h2 id="用户认证和配置下发"><a href="#用户认证和配置下发" class="headerlink" title="用户认证和配置下发"></a>用户认证和配置下发</h2><p>用户发送的网络包会通过 ADSL 和 FTTH 等接入网到达运营商的 BAS。</p>
<p>互联网本来就是由很多台路由器相互连接组成的，因此原则上应该是将接入网连接到路由器上。随着接入网发展到 ADSL 和 FTTH，接入网连接的路由器也跟着演进，而这种进化型的路由器就叫作 BAS。</p>
<p>首先是用户认证和配置下发功能。ADSL 和 FTTH 接入网中，都需要先输入用户名和密码，登录之后才能访问互联网，而 BAS 就是登录操作的窗口。BAS 使用 PPPoE 方式来实现这个功能。PPPoE 是由传统电话拨号上网上使用的 PPP 协议发展而来的，所以我们先来看一看 PPP 拨号上网的工作方式。</p>
<p>在使用电话线或者 ISDN 拨号上网时，PPP 是如图 4.17 这样工作的。首先，用户向运营商的接入点拨打电话（图 4.17 ① -1），电话接通后（图 4.17 ① -2）输入用户名和密码进行登录操作（图 4.17 ② -2）。用户名和密码通过 RADIUSF 协议从 RASG 发送到认证服务器，认证服务器校验这些信息是否正确。当确认无误后，认证服务器会返回 IP 地址等配置信息，并将这些信息下发给用户（图 4.17 ② -3）。用户的计算机根据这些信息配置 IP 地址等参数，完成 TCP&#x2F;IP 收发网络包的准备工作，接下来就可以发送 TCP&#x2F;IP 包了（图 4.17 ③）。</p>
<p>这个过程的重点在于图 4.17 ② -3 下发 TCP&#x2F;IP 配置信息的步骤。在接入互联网时，必须为计算机分配一个公有地址，但这个地址并不是事先确定的。因为在拨号连接时，可以根据电话号码来改变接入点，而不同的接入点具有不同的 IP 地址，因此无法事先在计算机上设置这个地址。所以，在连接时运营商会向计算机下发 TCP&#x2F;IP 配置信息，其中就包括为计算机分配的公有地址。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/19.png" class="">
<h2 id="在以太网上传输-PPP-消息"><a href="#在以太网上传输-PPP-消息" class="headerlink" title="在以太网上传输 PPP 消息"></a>在以太网上传输 PPP 消息</h2><p>ADSL 和 FTTH 接入方式也需要为计算机分配公有地址才能上网，这一点和拨号上网是相同的。不过，ADSL 和 FTTH 中，用户和 BAS 之间是通过电缆或光纤固定连接在一起的，因此没有必要验证用户身份，所以实际上并不需要 PPP 的所有这些功能。然而，通过用户名和密码登录的步骤可以根据用户名来切换不同的运营商，这很方便。因此，接入运营商在 ADSL 和 FTTH 中一般也会使用 PPP。</p>
<p>不过，拨号上网的 PPP 是无法直接用于 ADSL 和 FTTH 的，要理解这里的原因，我们先来看看 PPP 协议是如何传输消息的。</p>
<p>传输 PPP 消息的思路和将 IP 包装入以太网包中传输是一样的。PPP 协议中没有定义以太网中的报头和 FCS 等元素，也没有定义信号的格式，因此无法直接将 PPP 消息转换成信号来发送。要传输 PPP 消息，必须有另一个包含报头、FCS、信号格式等元素的“容器”，然后将 PPP 消息装在这个容器里才行。于是，在拨号接入中 PPP 借用了 HDLCC 协议作为容器，而 HDLC 协议原本是为在专线中传输网络包而设计的，拨号接入方式对这一规格进行了一些修正。最终，PPP 消息就是像图 4.18（a）这样来进行传输的。</p>
<p>对于 ADSL 和 FTTH，如果可以和前面一样借用 HDLC 来作为容器，PPP 协议就可以直接使用了。但是，ADSL 和 FTTH 并不能使用 HDLC，因此需要寻找另一个机制作为替代。于是，如图 4.18（b）③和图 4.18（c）③所示，我们用以太网包代替 HDLC 来装载 PPP 协议。此外，以太网和 PPP 在设计上有所不同，为了弥补这些问题就重新设计了一个新的规格，这就是 PPPoE。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/20.png" class="">
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/21.png" class="">
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/22.png" class="">

<p>于是，ADSL 和 FTTH 也可以像拨号上网一样传输 PPP 消息了。图4.18 只展示了图 4.17 ② -2 部分，其他部分也是一样的。总之，只要将 PPP 消息装入以太网包中进行传输，ADSL 和 FTTH 就也可以像拨号上网一样通信了。</p>
<p>PPPoE 是将 PPP 消息装入以太网包进行传输的方式。</p>
<h2 id="通过隧道将网络包发送给运营商"><a href="#通过隧道将网络包发送给运营商" class="headerlink" title="通过隧道将网络包发送给运营商"></a>通过隧道将网络包发送给运营商</h2><p>BAS 除了作为用户认证的窗口之外，还可以使用隧道方式来传输网络包。所谓隧道，就类似于套接字之间建立的 TCP 连接。在 TCP 连接中，我们从一侧的出口（套接字）放入数据，数据就会原封不动地从另一个出口出来，隧道也是如此。也就是说，我们将包含头部在内的整个包从隧道的一头扔进去，这个包就会原封不动地从隧道的另一头出来，就好像在网络中挖了一条地道，网络包从这个地道里穿过去一样。<br>像这样，如果在 BAS 和运营商路由器之间的 ADSL&#x2F;FTTH 接入服务商的网络中建立一条隧道，将用户到 BAS 的接入网连接起来，就形成了一条从用户一直到运营商路由器的通道，网络包通过这条通道，就可以进入互联网内部了，这样的机制就类似于将接入网一直延伸到运营商路由器。</p>
<p>隧道有几种实现方式，刚才提到的 TCP 连接就是其中一种实现方式（图 4.19（a））。这种方式中，首先需要在网络上的两台隧道路由器 A 之间建立 TCP 连接，然后将连接两端的套接字当作是路由器的端口，并从这个端口来收发数据。换句话说，在路由器收发包时，是基于隧道的规则向隧道中放入或取出网络包，这时，TCP 连接就好像变成了一根网线，包从这里穿过到达另一端。 图 4.19（b）中还介绍了另一种基于封装（encapsulation）的隧道实现方式，这种方式是将包含头部在内的整个包装入另一个包中传输到隧道的另一端。在这种方式中，包本身可以原封不动地到达另一端的出口，从结果上看和基于 TCP 连接的方式是一样的，都实现了一个可供包进行穿梭的通道。</p>
<p>无论任何机制，只要能够将包原封不动搬运到另一端，从原理上看就都可以用来建立隧道。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/23.png" class="">
<h2 id="接入网的整体工作过程"><a href="#接入网的整体工作过程" class="headerlink" title="接入网的整体工作过程"></a>接入网的整体工作过程</h2><p>理解了 PPPoE 和隧道的原理之后，下面来看看接入网的整体工作过程。接入网的工作从用户端的互联网接入路由器进行连接操作开始。首先，接入路由器中需要配置运营商分配的用户名和密码 A。然后，接入路由器会根据 PPPoE 的发现机制来寻找 BAS。这一机制和 ARP 一样是基于广播来实现的，过程如下，很简单。</p>
<p>用户询问：“BAS 在不在？在的话请报告 MAC 地址。”<br>BAS 回答：“我在这里，我的 MAC 地址是 xx:xx:xx:xx:xx:xx。”<br>这样用户端就知道了 BAS 的 MAC 地址，也就可以和 BAS 进行通信了。大家可以认为前面这个过程相当于拨号上网中拨通电话的动作（图4.17 ① -1 和① -2）。<br>互联网接入路由器通过 PPPoE 的发现机制查询 BAS 的 MAC 地址。</p>
<p>接下来，如图 4.17 ② -1 到② -4 中所示，进入用户认证和下发配置的阶段。这里的工作过程有点复杂，我们只说重点。第一个重点是用户名和密码如何发送给 BAS。这里有两种方式，一种是将密码进行加密的 CHAPB 方式，另一种是不加密的 PAPC 方式，在互联网接入路由器的设置画面中可以选择。进行加密的 CHAP 方式显然安全性更高，一般也推荐使用这种方式，但也并不是说使用不加密的 PAP 方式密码就立刻会被窃取。</p>
<p>由于明文密码只在 BAS 和用户端路由器之间传输 D，所以如果要窃取密码，要么在路由器和 ADSL Modem 中间进行窃听，要么爬到电线杆上安装窃听装置拾取电缆中泄漏的电磁波。不过，光纤是不会泄漏电磁波的，因此无法通过第二种方式进行窃听。</p>
<p>第二个重点是，在校验密码之后 BAS 如何向用户下发 TCP&#x2F;IP 配置信息。这里下发的配置信息包括分配给上网设备的 IP 地址、DNS 服务器的 IP 地址以及默认网关的 IP 地址。当使用路由器连接互联网时，路由器会根据这些信息配置自身的参数。这样一来，路由器的 BAS 端的端口就有了公有地址，路由表中也配置好了默认网关，接下来就可以将包转发到互联网中了。<br>BAS 下发的 TCP&#x2F;IP 参数会被配置到互联网接入路由器的 BAS 端的端口上，这样路由器就完成接入互联网的准备了。</p>
<p>接下来，客户端就会开始发送用来访问互联网的网络包，比如有人在浏览器里输入了一个网址，这时网络包就开始发送了。这些包的目的地是互联网中的某个地方，这个地方或许在互联网接入路由器的路由表里是找不到的。这时，路由器会选择默认路由，并将这个包转发给默认路由的网关地址，也就是 BAS 下发的默认路由。这里的操作过程和第 3 章介绍的路由器转发包的过程相同，只不过在通过路由表判断转发目标之后，包不是按照以太网规则转发，而是按照 PPPoE 规则转发，具体的过程如下。首先，如图 4.20，要发送的包会被加上头部信息，并设置相应的字段。第一个 MAC 头部中，接收方 MAC 地址填写通过 PPPoE 发现机制查询到的 BAS 的 MAC 地址，发送方 MAC 地址填写互联网接入路由器的 BAS 端的端口的 MAC 地址，然后以太类型填写代表 PPPoE 的 8864（十六进制）。接下来是 PPPoE 头部和 PPP 头部，它们包含的字段如图 4.20 所示，其中除了载荷长度之外，其他的值都是可以事先确定的，载荷长度就是需要传输的包的长度。再往后的部分就是包含 IP 头部在内的原始网络包。可以说，这里的转发操作中基本上不需要根据头部中的信息进行判断，只要将事先准备好的头部加上去就可以了。然后，网络包会被转换成信号，从相应的端口发送出去。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/24.png" class="">

<p>接下来，网络包会到达 BAS，而 BAS 会将 MAC 头部和 PPPoE 头部去掉，取出 PPP 头部以及后面的部分，然后通过隧道机制将包发送出去。<br>最后，PPP 包会沿隧道到达另一端的出口，也就是网络运营商的路由器。<br>BAS 在收到用户路由器发送的网络包之后，会去掉 MAC 头部和 PPPoE 头部，然后用隧道机制将包发送给网络运营商的路由器。<br>BAS 在收到用户路由器发送的网络包之后，会去掉 MAC 头部和 PPPoE 头部，然后用隧道机制将包发送给网络运营商的路由器。</p>
<h2 id="不分配-IP-地址的无编号端口"><a href="#不分配-IP-地址的无编号端口" class="headerlink" title="不分配 IP 地址的无编号端口"></a>不分配 IP 地址的无编号端口</h2><p>前面介绍了 PPPoE 的工作过程，这里面有一个有趣的问题，就是互联网接入路由器在发送包的时候为什么要加上那些头部呢？头部里面的值基本上都是事先定好的，跟路由表里面的默认网关地址根本没什么关系。当采用一对一连接，也就是两台路由器的端口用一根线直接连起来的情况下，一端发送的包肯定会到达另一端，那么这种情况下就没有必要按照路由表查询默认网关来判断转发目标地址了。如果没有必要判断转发地址，那么网关的地址也就没什么用了；如果网关地址没用，那么目标路由器的端口也用不着分配 IP 地址了。上面的性质对于所有一对一连接都是适用的。</p>
<p>以前，即便是在这样的场景中，还是会为每个端口分配 IP 地址，这是因为有一条规则规定所有的端口都必须具有 IP 地址。然而，当公有地址越来越少时，就提出了一个特例，即一对一连接的端口可以不分配 IP 地址。<br>现在，在这种场景中按惯例都是不为端口分配 IP 地址的 B，这种方式称为无编号（unnumbered）。这种情况下，BAS 下发配置信息时就不会下发默认网关的 IP 地址。<br>一对一连接的端口可以不分配 IP 地址，这种方式称为无编号。</p>
<h2 id="互联网接入路由器将私有地址转换成公有地址"><a href="#互联网接入路由器将私有地址转换成公有地址" class="headerlink" title="互联网接入路由器将私有地址转换成公有地址"></a>互联网接入路由器将私有地址转换成公有地址</h2><p>前面的介绍里面其实遗漏了一个地方，那就是互联网接入路由器在转发包时需要进行地址转换。刚才我们讲过，BAS 会向用户端下发 TCP&#x2F;IP 的配置信息，如果将这些信息配置在计算机上，就相当于计算机拥有了公有地址，这种情况下不需要进行地址转换也可以访问互联网。其实 TCP&#x2F;IP 原本的设计就是这样的。然而，如果使用路由器来上网，BAS 下发的参数就会被配置在路由器上，而且公有地址也是分配给路由器的。这样一来，计算机就没有公有地址了。</p>
<p>这时，计算机会被分配一个私有地址，计算机发送的包需要通过路由器进行地址转换然后再转发到互联网中。Web 和电子邮件等应用程序不会受到地址转换的影响，但有些应用程序会因为地址转换无法正常工作，这一点需要大家注意。这是因为有些应用程序需要将自己的 IP 地址告知通信对象或者告知控制服务器，但在有地址转换的情况下这些操作无法完成。</p>
<p>遇到应用程序因地址转换无法正常工作的情况时，我们可以不使用路由器，而是直接让计算机接收来自 BAS 的 PPPoE 消息，也就是采用最原始的上网方法。这样一来，计算机就具有了公有地址，不需要地址转换也可以上网了。</p>
<p>不过，不用路由器上网也有一点需要注意，因为上网的计算机拥有公有地址，这意味着来自互联网的包可以直接到达计算机，这可能导致计算机被攻击。因此，对于直接上网的客户端计算机，我们应该采取安装防火墙软件等防御手段。</p>
<h2 id="除-PPPoE-之外的其他方式"><a href="#除-PPPoE-之外的其他方式" class="headerlink" title="除 PPPoE 之外的其他方式"></a>除 PPPoE 之外的其他方式</h2><p>刚才我们讲的内容都是基于 PPPoE 方式的，实际的接入网还有其他一些方式。下面我们先跑个题，简单介绍一下这些其他的方式。</p>
<p>首先，我们先看看使用 PPPoA 方式的 ADSL 接入网。ADSL 使用 PPPoE 方式时，是先将 PPP 消息装入以太网包中，然后再将以太网包拆分并装入信元，而 PPPoA 方式是直接将 PPP 消息装入信元（图 4.21）。由于只是开头加不加 MAC 头部和 PPPoE 头部的区别，PPP 消息本身是没有区别的，因此密码校验、下发 TCP&#x2F;IP 配置参数、收发数据包等过程都是和 PPPoE 基本相同的。不过，虽然开头加不加 MAC 头部和 PPPoE 头部看上去只是很小的区别，但却会对用户体验产生一定的影响。 PPPoA 方式不添加 MAC 头部和 PPPoE 头部，而是直接将包装入信元中。</p>
<p>由于 PPPoA 没有 MAC 头部，所以 PPP 消息是无法通过以太网来传输的，这就意味着需要和 BAS 收发 PPP 消息的设备，也就是计算机和路由器，必须和 ADSL Modem 是一体的，否则 PPP 机制就无法工作了。这个一体化的方式主要有以下两种。</p>
<p>第一种是将计算机和 ADSL Modem 用 USB 接口连接起来，这样 ADSL Modem 就和计算机成为一体了。不过，这种方式最终并没有普及。<br>另一种方式是像图 4.21 所示的这样，将 ADSL Modem 和路由器整合成一台设备。这种方式和 PPPoE 中使用路由器上网的方式基本没什么区别，因此得到了广泛的普及。不过，正如我们刚才提到的，当由于地址转换产生问题时，这种方式就不容易处理了，因为我们无法抛开路由器用计算机直接上网。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/25.png" class="">

<p>当然，PPPoA 和 PPPoE 相比也有一些优势。PPPoE 方式中，如图 4.18 所示，需要添加 PPPoE 头部和 PPP 头部，这意味着 MTU 就相应变小了，这可能会降低网络的效率。而 PPPoA 不使用以太网包来传输 PPP 消息，因此不会发生 MTU 变小的问题。</p>
<p>PPPoE 会降低网络效率，PPPoA 也有 ADSL Modem 和路由器无法分离的限制，这两个问题其实都是由 PPP 引起的。因此，有一些运营商不使用 PPP，他们使用 DHCPA 协议从 BAS 向用户端下发 TCP&#x2F;IP 配置信息。<br>DHCP 经常用于通过公司网络向客户端计算机下发 TCP&#x2F;IP 配置信息，其原理如图 4.22 所示，首先客户端请求配置信息（图 4.22 ①），然后 DHCP 服务器下发配置信息（图 4.22 ②），非常简单，不需要像 PPP（图 4.17）那样需要多个步骤，也不需要验证用户名和密码。没有用户名和密码，就意味着无法通过用户名来切换运营商网络，但这种方式也有优势，它可以单纯地直接传输以太网包，不需要添加额外的 PPP 头部，因此不会占用 MTU。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/26.png" class="">

<p>此外，采用 DHCP 的运营商使用的 ADSL Modem 也和 PPPoE、PPPoA 方式不同，这种 ADSL Modem 不使用信元，而是直接将以太网包调制成 ADSL 信号，因此没有 ADSL Modem 和路由器无法分离的问题。<br>还有一种 DHCP 方式，它不使用 PPP，而是将以太网包直接转换成 ADSL 信号发送给 DSLAM。</p>
<h1 id="网络运营商的内部"><a href="#网络运营商的内部" class="headerlink" title="网络运营商的内部"></a>网络运营商的内部</h1><h2 id="POP-和-NOC"><a href="#POP-和-NOC" class="headerlink" title="POP 和 NOC"></a>POP 和 NOC</h2><p>现在网络包已经通过接入网，到达了网络运营商的路由器。这里是互联网的入口，网络包会从这里进入互联网内部。</p>
<p>互联网的实体并不是由一个组织运营管理的单一网络，而是由多个运营商网络相互连接组成的。ADSL、FTTH 等接入网是与用户签约的运营商设备相连的，这些设备称为 POP，互联网的入口就位于这里。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/27.png" class="">

<p>网络包通过接入网之后，到达运营商 POP 的路由器。</p>
<p>那么，POP 里面是什么样的呢？ POP 的结构根据接入网类型以及运营商的业务类型不同而不同，大体上是下图这个样子。POP 中包括各种类型的路由器，路由器的基本工作方式是相同的，但根据其角色分成了不同的类型。图中，中间部分列出了连接各种接入网的路由器，这里的意思就是根据接入网的类型需要分别使用不同类型的路由器。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/28.png" class="">

<p>我们从上面开始看，首先是专线，这里用的路由器就是具有通信线路端口的一般路由器。专线不需要用户认证、配置下发等功能，因此用一般的路由器就可以了。接下来是电话、ISDN 等拨号方式的接入网，这里使用的路由器称为 RAS。拨号接入需要对用户拨电话的动作进行应答，而 RAS 就具备这样的功能。此外，通过 PPP 协议进行身份认证和配置下发的过程，RAS 也具备这些功能。再往下是 PPPoE 方式的 ADSL 和 FTTH。PPPoE 方式中，ADSL、FTTH 接入服务商会使用 BAS，运营商的路由器则与 BAS 相连。PPPoE 中的身份认证和配置下发操作由接入服务商的 BAS 来负责，运营商的路由器只负责对包进行转发，因此这里也是使用一般的路由器就可以了。如果 ADSL 采用 PPPoA 方式接入，那么工作过程会有所不同，DSLAM 通过 ATM 交换机与 ADSL 的运营商的 BAS 相连，然后再连接到运营商的路由器。用户端传输的信号先经过 ADSL Modem 拆分成 ATM 信元并进行调制，然后 DSLAM 将信号还原成信元，通过 ATM 交换机转发到 BAS，最后 BAS 将信元还原成网络包，再通过运营商的路由器转发到互联网内部。</p>
<p>对于连接接入网的部分来说，由于要连接的线路数量很多，所以路由器需要配备大量的端口，但能传输的网络包数量相对比较少，这是因为接入网的速率比互联网核心网络要低。因此，端口多且价格便宜的路由器适用于这些场景。相对地，图中左侧的路由器用于连接运营商和核心 NOC 以及其他 POP，所有连接接入网的路由器发出的包都会集中到这里，使用的线路速率也比较高，因此这里需要配备转发性能和数据吞吐量高的路由器。</p>
<p>NOCA 是运营商的核心设备，从 POP 传来的网络包都会集中到这里，并从这里被转发到离目的地更近的 POP，或者是转发到其他的运营商。这里也需要配备高性能的路由器。</p>
<p>话说回来，到底需要多高的性能才行呢？我们来看实际产品的参数。</p>
<p>面向运营商的高性能路由器中有些产品的数据吞吐量超过 1 Tbit&#x2F;s，而一般面向个人的路由器的数据吞吐量也就 100 Mbit&#x2F;s 左右，两者相差 1 万多倍。当然，路由器的性能不完全是由吞吐量决定的，但从这里可以看出规模和性能的差异。</p>
<p>其实，NOC 和 POP 并没有非常严格的界定。NOC 里面也可以配备连接接入网的路由器，很多情况下是和 POP 共用的。从 IP 协议的传输过程来看，也没有对两者进行区分的必然性，因为无论是哪个路由器，其转发网络包的基本工作原理都是相同的。因此，大家可以简单地认为，NOC 就是规模扩大后的 POP。</p>
<h2 id="室外通信线路的连接"><a href="#室外通信线路的连接" class="headerlink" title="室外通信线路的连接"></a>室外通信线路的连接</h2><p>POP 和 NOC 遍布全国各地，它们各自的规模有大有小，但看起来跟公司里的机房没什么太大区别，都是位于一幢建筑物中的，其中的路由器或者通过线路直接连接，或者通过交换机进行连接，这些和公司以及家庭网络都是相同的。只不过，公司的机房一般使用双绞线来连接设备，但运营商的网络中需要传输大量的包，已经超过了双绞线能容纳的极限，因此一般还是更多地使用光纤。</p>
<p>大楼室内可以用线路直接连接，对于距离较远的 NOC 和 POP 来说，它们之间的连接方式可以分为几种。</p>
<p>对于自己拥有光纤的运营商来说，可以选择最简单的方式，也就是用光纤将 NOC 和 POP 直接连接起来。这种方式虽然想法简单，但实现起来却并不简单。光纤需要在地下铺设，需要很大的工程费用，而且当线路发生中断时还必须进行维修，这些维护工作也需要费用。因此，只有有限的几家大型运营商才拥有光纤。</p>
<p>那么，其他运营商怎么办呢？其实也不难，只要从其他公司租借光纤就可以了，但所谓租借并不是光纤本身。</p>
<p>拥有光纤的公司一般都会提供光纤租用服务。以电话公司为例，电话公司会在其拥有的光纤中传输语音数据，但一条光纤并不是只能传输一条语音数据，光纤是可以复用的，一条语音数据只占其通信能力的一部分。<br>换句话说，电话公司可以将自己的光纤的一部分通信能力租借给客户。对于客户来说，只要支付一定的费用就可以使用其中的通信能力了。对于电话公司来说，其拥有的光纤不会全部自己使用，通过租借的方式也可以带来一定的收益，无论其业务本质是电话还是互联网，这一点都是共通的。</p>
<p>这种服务就叫作通信线路服务。</p>
<p>不拥有光纤的运营商则可以使用租借通信线路的方式将相距较远的 NOC 和 POP 连接起来。电话使用的通信线路（电话线）只能传输语音这种单一形式的数据，但运营商使用的通信线路则种类繁多。首先，在速率上就分为很多种，其中比较快的种类，其速率为电话线的 100 万倍左右。除了速率之外，数据的传输方式也分为很多种。以前，将多条电话线捆绑在一起的方式比较主流，现在我们有了各种类型的通信线路，其中也有一些公司不对光纤进行细分，而是直接将整条光纤租借出去。不同的通信方式和速率对应着不同的价格，对于不拥有光纤的运营商来说，需要根据需要从中进行选择。</p>
<h1 id="跨越运营商的网络包"><a href="#跨越运营商的网络包" class="headerlink" title="跨越运营商的网络包"></a>跨越运营商的网络包</h1><h2 id="运营商之间的连接"><a href="#运营商之间的连接" class="headerlink" title="运营商之间的连接"></a>运营商之间的连接</h2><p>让我们重新回到运营商内部，看一看到达 POP 路由器之后，网络包是如何前往下一站的。首先，如果最终目的地 Web 服务器和客户端是连接在同一个运营商中的，那么 POP 路由器的路由表中应该有相应的转发目标。</p>
<p>运营商的路由器可以和其他路由器交换路由信息，从而自动更新自己的路由表，通过这一功能，路由信息就实现了自动化管理。于是，路由器根据路由表中的信息判断转发目标，这个转发目标可能是 NOC，也可能是相邻的 POP，无论如何，路由器都会把包转发出去，然后下一个路由器也同样根据自己路由表中的信息继续转发。经过几次转发之后，网络包就到达了 Web 服务器所在的 POP 的路由器，然后从这里被继续转发到 Web 服务器。</p>
<p>那么，如果服务器的运营商和客户端的运营商不同又会怎样呢？这种情况下，网络包需要先发到服务器所在的运营商，这些信息也可以在路由表中找到，这是因为运营商的路由器和其他运营商的路由器也在交换路由信息。这个信息交换的过程稍后再讲，我们暂且认为路由表中能找到对方运营商的路由信息，这时网络包会被转发到对方运营商的路由器。</p>
<p>总之，对于互联网内部的路由器来说，无论最终目的地是否属于同一家运营商，都可以从路由表中查到，因此只要一次接一次按照路由表中的目标地址来转发包，最终一定可以到达 Web 服务器所在的 POP。这样一来，我们就可以把包发到任何地方，包括地球的另一面。</p>
<h2 id="运营商之间的路由信息交换"><a href="#运营商之间的路由信息交换" class="headerlink" title="运营商之间的路由信息交换"></a>运营商之间的路由信息交换</h2><p>只要路由表中能够查到，我们当然可以把包发到任何地方，包括地球的另一面，但这些路由信息是如何写入路由表的呢？如果路由表中没有相应的路由信息，路由器就无法判断某个网络的位置，也就无法对包进行转发，也就是说，仅仅用线路将路由器连起来，是无法完成包转发的。</p>
<p>下面我们来看看运营商之间是如何交换路由信息，并对路由器进行自动更新的。</p>
<p>其实方法并不难。如图所示，只要让相连的路由器告知路由信息就可以了。只要获得了对方的路由信息，就可以知道对方路由器连接的所有网络，将这些信息写入自己的路由表中，也就可以向那些网络发送包了。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/29.png" class="">

<p>获得对方的路由信息之后，我们也需要将自身的路由信息告知对方。</p>
<p>这样一来，对方也可以将发往我们所在子网的包转发过来。这个路由信息交换的过程是由路由器自动完成的，这里使用的机制称为 BGP。</p>
<p>根据所告知的路由信息的内容，这种路由交换可分为两类。一类是将互联网中的路由全部告知对方。例如图中，如果运营商 D 将互联网上所有路由都告知运营商 E，则运营商 E 不但可以访问运营商 D，还可以访问运营商 D 后面的运营商 B、A 和 C。然后，通过运营商 D 就可以向所有的运营商发送包。像这样，通过运营商 D 来发送网络包的方式称为转接。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/30.png" class="">

<p>另一种类型是两个运营商之间仅将与各自网络相关的路由信息告知对方。这样，只有双方之间的网络可以互相收发网络包，这种方式称为非转接，也叫对等。<br>互联网内部使用 BGP 机制在运营商之间交换路由信息。</p>
<h2 id="与公司网络中自动更新路由表机制的区别"><a href="#与公司网络中自动更新路由表机制的区别" class="headerlink" title="与公司网络中自动更新路由表机制的区别"></a>与公司网络中自动更新路由表机制的区别</h2><p>路由器之间相互交换信息自动更新路由表的方式在公司网络中也会用到，不过公司内部和运营商之间在路由交换方式上是有区别的。</p>
<p>公司中使用的方式是寻找与目的地之间的最短路由，并按照最短路由来转发包，因此，周围的所有路由器都是平等对待的。</p>
<p>公司内部采用这样的方式没问题，但运营商之间就不行了。假设某个运营商拥有一条连接日本和美国的高速线路，那么要访问美国的地址时，可能这条线路是最短路由。如果单纯采用最短路由的方式，那么其他运营商的包就都会走这条线路，这时，该运营商需要向其他运营商收取相应的费用，否则就成义务劳动了。在这种情况下，如果使用最短路由的方式，就无法区分哪个运营商交了费，哪个运营商没交费，也就是说无法阻止那些没交费的运营商使用这条线路，这样就很难和对方进行交涉了。正是出于这样的原因，互联网中不能单纯采用最短路由，而是需要一种能够阻止某些来源的网络包的机制，互联网的路由交换机制就具有这样的功能。</p>
<p>首先，互联网中可以指定路由交换的对象。公司中，路由信息是在所有路由器间平等交换的，但运营商之间的路由交换是在特定路由器间一对一进行的。这样一来，运营商就可以只将路由信息提供给那些交了费的运营商，那些没交费的运营商也就无法将网络包发送过来了。</p>
<p>其次，在判断路由时，该机制不仅可以判断是否是最短路由，还可以设置其他一些判断因素。例如当某个目的地有多条路由时，可以对每条路由设置优先级。</p>
<p>运营商之间需要对交换路由信息的对象进行判断和筛选，但这样一来，对于没有交换路由信息的运营商网络，我们就无法将网络包发送过去了，如果要访问的 Web 服务器就在那个运营商网络中，我们不就访问不了了吗？其实不用担心，运营商在进行路由交换时会避免出现这样的情况。互联网中有很多运营商，每个运营商都和其他多个运营商相互连接。因此，如果一个运营商走不过去，可以走另一个运营商，无论网络包要发送到什么地方，都会确保能够获取相应的路由信息。如果某个运营商做不到这一点，那它也就该倒闭了。</p>
<h2 id="IX-的必要性"><a href="#IX-的必要性" class="headerlink" title="IX 的必要性"></a>IX 的必要性</h2><p>对于两个运营商来说，一对一的连接是最基本的一种连接方式，现在也会使用这种方式。但这种方式有个不方便的地方，如果运营商之间只能一对一连接，那么就需要像下图（a）这样将所有的运营商都用通信线路连接起来。现在光日本国内就有数千家运营商，这样连接非常困难。对于这种情况，我们可以采用下图（b）的方式，设置一个中心设备，通过连接到中心设备的方式来减少线路数量，这个中心设备就称为 IX。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/31.png" class="">
<h2 id="运营商如何通过-IX-互相连接"><a href="#运营商如何通过-IX-互相连接" class="headerlink" title="运营商如何通过 IX 互相连接"></a>运营商如何通过 IX 互相连接</h2><p>首先是 IX 的部署场所。为了保证在遇到停电、火灾等事故，以及地震等自然灾害时，路由器等网络设备还能继续工作，IX 所在的大楼都装有自主发电设备，并具有一定的抗震能力。其实这样的要求也不仅限于 IX，运营商的 NOC 也是一样。拥有如此高安全性的大楼其实并不多，因此符合这样要求的大楼里面都可能会有 NOC 和 IX。运营商和 IX 运营机构会租下大楼中的一块地方用于放置 NOC 和 IX 的设备，换句话说，IX 就在这些大楼中某一层的某个角落中。</p>
<p>IX的核心是具有大量高速以太网端口的二层交换机（图4.28）。二层交换机的基本原理和一般交换机相同，大家可以认为 IX 的核心就是大型的、高速的交换机。</p>
<p>接下来就是将各个运营商的路由器连接到 IX 核心交换机上，连接方法有几种。首先，当运营商 NOC 和 IX 位于同一幢大楼里时，只要从 NOC 中将光纤延长出来接到 IX 交换机就可以了（图 4.28 ①）。这种情况和公司、家庭网络中的路由器与交换机的连接方法是相同的。这种方法很简单，但如果 NOC 和 IX 不在同一幢大楼里又该怎么办呢？我们可以用通信线路将路由器和交换机连起来。这种情况下有两种连法，一种是从路由器延伸出一根通信线路并连接到 IX 交换机上（图 4.28 ②），另一种是将路由器搬到 IX 机房里，用通信线路将路由器和 NOC 连起来，再将路由器连到 IX 交换机上（图 4.28 ③）。</p>
<p>以前 IX 交换机都是放在一个地方的，也就是呈点状分布的。现在这些点状设施已经逐步扩张，在数据中心等网络流量集中的地方一般都会设置 IX终端交换机，各运营商的路由器在这里连接到终端交换机上（图 4.28 ④）。</p>
<p>IX 已经从点扩张到线，甚至到面了。</p>
<p>下面我们来看一看网络包具体是如何传输的。其实这里并没有什么特别需要解释的，因为 IX 的交换机和一般的交换机在工作方式上没有区别，路由器发送网络包时，先通过 ARP 查询下一个路由器的 MAC 地址，然后将其写入 MAC 头部发送出去即可。只要填写了正确的 MAC 地址，就可以向任何运营商的路由器发送包。不过实际上，要成功发送包还需要正确的路由信息，对于没有进行路由交换的运营商，我们是无法向其发送包的。</p>
<p>这需要运营商之间通过谈判签订合约，然后按照合约来交换路由信息，实现网络包的收发。</p>
<p>运营商之间可以直接连接，也可以通过 IX 连接，无论是哪种方式，最终网络包都会到达服务器所在的运营商，然后通过 POP 进入服务器端的网络。</p>
<img src="/2021/12/09/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%844/32.png" class=""> 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" rel="tag">计算机网络</a></li></ul>

    </footer>
  </div>

   
   
  
</article>

    
    <article
  id="post-网络是怎样连接的/网络是怎样连接的3"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/"
    >网络是怎样连接的——集线器、交换机和路由器</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/" class="article-date">
  <time datetime="2021-12-03T06:51:41.000Z" itemprop="datePublished">2021-12-03</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">计算机网络</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="信号在网线和集线器中传输"><a href="#信号在网线和集线器中传输" class="headerlink" title="信号在网线和集线器中传输"></a>信号在网线和集线器中传输</h1><h2 id="每个包都是独立传输的"><a href="#每个包都是独立传输的" class="headerlink" title="每个包都是独立传输的"></a>每个包都是独立传输的</h2><p>从计算机发送出来的网络包会通过集线器、路由器等设备被转发，最终到达目的地。转发设备会根据包头部中的控制信息，在转发设备内部一个写有转发规则的表中进行查询，以此来判断包的目的地，然后将包朝目的地的方向进行转发。</p>
<p>转发设备在进行转发时也不看数据的内容。因此，无论包里面装的是应用程序的数据或者是 TCP 协议的控制信息，都不会对包的传输操作本身产生影响。换句话说，HTTP 请求的方法，TCP 的确认响应和序号，客户端和服务器之间的关系，这一切都与包的传输无关。因此，所有的包在传输到目的地的过程中都是独立的，相互之间没有任何关联。</p>
<h3 id="网络包在进入互联网之前经历的传输过程"><a href="#网络包在进入互联网之前经历的传输过程" class="headerlink" title="网络包在进入互联网之前经历的传输过程"></a>网络包在进入互联网之前经历的传输过程</h3><p>假设客户端计算机连接的局域网结构如图。</p>
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/1.png" class="">

<p>网络包从客户端计算机发出之后，要经过集线器、交换机和路由器最终进入互联网。实际上，我们家里用的路由器已经集成了集线器和交换机的功能，像图上这样使用独立设备的情况很少见。不过，把每个功能独立出来更容易理解，而且理解了这种模式之后，也就能理解集成了多种功能的设备了，因此我们这里将所有功能独立出来。</p>
<h2 id="防止网线中的信号衰减很重要"><a href="#防止网线中的信号衰减很重要" class="headerlink" title="防止网线中的信号衰减很重要"></a>防止网线中的信号衰减很重要</h2><img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/2.png" class="">
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/3.png" class="">

<p>从信号流出网卡进入网线开始。网卡中的 PHY（MAU）(信号收发模块) 模块负责将包转换成电信号，信号通过 RJ-45 接口进入双绞线。以太网信号的本质是正负变化的电压，大家可以认为网卡的 PHY（MAU）模块就是一个从正负两个信号端子输出信号的电路。</p>
<p>网卡的 PHY（MAU）模块直接连接 RJ-45 接口，信号从这个接口中的 1 号和 2 号针脚流入网线。然后，信号会通过网线到达集线器的接口，这个过程就是单纯地传输电信号而已。</p>
<p>但是，信号到达集线器的时候并不是跟刚发送出去的时候一模一样。集线器收到的信号有时会出现衰减。信号在网线的传输过程中，能量会逐渐损失。网线越长，信号衰减就越严重。</p>
<p>而且，信号损失能量并非只是变弱而已。以太网中的信号波形是方形的，但损失能量会让信号的拐角变圆，这是因为电信号的频率越高，能量的损失率越大。信号的拐角意味着电压发生剧烈的变化，而剧烈的变化意味着这个部分的信号频率很高。高频信号更容易损失能量，因此本来剧烈变化的部分就会变成缓慢的变化，拐角也就变圆了。</p>
<p>即便线路条件很好，没有噪声，信号在传输过程中依然会发生失真，如果再加上噪声的影响，失真就会更厉害。噪声根据强度和类型会产生不同的影响，无法一概而论，但如果本来就已经衰减的信号再进一步失真，就会出现对 0 和 1 的误判，这就是产生通信错误的原因。</p>
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/4.png" class="">
<h2 id="“双绞”是为了抑制噪声"><a href="#“双绞”是为了抑制噪声" class="headerlink" title="“双绞”是为了抑制噪声"></a>“双绞”是为了抑制噪声</h2><p>局域网网线使用的是双绞线，其中“双绞”的意思就是以两根信号线为一组缠绕在一起，这种拧麻花一样的设计是为了抑制噪声的影响。那么双绞线为什么能够抑制噪声呢？首先，我们来看看噪声是如何产生的。</p>
<h3 id="产生噪声的原因"><a href="#产生噪声的原因" class="headerlink" title="产生噪声的原因"></a>产生噪声的原因</h3><p>产生噪声的原因是网线周围的电磁波，当电磁波接触到金属等导体时，在其中就会产生电流。因此，如果网线周围存在电磁波，就会在网线中产生和原本的信号不同的电流。由于信号本身也是一种带有电压变化的电流，其本质和噪声产生的电流是一样的，所以信号和噪声的电流就会混杂在一起，导致信号的波形发生失真，这就是噪声的影响。</p>
<p>影响网线的电磁波分为两种。一种是由电机、荧光灯、CRT 显示器等设备泄漏出来的电磁波，这种电磁波来自网线之外的其他设备，我们来看看双绞线如何抑制这种电磁波的影响。首先，信号线是用金属做成的，当电磁波接触到信号线时，会沿电磁波传播的右旋方向产生电流，这种电流会导致波形发生失真。如果我们将信号线缠绕在一起，信号线就变成了螺旋形，其中两根信号线中产生的噪声电流方向就会相反，从而使得噪声电流相互抵消，噪声就得到了抑制（a）。当然，即便信号线变成螺旋形，里面的信号依然可以原样传输，也就是说，信号没有变，只是噪声被削弱了。</p>
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/5.png" class="">

<p>另一种电磁波是从网线中相邻的信号线泄漏出来的。由于传输的信号本身就是一种电流，当电流流过时就会向周围发出电磁波，这些电磁波对于其他信号线来说就成了噪声。这种内部产生的噪声称为串扰。</p>
<p>这种噪声的强度其实并不高，但问题是噪声源的距离太近了。距离发生源越远，电磁波就会因扩散而变得越弱，但在同一根网线中的信号线之间距离很近，这些电磁波还没怎么衰减就已经接触到了相邻的信号线。因此，尽管信号线产生的电磁波十分微弱，也能够在相邻的信号线中产生感应电流。</p>
<h3 id="双绞抑制噪声"><a href="#双绞抑制噪声" class="headerlink" title="双绞抑制噪声"></a>双绞抑制噪声</h3><p>要抑制这种噪声，关键在于双绞线的缠绕方式。在一根网线中，每一对信号线的扭绞间隔（节距）都有一定的差异，这使得在某些地方正信号线距离近，另一些地方则是负信号线距离近。由于正负信号线产生的噪声影响是相反的，所以两者就会相互抵消（b）。从网线整体来看，正负的分布保持平衡，自然就会削弱噪声的影响。</p>
<p>通过将信号线缠绕在一起的方式，噪声得到了抑制，从结果来看提升了网线的性能，除此之外还有其他一些工艺也能够帮助提升性能。例如在信号线之间加入隔板保持距离，以及在外面包裹可阻挡电磁波的金属屏蔽网等。有了这些工艺的帮助，我们现在可以买到性能指标不同的各种网线。网线的性能是以“类”来区分的，双绞线的主要种类如表。</p>
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/6.png" class="">
<h2 id="集线器将信号发往所有线路"><a href="#集线器将信号发往所有线路" class="headerlink" title="集线器将信号发往所有线路"></a>集线器将信号发往所有线路</h2><p>当信号到达集线器后，会被广播到整个网络中。以太网的基本架构就是将包发到所有的设备，然后由设备根据接收方 MAC 地址来判断应该接收哪些包，而集线器就是这一架构的忠实体现，它就是负责按照以太网的基本架构将信号广播出去。</p>
<h3 id="集线器工作方式"><a href="#集线器工作方式" class="headerlink" title="集线器工作方式"></a>集线器工作方式</h3><p>首先，在每个接口的后面装有和网卡中的 PHY（MAU）功能相同的模块，但如果它们像网卡端一样采用直连式接线，是无法正常接收信号的。要正常接收信号，必须将“发送线路”和“接收线路”连接起来才行。集线器中的 PHY（MAU）模块与接口之间采用交叉接线的原因正是在于此。</p>
<p>集线器的接口中有一个 MDI&#x2F;MDI-XB 切换开关，MDI(<code>Media Dependent Interface</code>媒体相关接口) 就是对 RJ-45 接口和信号收发模块进行直连接线， 而 MDI-X 则是交叉接线。由于集线器的接口一般都是 MDI-X 模式，要将两台集线器相连时，就需要将其中一台改成 MDI 模式（（a））。如果集线器上没有 MDI 切换开关，而且所有的接口又都是 MDI-X 时，可以用交叉网线连接两台集线器。所谓交叉网线，就是一种将发送和接收信号线反过来接的网线。</p>
<p>此外，交叉网线也可以像图（b）这样用于将两台计算机直接连接起来。网卡不仅可以连接集线器，因为网卡的 PHY（MAU）模块和集线器都是一样的，所以两台计算机的网卡也可以相互连接，只要将一侧的发送信号线和另一侧的接收信号线连起来就可以收发数据了。</p>
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/7.png" class="">
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/8.png" class="">

<p>信号到达集线器的 PHY（MAU）模块后，会进入中继电路。中继电路的基本功能就是将输入的信号广播到集线器的所有端口上。当然，也有一些产品具有信号整形、错误抑制等功能，但基本上就是将输入的信号原封不动地输出到网线接口。</p>
<p>接下来，信号从所有接口流出，到达连接在集线器上的所有设备。然后，这些设备在收到信号之后会通过 MAC 头部中的接收方 MAC 地址判断是不是发给自己的，如果是发给自己的就接受，否则就忽略。这样，网络包就能够到达指定 MAC 地址的接收方了。</p>
<p>由于集线器只是原封不动地将信号广播出去，所以即便信号受到噪声的干扰发生了失真，也会原样发送到目的地。这时，接收信号的设备，也就是交换机、路由器、服务器等，会在将信号转换成数字信息后通过 FCS 校验发现错误，并将出错的包丢弃。当然，丢弃包并不会影响数据的传输，因为丢弃的包不会触发确认响应。因此协议栈的 TCP 模块会检测到丢包，并对该包进行重传。</p>
<h1 id="交换机的包转发操作"><a href="#交换机的包转发操作" class="headerlink" title="交换机的包转发操作"></a>交换机的包转发操作</h1><h2 id="交换机根据地址表进行转发"><a href="#交换机根据地址表进行转发" class="headerlink" title="交换机根据地址表进行转发"></a>交换机根据地址表进行转发</h2><h3 id="包是如何通过交换机的"><a href="#包是如何通过交换机的" class="headerlink" title="包是如何通过交换机的"></a>包是如何通过交换机的</h3><p>交换机的设计是将网络包原样转发到目的地，下图就是它的内部结构。</p>
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/9.png" class="">

<p>首先，信号到达网线接口，并由 PHY（MAU）模块进行接收，这一部分和集线器是相同的。也就是说，它的接口和 PHY（MAU）模块也是以 MDI-X 模式进行连接的，当信号从双绞线传入时，就会进入 PHY（MAU）模块的接收部分。</p>
<p>接下来，PHY（MAU）模块会将网线中的信号转换为通用格式，然后传递给 MAC 模块。MAC 模块将信号转换为数字信息，然后通过包末尾的 FCS 校验错误，如果没有问题则存放到缓冲区中。这部分操作和网卡基本相同，大家可以认为交换机的每个网线接口后面都是一块网卡。网线接口和后面的电路部分加在一起称为一个端口，也就是说交换机的一个端口就相当于计算机上的一块网卡。但交换机的工作方式和网卡有一点不同。网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，交换机的端口不具有 MAC 地址。</p>
<p>将包存入缓冲区后，接下来需要查询一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录了。MAC 地址表主要包含两个信息，一个是设备的 MAC 地址，另一个是该设备连接在交换机的哪个端口上。以图中的地址表为例，MAC 地址和端口是一一对应的，通过这张表就能够判断出收到的包应该转发到哪个端口。举个例子，如果收到的包的接收方 MAC 地址为<code>00-02-B3-1C-9C-F9</code>，则与图的表中的第 3 行匹配，根据端口列的信息，可知这个地址位于 8 号端口上，然后就可以通过交换电路将包发送到相应的端口了。</p>
<h3 id="交换电路是如何工作的"><a href="#交换电路是如何工作的" class="headerlink" title="交换电路是如何工作的"></a>交换电路是如何工作的</h3><p>交换电路的结构如图所示，它可以将输入端和输出端连接起来。</p>
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/10.png" class="">

<p>其中，信号线排列成网格状，每一个交叉点都有一个交换开关，交换开关是电子控制的，通过切换开关的状态就可以改变信号的流向。交换电路的输入端和输出端分别连接各个接收端口和发送端口，网络包通过这个网格状的电路在端口之间流动。举个例子，假设现在要将包从 2 号端口发送到 7 号端口，那么信号会从输入端的 2 号线进入交换电路，这时，如果让左起的 6 个开关水平导通，然后将第 7 个开关切换为垂直导通，信号就会像图上一样流到输出端 7 号线路，于是网络包就被发送到了 7 号端口。每个交叉点上的交换开关都可以独立工作，因此只要路径不重复，就可以同时传输多路信号。</p>
<p>当网络包通过交换电路到达发送端口时，端口中的 MAC 模块和 PHY（MAU）模块会执行发送操作，将信号发送到网线中，这部分和网卡发送信号的过程是一样的。根据以太网的规则，首先应该确认没有其他设备在发送信号，也就是确认信号收发模块中的接收线路没有信号进来。如果检测到其他设备在发送信号，则需要等待信号发送完毕；如果没有其他信号，或者其他信号已经发送完毕，这时就可以将包的数字信息转换为电信号发送出去。在发送信号的过程中，还需要对接收信号进行监控，这一点和网卡也是一样的。如果在发送过程中检测到其他设备发送信号，就意味着出现了信号碰撞，这时需要发送阻塞信号以停止网络中所有的发送操作，等待一段时间后再尝试重新发送，这一步和网卡也是一样的。</p>
<h2 id="MAC-地址表的维护"><a href="#MAC-地址表的维护" class="headerlink" title="MAC 地址表的维护"></a>MAC 地址表的维护</h2><p>交换机在转发包的过程中，还需要对 MAC 地址表的内容进行维护，维护操作分为两种。</p>
<p>第一种是收到包时，将发送方 MAC 地址以及其输入端口的号码写入 MAC 地址表中。由于收到包的那个端口就连接着发送这个包的设备，所以只要将这个包的发送方 MAC 地址写入地址表，以后当收到发往这个地址的包时，交换机就可以将它转发到正确的端口了。交换机每次收到包时都会执行这个操作，因此只要某个设备发送过网络包，它的 MAC 地址就会被记录到地址表中。</p>
<p>另一种是删除地址表中某条记录的操作，这是为了防止设备移动时产生问题。比如，我们在开会时会把笔记本电脑从办公桌拿到会议室，这时设备就发生了移动。从交换机的角度来看，就是本来连接在某个端口上的笔记本电脑消失了。这时如果交换机收到了发往这台已经消失的笔记本电脑的包，那么它依然会将包转发到原来的端口，通信就会出错，因此必须想办法删除那些过时的记录。然而，交换机没办法知道这台笔记本电脑已经从原来的端口移走了。因此地址表中的记录不能永久有效，而是要在一段时间不使用后就自动删除。</p>
<p>那么当笔记本电脑被拿到会议室之后，只要笔记本电脑连接到会议室的交换机，交换机就会根据笔记本电脑发出的包来更新它的地址表。因此，对于目的地的交换机来说，不需要什么特别的措施就可以正常工作了。</p>
<p>综合来看，为了防止终端设备移动产生问题，只需要将一段时间不使用的过时记录从地址表中删除就可以了。</p>
<p>过时记录从地址表中删除的时间一般为几分钟，因此在过时记录被删除之前，依然可能有发给该设备的包到达交换机。这时，交换机会将包转发到老的端口，通信就会发生错误，这种情况尽管罕见，但的确也有可能发生。遇到这样的情况，只要重启一下交换机，地址表就会被清空并更新正确的信息，然后网络就又可以正常工作了。</p>
<p>总之，交换机会自行更新或删除地址表中的记录，不需要手动维护。当地址表的内容出现异常时，只要重启一下交换机就可以重置地址表，也不需要手动进行维护。</p>
<h2 id="特殊操作"><a href="#特殊操作" class="headerlink" title="特殊操作"></a>特殊操作</h2><p>比如，交换机查询地址表之后发现记录中的目标端口和这个包的源端口是同一个端口。当像图这样用集线器和交换机连接在一起时就会遇到这样的情况，那么这种情况要怎么处理呢？</p>
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/11.png" class="">

<p>首先，计算机 A 发送的包到达集线器后会被集线器转发到所有端口上，也就是会到达交换机和计算机 B（①）。</p>
<p>这时，交换机转发这个包之后，这个包会原路返回集线器（②），然后，集线器又把包转发到所有端口，于是这个包又到达了计算机 A 和计算机 B。所以计算机 B 就会收到两个相同的包，这会导致无法正常通信。因此，当交换机发现一个包要发回到原端口时，就会直接丢弃这个包。</p>
<p>还有另外一种特殊情况，就是地址表中找不到指定的 MAC 地址。这可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备一段时间没有工作导致地址被从地址表中删除了。这种情况下，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。这样做不会产生什么问题，因为以太网的设计本来就是将包发送到整个网络的，然后只有相应的接收者才接收包，而其他设备则会忽略这个包。</p>
<p>有人会说：“这样做会发送多余的包，会不会造成网络拥塞呢？”其实完全不用过于担心，因为发送了包之后目标设备会作出响应，只要返回了响应包，交换机就可以将它的地址写入地址表，下次也就不需要把包发到所有端口了。局域网中每秒可以传输上千个包，多出一两个包并无大碍。</p>
<p>此外，如果接收方 MAC 地址是一个广播地址，那么交换机会将包发送到除源端口之外的所有端口。</p>
<h2 id="全双工模式可以同时进行发送和接收"><a href="#全双工模式可以同时进行发送和接收" class="headerlink" title="全双工模式可以同时进行发送和接收"></a>全双工模式可以同时进行发送和接收</h2><p>全双工模式是交换机特有的工作模式，它可以同时进行发送和接收操作，集线器不具备这样的特性。</p>
<p>使用集线器时，如果多台计算机同时发送信号，信号就会在集线器内部混杂在一起，进而无法使用，这种现象称为碰撞，是以太网的一个重要特征。不过，只要不用集线器，就不会发生碰撞。</p>
<p>而使用双绞线时，发送和接收的信号线是各自独立的，因此在双绞线中信号不会发生碰撞。网线连接的另一端，即交换机端口和网卡的 PHY（MAU）模块以及 MAC 模块，其内部发送和接收电路也是各自独立的，信号也不会发生碰撞。因此，只要不用集线器，就可以避免信号碰撞了。如果不存在碰撞，也就不需要半双工模式中的碰撞处理机制了。也就是说，发送和接收可以同时进行。然而，以太网规范中规定了在网络中有信号时要等该信号结束后再发送信号，因此发送和接收还是无法同时进行。</p>
<p>于是，人们对以太网规范进行了修订，增加了一个无论网络中有没有信号都可以发送信号的工作模式，同时规定在这一工作模式下停用碰撞检测。这种工作模式就是全双工模式。在全双工模式下，无需等待其他信号结束就可以发送信号，因此它比半双工模式速度要快。由于双方可以同时发送数据，所以可同时传输的数据量也更大，性能也就更高。</p>
<blockquote>
<p>交换机的全双工模式可以同时发送和接收信号。</p>
</blockquote>
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/12.png" class="">
<h2 id="自动协商：确定最优的传输速率"><a href="#自动协商：确定最优的传输速率" class="headerlink" title="自动协商：确定最优的传输速率"></a>自动协商：确定最优的传输速率</h2><p>随着全双工模式的出现，如何在全双工和半双工模式之间进行切换的问题也产生了。在全双工模式刚刚出现的时候，还需要手动进行切换，但这样实在太麻烦，于是后来出现了自动切换工作模式的功能。这一功能可以由相互连接的双方探测对方是否支持全双工模式，并自动切换成相应的工作模式。此外，除了能自动切换工作模式之外，还能探测对方的传输速率并进行自动切换。这种自动切换的功能称为自动协商。</p>
<p>在以太网中，当没有数据在传输时，网络中会填充一种被称为连接脉冲的脉冲信号。在没有数据信号时就填充连接脉冲，这使得网络中一直都有一定的信号流过，从而能够检测对方是否在正常工作，或者说网线有没有正常连接。以太网设备的网线接口周围有一个绿色的 LED 指示灯，它表示是否检测到正常的脉冲信号。如果绿灯亮，说明 PHY（MAU）模块以及网线连接正常。</p>
<p>在双绞线以太网规范最初制定的时候，只规定了按一定间隔发送脉冲信号，这种信号只能用来确认网络是否正常。后来，人们又设计出了如图这样的具有特定排列的脉冲信号，通过这种信号可以将自身的状态告知对方。自动协商功能就利用了这样的脉冲信号，即通过这种信号将自己能够支持的工作模式和传输速率相互告知对方，并从中选择一个最优的组合。</p>
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/13.png" class="">

<p>下面来看一个具体的例子。假设现在连接双方的情况如表所示，网卡一方支持所有的速率和工作模式，而交换机只支持到 100 Mbit&#x2F;s 全双工模式。当两台设备通电并完成硬件初始化之后，就会开始用脉冲信号发送自己支持的速率和工作模式。当对方收到信号之后，会通过读取脉冲信号的排列来判断对方支持的模式，然后看看双方都支持的模式有哪些。 表是按照优先级排序的，因此双方都支持的模式就是第 3 行及以下的部分。越往上优先级越高，因此在本例中 100 Mbit&#x2F;s 全双工模式就是最优组合，于是双方就会以这个模式开始工作。</p>
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/14.png" class="">
<h2 id="交换机可同时执行多个转发操作"><a href="#交换机可同时执行多个转发操作" class="headerlink" title="交换机可同时执行多个转发操作"></a>交换机可同时执行多个转发操作</h2><p>交换机只将包转发到具有特定 MAC 地址的设备连接的端口，其他端口都是空闲的。当包从最上面的端口发送到最下面的端口时，其他端口都处于空闲状态，这些端口可以传输其他的包，因此交换机可以同时转发多个包。</p>
<p>相对地，集线器会将输入的信号广播到所有的端口，如果同时输入多个信号就会发生碰撞，无法同时传输多路信号，因此从设备整体的转发能力来看，交换机要高于集线器。</p>
<h1 id="路由器的包转发操作"><a href="#路由器的包转发操作" class="headerlink" title="路由器的包转发操作"></a>路由器的包转发操作</h1><h2 id="路由器的基本知识"><a href="#路由器的基本知识" class="headerlink" title="路由器的基本知识"></a>路由器的基本知识</h2><p>网络包经过集线器和交换机之后，现在到达了路由器，并在此被转发到下一个路由器。这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。不过在具体的操作过程上，路由器和交换机是有区别的。因为路由器是基于 IP 设计的，而交换机是基于以太网设计的。</p>
<p>路由器的内部结构如图。</p>
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/15.png" class="">

<p>只要看明白路由器包括转发模块和端口模块两部分就可以了。其中转发模块负责判断包的转发目的地，端口模块负责包的收发操作。换句话说，路由器转发模块和端口模块的关系，就相当于协议栈的 IP 模块和网卡之间的关系。因此，可以将路由器的转发模块想象成 IP 模块，将端口模块想象成网卡。</p>
<p>通过更换网卡，计算机不仅可以支持以太网，也可以支持无线局域网，路由器也是一样。如果路由器的端口模块安装了支持无线局域网的硬件，就可以支持无线局域网了。此外，计算机的网卡除了以太网和无线局域网之外很少见到支持其他通信技术的品种，而路由器的端口模块则支持除局域网之外的多种通信技术，如 ADSL、FTTH，以及各种宽带专线等，只要端口模块安装了支持这些技术的硬件即可。</p>
<p>路由器在转发包时，首先会通过端口将发过来的包接收进来，这一步的工作过程取决于端口对应的通信技术。对于以太网端口来说，就是按照以太网规范进行工作，而无线局域网端口则按照无线局域网的规范工作，总之就是委托端口的硬件将包接收进来。接下来，转发模块会根据接收到的包的 IP 头部中记录的接收方 IP 地址，在路由表中进行查询，以此判断转发目标。然后，转发模块将包转移到转发目标对应的端口，端口再按照硬件的规则将包发送出去，也就是转发模块委托端口模块将包发送出去的意思。</p>
<p>这就是路由器的基本原理，下面再做一些补充。端口模块会根据相应通信技术的规范来执行包收发的操作，这意味着端口模块是以实际的发送方或者接收方的身份来收发网络包的。以以太网端口为例，路由器的端口具有 MAC 地址，因此它就能够成为以太网的发送方和接收方。端口还具有 IP 地址，从这个意义上来说，它和计算机的网卡是一样的。当转发包时，首先路由器端口会接收发给自己的以太网包，然后查询转发目标，再由相应的端口作为发送方将以太网包发送出去。这一点和交换机是不同的，交换机只是将进来的包转发出去而已，它自己并不会成为发送方或者接收方。</p>
<blockquote>
<p>路由器的各个端口都具有 MAC 地址和 IP 地址。</p>
</blockquote>
<h2 id="路由表中的信息"><a href="#路由表中的信息" class="headerlink" title="路由表中的信息"></a>路由表中的信息</h2><p>在“查表判断转发目标”这一点上，路由器和交换机的大体思路是类似的，不过具体的工作过程有所不同。交换机是通过 MAC 头部中的接收方 MAC 地址来判断转发目标的，而路由器则是根据 IP 头部中的 IP 地址来判断的。由于使用的地址不同，记录转发目标的表的内容也会不同。</p>
<p>路由器中的表叫作路由表，其中包含的信息如图所示。</p>
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/16.png" class="">

<blockquote>
<p>路由器根据“IP 地址”判断转发目标。</p>
</blockquote>
<p>最左侧的目标地址列记录的是接收方的信息。这里可能不是很容易理解，实际上这里的 IP 地址只包含表示子网的网络号部分的比特值，而表示主机号部分的比特值全部为 0。路由器会将接收到的网络包的接收方 IP 地址与路由表中的目标地址进行比较，并找到相应的记录。交换机在地址表中只匹配完全一致的记录，而路由器则会忽略主机号部分，只匹配网络号部分。</p>
<p>在匹配地址的过程中，路由器需要知道网络号的比特数，因此路由表中还有一列子网掩码。通过这个值就可以判断出网络号的比特数。</p>
<blockquote>
<p>路由器会忽略主机号，只匹配网络号。</p>
</blockquote>
<p>刚才我们说过，目标地址列中的 IP 地址表示的是子网，但也有一些例外，有时地址本身的子网掩码和路由表中的子网掩码是不一致的，这是路由聚合的结果。路由聚合会将几个子网合并成一个子网，并在路由表中只产生一条记录。</p>
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/17.png" class="">

<p>如图所示，我们现在有 3 个子网，分别为<code>10.10.1.0/24、10.10.2.0/24、10.10.3.0/24</code>，路由器 B 需要将包发往这 3 个子网。在这种情况下，路由器 B 的路由表中原本应该有对应这 3 个子网的 3 条记录，但在这个例子中，无论发往任何一个子网，都是通过路由器 A 来进行转发，因此我们可以在路由表中将这 3 个子网合并成<code>10.10.0.0/16</code>，这样也可以正确地进行转发，但我们减少了路由表中的记录数量，这就是路由聚合。经过路由聚合，多个子网会被合并成一个子网，子网掩码会发生变化，同时，目标地址列也会改成聚合后的地址。</p>
<p>相对地，还有另外一些情况，如将一个子网进行细分并注册在路由表中，然后拆分成多条记录。</p>
<p>从结果上看，路由表的子网掩码列只是用来在匹配目标地址时告诉路由器应该匹配多少个比特。而且，目标地址中的地址和实际子网的网络号可能并不完全相同，但即便如此，路由器依然可以正常工作。</p>
<p>此外，通过上述方法，我们也可以将某台具体计算机的地址写入路由表中，这时的子网掩码为<code>255.255.255.255</code>，也就是说地址中的全部 32 个比特都为 1。这样一来，主机号部分比特全部为 0 可以表示一个子网，主机号部分比特不全部为 0 可以表示某一台计算机，两种情况可以用相同的规则来处理。</p>
<p>路由表的子网掩码列只表示在匹配网络包目标地址时需要对比的比特数量。</p>
<p>在子网掩码的右边还有网关和接口两列，它们表示网络包的转发目标。根据目标地址和子网掩码匹配到某条记录后，路由器就会将网络包交给接口列中指定的网络接口（即端口），并转发到网关列中指定的 IP 地址。</p>
<p>最后一列是跃点计数，它表示距离目标 IP 地址的距离是远还是近。这个数字越小，表示距离目的地越近；数字越大，表示距离目的地越远。</p>
<p>路由表记录维护的方式和交换机也有所不同。交换机中对 MAC 地址表的维护是包转发操作中的一个步骤，而路由器中对路由表的维护是与包转发操作相互独立的，也就是说，在转发包的过程中不需要对路由表的内容进行维护。</p>
<p>对路由表进行维护的方法有几种，大体上可分为以下两类。</p>
<ul>
<li>由人手动维护路由记录</li>
<li>根据路由协议机制，通过路由器之间的信息交换由路由器自行维护路由表的记录，路由协议有很多种，例如 RIP、OSPC、BGP 等都属于路由协议。</li>
</ul>
<h2 id="路由器的包接收操作"><a href="#路由器的包接收操作" class="headerlink" title="路由器的包接收操作"></a>路由器的包接收操作</h2><p>首先，路由器会接收网络包。路由器的端口有各种不同的类型，以以太网端口为例。以太网端口的结构和计算机的网卡基本相同，接收包并存放到缓冲区中的过程也和网卡几乎没有区别。</p>
<p>首先，信号到达网线接口部分，其中的 PHY（MAU）模块和 MAC 模块将信号转换为数字信息，然后通过包末尾的 FCS 进行错误校验，如果没问题则检查 MAC 头部中的接收方 MAC 地址，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。如果包的接收方 MAC 地址不是自己，说明这个包是发给其他设备的，如果接收这个包就违反了以太网的规则。</p>
<p>路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。</p>
<h2 id="查询路由表确定输出端口"><a href="#查询路由表确定输出端口" class="headerlink" title="查询路由表确定输出端口"></a>查询路由表确定输出端口</h2><p>完成包接收操作之后，路由器就会丢弃包开头的 MAC 头部。MAC 头部的作用就是将包送达路由器，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会被丢弃。</p>
<p>通过路由器转发的网络包，其接收方 MAC 地址为路由器端口的 MAC 地址。</p>
<p>接下来，路由器会根据 MAC 头部后方的 IP 头部中的内容进行包的转发操作。转发操作分为几个阶段，首先是查询路由表判断转发目标。</p>
<p>关于具体的工作过程，我们还是来看一个实际的例子，如图的情况，假设地址为<code>10.10.1.101</code>的计算机要向地址为<code>192.168.1.10</code>的服务器发送一个包，这个包先到达图中的路由器。判断转发目标的第一步，就是根据包的接收方 IP 地址查询路由表中的目标地址栏，以找到相匹配的记录。这个匹配并不是匹配全部 32 个比特，而是根据子网掩码列中的值判断网络号的比特数，并匹配相应数量的比特。例如，图中的第 3 行，子网掩码列为<code>255.255.255.0</code>，就表示需要匹配从左起 24 个比特。网络包的接收方 IP 地址和路由表中的目标地址左起 24 个比特的内容都是<code>192.168.1</code>，因此两者是匹配的，该行记录就是候选转发目标之一。</p>
<p>按照这样的规则，我们可能会匹配到多条候选记录。在这个例子中， 第 3、4、5 行都可以匹配。其中，路由器首先寻找网络号比特数最长的一条记录。网络号比特数越长，说明主机号比特数越短，也就意味着该子网内可分配的主机数量越少，即子网中可能存在的主机数量越少，这一规则的目的是尽量缩小范围，所以根据这条记录判断的转发目标就会更加准确。</p>
<p>我们来看图中的例子。第 3 行<code>192.168.1.0/255.255.255.0</code>表示一个子网，第 4 行<code>192.168.1.10/255.255.255.255</code>表示一台服务器。相比服务器所属的子网来说，直接指定服务器本身的地址时范围更小，因此这里应该选择第 4 行作为转发目标。</p>
<p>按照最长匹配原则筛选后，如果只剩一条候选记录，则按照这条记录的内容进行转发。</p>
<p>然而，有时候路由表中会存在网络号长度相同的多条记录，例如考虑到路由器或网线的故障而设置的备用路由就属于这种情况。这时，需要根据跃点计数的值来进行判断。跃点计数越小说明该路由越近，因此应选择跃点计数较小的记录。</p>
<p>如果在路由表中无法找到匹配的记录，路由器会丢弃这个包，并通过 ICMP 消息告知发送方。这里的处理方式和交换机不同，原因在于网络规模的大小。交换机连接的网络最多也就是几千台设备的规模，这个规模并不大。如果只有几千台设备，遇到不知道应该转发到哪里的包，交换机可以将包发送到所有的端口上，虽然这个方法很简单粗暴，但不会引发什么问题。然而，路由器工作的网络环境是互联网，它的规模是远远大于以太网的，全世界所有的设备都连接在互联网上。在如此庞大的网络中，如果将不知道应该转发到哪里的包发送到整个网络上，那就会产生大量的网络包，造成网络拥塞。因此，路由器遇到不知道该转发到哪里的包，就会直接丢弃。</p>
<h2 id="找不到匹配路由时选择默认路由"><a href="#找不到匹配路由时选择默认路由" class="headerlink" title="找不到匹配路由时选择默认路由"></a>找不到匹配路由时选择默认路由</h2><p>既然如此，那么是不是所有的转发目标都需要配置在路由表中才行呢？如果是公司或者家庭网络，这样的做法也没什么问题，但互联网中的转发目标可能超过 20 万个，如果全部要配置在路由表中实在是不太现实。</p>
<p>其实，大家不必担心，因为之前的图，路由表中的最后一行的作用就相当于把所有目标都配置好了。这一行的子网掩码为<code>0.0.0.0</code>，关键就在这里，子网掩码<code>0.0.0.0</code>的意思是网络包接收方 IP 地址和路由表目标地址的匹配中需要匹配的比特数为 0，换句话说，就是根本不需要匹配。只要将子网掩码设置为<code>0.0.0.0</code>，那么无论任何地址都能匹配到这一条记录，这样就不会发生不知道要转发到哪里的问题了。</p>
<p>只要在这一条记录的网关列中填写接入互联网的路由器地址，当匹配不到其他路由时，网络包就会被转发到互联网接入路由器。因此这条记录被称为默认路由，这一行配置的网关地址被称为默认网关。在计算机的 TCP&#x2F;IP 设置窗口中也有一个填写默认网关的框，意思是一样的。计算机上也有一张和路由器一样的路由表，其中默认网关的地址就是我们在设置窗口中填写的地址。</p>
<p>路由表中子网掩码为<code>0.0.0.0</code>的记录表示“默认路由”。</p>
<p>这样一来，无论目标地址是表示一个子网还是表示某台设备，都可以用相同的方法查找出转发目标，而且也避免了不知道转发到哪里的问题。</p>
<h2 id="包的有效期"><a href="#包的有效期" class="headerlink" title="包的有效期"></a>包的有效期</h2><p>从路由表中查找到转发目标之后，网络包就会被转交给输出端口，并最终发送出去，但在此之前，路由器还有一些工作要完成。</p>
<p>第一个工作是更新 IP 头部中的 TTL（Time to Live，生存时间）字段。TTL 字段表示包的有效期，包每经过一个路由器的转发，这个值就会减 1，当这个值变成 0 时，就表示超过了有效期，这个包就会被丢弃。</p>
<p>这个机制是为了防止包在一个地方陷入死循环。如果路由表中的转发目标都配置正确，应该不会出现这样的情况，但如果其中的信息有问题，或者由于设备故障等原因切换到备用路由时导致暂时性的路由混乱，就会出现这样的情况。</p>
<p>发送方在发送包时会将 TTL 设为 64 或 128，也就是说包经过这么多路由器后就会“寿终正寝”。现在的互联网即便访问一台位于地球另一侧的服务器，最多也只需要经过几十个路由器，因此只要包被正确转发，就可以在过期之前到达目的地。</p>
<h2 id="通过分片功能拆分大网络包"><a href="#通过分片功能拆分大网络包" class="headerlink" title="通过分片功能拆分大网络包"></a>通过分片功能拆分大网络包</h2><p>路由器的端口并不只有以太网一种，也可以支持其他局域网或专线通信技术。不同的线路和局域网类型各自能传输的最大包长度也不同，因此输出端口的最大包长度可能会小于输入端口。即便两个端口的最大包长度相同，也可能会因为添加了一些头部数据而导致包的实际长度发生变化，ADSL、FTTH 等宽带接入技术中使用的 PPPoE 协议就属于这种情况。无论哪种情况，一旦转发的包长度超过了输出端口能传输的最大长度，就无法直接发送这个包了。</p>
<p>遇到这种情况，可以使用 IP 协议中定义的分片功能对包进行拆分，缩短每个包的长度。需要注意的是，这里说的分片和 TCP 对数据进行拆分的机制是不同的。TCP 拆分数据的操作是在将数据装到包里之前进行的，换句话说，拆分好的一个数据块正好装进一个包里。从 IP 分片的角度来看，这样一个包其实是一个未拆分的整体，也就是说，分片是对一个完整的包再进行拆分的过程。</p>
<p>分片操作的过程如图所示。</p>
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/18.png" class="">

<p>首先，我们需要知道输出端口的 MTU ，看看这个包能不能不分片直接发送。最大包长度是由端口类型决定的，用这个最大长度减掉头部的长度就是 MTU，将 MTU 与要转发的包长度进行比较。如果输出端口的 MTU 足够大，那么就可以不分片直接发送；如果输出端口的 MTU 太小，那么就需要将包按照这个 MTU 进行分片，但在此之前还需要看一下 IP 头部中的标志字段，确认是否可以分片。</p>
<p>如果查询标志字段发现不能分片，那么就只能丢弃这个包，并通过 ICMP 消息通知发送方。否则，就可以按照输出端口 MTU 对数据进行依次拆分了。在分片中，TCP 头部及其后面的部分都是可分片的数据，尽管 TCP 头部不属于用户数据，但从 IP 来看也是 TCP 请求传输的数据的一部分。数据被拆分后，每一份数据前面会加上 IP 头部，其大部分内容都和原本的 IP 头部一模一样，但其中有部分字段需要更新，这些字段用于记录分片相关的信息。</p>
<h2 id="路由器的发送操作和计算机相同"><a href="#路由器的发送操作和计算机相同" class="headerlink" title="路由器的发送操作和计算机相同"></a>路由器的发送操作和计算机相同</h2><p>到这里，发送前的准备工作就完成了，接下来就会进入包的发送操作。</p>
<p>这一步操作取决于输出端口的类型。如果是以太网端口，则按照以太网的规则将包转换为电信号发送出去；如果是 ADSL 则按照 ADSL 的规则来转换，以此类推。在家庭网络中，路由器后面一般连接 ADSL 等线路接入互联网，因此路由器会根据接入网的规则来发送包。这里，我们假设路由器位于公司等局域网的内部，即输出端口也是以太网，看看这种情况是如何操作的。</p>
<p>以太网的包发送操作是根据以太网规则来进行的，即便设备种类不同，规则也是相同的。也就是说，其基本过程和协议栈中的 IP 模块发送包的过程是相同的，即在包前面加上 MAC 头部，设置其中的一些字段，然后将完成的包转换成电信号并发送出去。</p>
<p>首先，为了判断 MAC 头部中的 MAC 地址应该填写什么值，我们需要根据路由表的网关列判断对方的地址。如果网关是一个 IP 地址，则这个 IP 地址就是我们要转发到的目标地址；如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址。知道对方的 IP 地址之后，接下来需要通过 ARPD 根据 IP 地址查询 MAC 地址，并将查询的结果作为接收方MAC 地址。路由器也有 ARP 缓存，因此首先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。</p>
<p>路由器判断下一个转发目标的方法如下。</p>
<ul>
<li>如果路由表的网关列内容为 IP 地址，则该地址就是下一个转发目标。</li>
<li>如果路由表的网关列内容为空，则 IP 头部中的接收方 IP 地址就是下一个转发目标。</li>
</ul>
<blockquote>
<p>路由器也会使用 ARP 来查询下一个转发目标的 MAC 地址。</p>
</blockquote>
<p>接下来是发送方 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 0080（十六进制）。</p>
<p>网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。例如，当以太网工作在半双工模式时，需要先确认线路中没有其他信号后才能发送，如果检测到碰撞，则需要等待一段时间后重发。如果以太网工作在全双工模式，则不需要确认线路中的信号，可以直接发送。</p>
<p>如果输出端口为以太网，则发送出去的网络包会通过交换机到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地。</p>
<h2 id="路由器与交换机的关系"><a href="#路由器与交换机的关系" class="headerlink" title="路由器与交换机的关系"></a>路由器与交换机的关系</h2><p>要理解两者之间的关系，关键点在于计算机在发送网络包时，或者是路由器在转发网络包时，都需要在前面加上 MAC 头部。之前都是说在开头加上 MAC 头部，准确的说法应该是将 IP 包装进以太网包的数据部分中。也就是说，给包加上 MAC 头部并发送，从本质上说是将 IP 包装进以太网包的数据部分中，委托以太网去传输这些数据。IP 协议本身没有传输包的功能，因此包的实际传输要委托以太网来进行。</p>
<p>路由器是基于 IP 设计的，而交换机是基于以太网设计的，因此 IP 与以太网的关系也就是路由器与交换机的关系。换句话说，路由器将包的传输工作委托给交换机来进行。当然，这里的内容只适用于原原本本实现 IP 和以太网机制的纯粹的路由器和交换机，实际的路由器有内置交换机功能的，比如用于连接互联网的家用路由器就属于这一种，对于这种路由器，上面内容可能就不适用了。但是，如果把这种“不纯粹”的路由器拆分成“纯粹”的路由器和“纯粹”的交换机，则它们各自都适用上面的内容。</p>
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/19.png" class="">

<p>从包的转发目标也可以看出路由器和交换机之间的委托关系。IP 并不是委托以太网将包传输到最终目的地，而是传输到下一个路由器。在创建 MAC 头部时，也是从 IP 的路由表中查找出下一个路由器的 IP 地址，并通过 ARP 查询出 MAC 地址，然后将 MAC 地址写入 MAC 头部中的，这表示 IP 对以太网的委托只是将包传输到下一个路由器就行了。当包到达下一个路由器后，下一个路由器又会重新委托以太网将包传输到再下一个路由器。随着这一过程反复执行，包就会最终到达 IP 的目的地，也就是通信的对象。</p>
<p>到这里我们已经梳理了路由器与交换机之间的关系。简单来说，IP（路由器）负责将包发送给通信对象这一整体过程，而其中将包传输到下一个路由器的过程则是由以太网（交换机）来负责的。</p>
<p>当然，网络并非只有以太网一种，还有无线局域网，以及接入互联网的通信线路，它们和 IP 之间的关系又是什么样的呢？其实只要将以太网替换成无线局域网、互联网线路等通信规格就可以了。也就是说，如果和下一个路由器之间是通过无线局域网连接的，那么就委托无线局域网将包传输过去；如果是通过互联网线路连接的，那么就委托它将包传输过去。除了这里列举的例子之外，世界上还有很多其他类型的通信技术，它们之间的关系也是一样的，都是委托所使用的通信技术将包传输过去。IP 本身不负责包的传输，而是委托各种通信技术将包传输到下一个路由器，这样的设计是有重要意义的，即可以根据需要灵活运用各种通信技术，这也是 IP 的最大特点。正是有了这一特点，我们才能够构建出互联网这一规模巨大的网络。</p>
<p>IP（路由器）负责将包送达通信对象这一整体过程，而其中将包传输到下一个路由器的过程则是由以太网（交换机）来负责的。</p>
<h1 id="路由器的附加功能"><a href="#路由器的附加功能" class="headerlink" title="路由器的附加功能"></a>路由器的附加功能</h1><h2 id="通过地址转换有效利用-IP-地址"><a href="#通过地址转换有效利用-IP-地址" class="headerlink" title="通过地址转换有效利用 IP 地址"></a>通过地址转换有效利用 IP 地址</h2><p>现在的路由器除了基本功能之外，还有一些附加功能。两种最重要的功能——地址转换和包过滤。</p>
<p>所谓地址，就是用来识别每一台设备的标志，因此每台设备都应该有一个唯一不重复的地址，就好像如果很多人的地址都一样，那么快递员就不知道该把包裹送给谁了。</p>
<p>网络也是一样，本来互联网中所有的设备都应该有自己的固定地址，而且最早也确实是这样做的。比如，公司内网需要接入互联网的时候，应该向地址管理机构申请 IP 地址，并将它们分配给公司里的每台设备。换句话说，那个时候没有内网和外网的区别，所有客户端都是直接连接到互联网的。</p>
<p>尽管互联网原本是这样设计的，但进入 20 世纪 90 年代之后，互联网逐步向公众普及，接入互联网的设备数量也快速增长，如此一来，情况就发生了变化。如果还用原来的方法接入，过不了多久，可分配的地址就用光了。如果不能保证每台设备有唯一不重复的地址，就会从根本上影响网络包的传输，这是一个非常严重的问题。如果任由这样发展下去，不久的将来，一旦固定地址用光，新的设备就无法接入了，互联网也就无法继续发展了。</p>
<p>解决这个问题的关键在于固定地址的分配方式。举个例子，假如有 A、 B 两家公司，它们的内网是完全独立的。这种情况下，两家公司的内网之间不会有网络包流动，即使 A 公司的某台服务器和 B 公司的某台客户端具有相同的 IP 地址也没关系，因为它们之间不会进行通信。只要在每家公司自己的范围内，能够明确判断网络包的目的地就可以了，是否和其他公司的内网地址重复无关紧要，只要每个公司的网络是相互独立的，就不会出现问题。</p>
<p>解决地址不足的问题，利用的就是这样的性质，即公司内部设备的地址不一定要和其他公司不重复。这样一来，公司内部设备就不需要分配固定地址了，从而大幅节省了 IP 地址。当然，就算是公司内网，也不是可以随便分配地址的，因此需要设置一定的规则，规定某些地址是用于内网的，这些地址叫作私有地址，而原来的固定地址则叫作公有地址。</p>
<p>私有地址的规则其实并不复杂，在内网中可用作私有地址的范围仅限以下这些。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">10.0.0.0 ～ 10.255.255.255</span><br><span class="line">172.16.0.0 ～ 172.31.255.255</span><br><span class="line">192.168.0.0 ～ 192.168.255.255</span><br></pre></td></tr></table></figure>
<p>在制定私有地址规则时，这些地址属于公有地址中还没有分配的范围。</p>
<p>换句话说，私有地址本身并没有什么特别的结构，只不过是将公有地址中没分配的一部分拿出来规定只能在内网使用它们而已。这个范围中的地址和其他公司重复也没关系，所以对于这些地址不作统一管理，不需要申请，任何人都可以自由使用。当然，如果在公司内部地址有重复就无法传输网络包了，因此必须避免在内网中出现重复的地址。</p>
<p>尽管这样的确能节省一部分地址，但仅凭这一点还无法完全解决问题。公司内网并不是完全独立的，而是需要通过互联网和其他很多公司相连接，所以当内网和互联网之间需要传输包的时候，问题就出现了，因为如果很多地方都出现相同的地址，包就无法正确传输了。</p>
<p>于是，当公司内网和互联网连接的时候，需要将公司内网分成两个部分，一部分是对互联网开放的服务器，另一部分是公司内部设备。其中对互联网开放的部分分配公有地址，可以和互联网直接进行通信。相对地，内网部分则分配私有地址，内网中的设备不能和互联网直接收发网络包，而是通过一种特别的机制进行连接，这个机制就叫地址转换。</p>
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/20.png" class="">
<h2 id="地址转换的基本原理"><a href="#地址转换的基本原理" class="headerlink" title="地址转换的基本原理"></a>地址转换的基本原理</h2><p>地址转换的基本原理是在转发网络包时对 IP 头部中的 IP 地址和端口号进行改写。具体的过程我们来看一个实际的例子，假设现在要访问 Web 服务器，看看包是如何传输的。</p>
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/21.png" class="">

<p>首先，TCP 连接操作的第一个包被转发到互联网时，将发送方 IP 地址从私有地址改写成公有地址。这里使用的公有地址是地址转换设备的互联网接入端口的地址。与此同时，端口号也需要进行改写，地址转换设备会随机选择一个空闲的端口。然后，改写前的私有地址和端口号，以及改写后的公有地址和端口号，会作为一组相对应的记录保存在地址转换设备内部的一张表中。</p>
<p>改写发送方 IP 地址和端口号之后，包就被发往互联网，最终到达服务器，然后服务器会返回一个包。服务器返回的包的接收包是原始包的发送方，因此返回的包的接收方就是改写后的公有地址和端口号。这个公有地址其实是地址转换设备的地址，因此这个返回包就会到达地址转换设备。</p>
<p>接下来，地址转换设备会从地址对应表中通过公有地址和端口号找到相对应的私有地址和端口号，并改写接收方信息，然后将包发给公司内网，这样包就能够到达原始的发送方了。</p>
<p>在后面的包收发过程中，地址转换设备需要根据对应表查找私有地址和公有地址的对应关系，再改写地址和端口号之后进行转发。当数据收发结束，进入断开阶段，访问互联网的操作全部完成后，对应表中的记录就会被删除。</p>
<p>通过这样的机制，具有私有地址的设备就也可以访问互联网了。从互联网一端来看，实际的通信对象是地址转换设备（这里指的是路由器）。</p>
<p>家庭网络中的工作过程也是完全相同的，只是规模不同而已。</p>
<h2 id="改写端口号的原因"><a href="#改写端口号的原因" class="headerlink" title="改写端口号的原因"></a>改写端口号的原因</h2><p>现在我们使用的地址转换机制是同时改写地址和端口号的，但早期的地址转换机制是只改写地址，不改写端口号的。用这种方法也可以让公司内网和互联网进行通信，而且这种方法更简单。</p>
<p>但是，使用这种方法的前提是私有地址和公有地址必须一一对应，也就是说，有多少台设备要上互联网，就需要多少个公有地址。当然，访问动作结束后可以删除对应表中的记录，这时同一个公有地址可以分配给其他设备使用，因此只要让公有地址的数量等于同时访问互联网的设备数量就可以了。然而公司人数一多，同时访问互联网的人数也会增加。一个几千人的公司里，有几百人同时访问互联网是很正常的，这样就需要几百个公有地址。</p>
<p>改写端口号正是为了解决这个问题。客户端一方的端口号本来就是从空闲端口中随机选择的，因此改写了也不会有问题。端口号是一个 16 比特的数值，总共可以分配出几万个端口，因此如果用公有地址加上端口的组合对应一个私有地址，一个公有地址就可以对应几万个私有地址，这种方法提高了公有地址的利用率。</p>
<h2 id="从互联网访问公司内网"><a href="#从互联网访问公司内网" class="headerlink" title="从互联网访问公司内网"></a>从互联网访问公司内网</h2><p>对于从公司内网访问互联网的包，即便其发送方私有地址和端口号没有保存在对应表中也是可以正常转发的，因为用来改写的公有地址就是地址转换设备自身的地址，而端口号只要随便选一个空闲的端口就可以了，这些都可以由地址转换设备自行判断。然而，对于从互联网访问公司内网的包，如果在对应表中没有记录就无法正常转发。因为如果对应表中没有记录，就意味着地址转换设备无法判断公有地址与私有地址之间的对应关系。</p>
<p>换个角度来看，这意味着对于没有在访问互联网的内网设备，是无法从互联网向其发送网络包的。而且即便是正在访问的设备，也只能向和互联网通信中使用的那个端口发送网络包，无法向其他端口发送包。也就是说，除非公司主动允许，否则是无法从互联网向公司内网发送网络包的。</p>
<p>这种机制具有防止非法入侵的效果。<br>不过，有时候我们希望能够从互联网访问公司内网，这需要进行一些设置才能实现。之所以无法从互联网访问内网，是因为对应表里没有相应的记录，那么我们只要事先手动添加这样的记录就可以了。一般来说，用于外网访问的服务器可以放在地址转换设备的外面并为它分配一个公有地址，也可以将服务器的私有地址手动添加到地址转换设备中，这样就可以从互联网访问到这台具有私有地址的服务器了。</p>
<img src="/2021/12/03/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84/%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%843/22.png" class="">
<h2 id="路由器的包过滤功能"><a href="#路由器的包过滤功能" class="headerlink" title="路由器的包过滤功能"></a>路由器的包过滤功能</h2><p>包过滤也是路由器的一个重要附加功能。包过滤就是在对包进行转发时，根据 MAC 头部、IP 头部、TCP 头部的内容，按照事先设置好的规则决定是转发这个包，还是丢弃这个包。我们通常说的防火墙设备或软件，大多数都是利用这一机制来防止非法入侵的。</p>
<p>包过滤的原理非常简单，但要想设置一套恰当的规则来区分非法访问和正常访问，只阻止非法入侵而不影响正常访问，是非常不容易的。</p>
<p>举个例子，为了防止从互联网非法入侵内网，我们可以将来自互联网的所有包都屏蔽掉，正如 TCP 的工作过程一样，网络包是双向传输的，如果简单地阻止来自互联网的全部包，那么从内网访问互联网的操作也会无法正常进行。</p>
<p>当网络包通过互联网接入路由器之后，它终于要进入互联网内部了。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" rel="tag">计算机网络</a></li></ul>

    </footer>
  </div>

   
   
  
</article>

    
  </article>
  

  
  <nav class="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/11/">上一页</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><a class="page-number" href="/page/11/">11</a><span class="page-number current">12</span><a class="page-number" href="/page/13/">13</a><a class="page-number" href="/page/14/">14</a><span class="space">&hellip;</span><a class="page-number" href="/page/37/">37</a><a class="extend next" rel="next" href="/page/13/">下一页</a>
  </nav>
  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2017-2023
        <i class="ri-heart-fill heart_icon"></i> WSQ
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="学海无涯"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories/%E5%89%8D%E7%AB%AF/">前端</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/">数据库</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<script src="https://cdn.staticfile.org/animejs/3.2.1/anime.min.js"></script>

<script src="/js/clickBoom1.js"></script>
 
<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>复制</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->
 
<script src="/js/dz.js"></script>
 
<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    

  </div>
</body>

</html>